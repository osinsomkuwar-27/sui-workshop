{"ast":null,"code":"/**\n * @module LRUCache\n */\nconst perf = typeof performance === 'object' && performance && typeof performance.now === 'function' ? performance : Date;\nconst warned = new Set();\n/* c8 ignore start */\nconst PROCESS = typeof process === 'object' && !!process ? process : {};\n/* c8 ignore start */\nconst emitWarning = (msg, type, code, fn) => {\n  typeof PROCESS.emitWarning === 'function' ? PROCESS.emitWarning(msg, type, code, fn) : console.error(`[${code}] ${type}: ${msg}`);\n};\nlet AC = globalThis.AbortController;\nlet AS = globalThis.AbortSignal;\n/* c8 ignore start */\nif (typeof AC === 'undefined') {\n  //@ts-ignore\n  AS = class AbortSignal {\n    onabort;\n    _onabort = [];\n    reason;\n    aborted = false;\n    addEventListener(_, fn) {\n      this._onabort.push(fn);\n    }\n  };\n  //@ts-ignore\n  AC = class AbortController {\n    constructor() {\n      warnACPolyfill();\n    }\n    signal = new AS();\n    abort(reason) {\n      if (this.signal.aborted) return;\n      //@ts-ignore\n      this.signal.reason = reason;\n      //@ts-ignore\n      this.signal.aborted = true;\n      //@ts-ignore\n      for (const fn of this.signal._onabort) {\n        fn(reason);\n      }\n      this.signal.onabort?.(reason);\n    }\n  };\n  let printACPolyfillWarning = PROCESS.env?.LRU_CACHE_IGNORE_AC_WARNING !== '1';\n  const warnACPolyfill = () => {\n    if (!printACPolyfillWarning) return;\n    printACPolyfillWarning = false;\n    emitWarning('AbortController is not defined. If using lru-cache in ' + 'node 14, load an AbortController polyfill from the ' + '`node-abort-controller` package. A minimal polyfill is ' + 'provided for use by LRUCache.fetch(), but it should not be ' + 'relied upon in other contexts (eg, passing it to other APIs that ' + 'use AbortController/AbortSignal might have undesirable effects). ' + 'You may disable this with LRU_CACHE_IGNORE_AC_WARNING=1 in the env.', 'NO_ABORT_CONTROLLER', 'ENOTSUP', warnACPolyfill);\n  };\n}\n/* c8 ignore stop */\nconst shouldWarn = code => !warned.has(code);\nconst TYPE = Symbol('type');\nconst isPosInt = n => n && n === Math.floor(n) && n > 0 && isFinite(n);\n/* c8 ignore start */\n// This is a little bit ridiculous, tbh.\n// The maximum array length is 2^32-1 or thereabouts on most JS impls.\n// And well before that point, you're caching the entire world, I mean,\n// that's ~32GB of just integers for the next/prev links, plus whatever\n// else to hold that many keys and values.  Just filling the memory with\n// zeroes at init time is brutal when you get that big.\n// But why not be complete?\n// Maybe in the future, these limits will have expanded.\nconst getUintArray = max => !isPosInt(max) ? null : max <= Math.pow(2, 8) ? Uint8Array : max <= Math.pow(2, 16) ? Uint16Array : max <= Math.pow(2, 32) ? Uint32Array : max <= Number.MAX_SAFE_INTEGER ? ZeroArray : null;\n/* c8 ignore stop */\nclass ZeroArray extends Array {\n  constructor(size) {\n    super(size);\n    this.fill(0);\n  }\n}\nclass Stack {\n  heap;\n  length;\n  // private constructor\n  static #constructing = false;\n  static create(max) {\n    const HeapCls = getUintArray(max);\n    if (!HeapCls) return [];\n    Stack.#constructing = true;\n    const s = new Stack(max, HeapCls);\n    Stack.#constructing = false;\n    return s;\n  }\n  constructor(max, HeapCls) {\n    /* c8 ignore start */\n    if (!Stack.#constructing) {\n      throw new TypeError('instantiate Stack using Stack.create(n)');\n    }\n    /* c8 ignore stop */\n    this.heap = new HeapCls(max);\n    this.length = 0;\n  }\n  push(n) {\n    this.heap[this.length++] = n;\n  }\n  pop() {\n    return this.heap[--this.length];\n  }\n}\n/**\n * Default export, the thing you're using this module to get.\n *\n * The `K` and `V` types define the key and value types, respectively. The\n * optional `FC` type defines the type of the `context` object passed to\n * `cache.fetch()` and `cache.memo()`.\n *\n * Keys and values **must not** be `null` or `undefined`.\n *\n * All properties from the options object (with the exception of `max`,\n * `maxSize`, `fetchMethod`, `memoMethod`, `dispose` and `disposeAfter`) are\n * added as normal public members. (The listed options are read-only getters.)\n *\n * Changing any of these will alter the defaults for subsequent method calls.\n */\nexport class LRUCache {\n  // options that cannot be changed without disaster\n  #max;\n  #maxSize;\n  #dispose;\n  #disposeAfter;\n  #fetchMethod;\n  #memoMethod;\n  /**\n   * {@link LRUCache.OptionsBase.ttl}\n   */\n  ttl;\n  /**\n   * {@link LRUCache.OptionsBase.ttlResolution}\n   */\n  ttlResolution;\n  /**\n   * {@link LRUCache.OptionsBase.ttlAutopurge}\n   */\n  ttlAutopurge;\n  /**\n   * {@link LRUCache.OptionsBase.updateAgeOnGet}\n   */\n  updateAgeOnGet;\n  /**\n   * {@link LRUCache.OptionsBase.updateAgeOnHas}\n   */\n  updateAgeOnHas;\n  /**\n   * {@link LRUCache.OptionsBase.allowStale}\n   */\n  allowStale;\n  /**\n   * {@link LRUCache.OptionsBase.noDisposeOnSet}\n   */\n  noDisposeOnSet;\n  /**\n   * {@link LRUCache.OptionsBase.noUpdateTTL}\n   */\n  noUpdateTTL;\n  /**\n   * {@link LRUCache.OptionsBase.maxEntrySize}\n   */\n  maxEntrySize;\n  /**\n   * {@link LRUCache.OptionsBase.sizeCalculation}\n   */\n  sizeCalculation;\n  /**\n   * {@link LRUCache.OptionsBase.noDeleteOnFetchRejection}\n   */\n  noDeleteOnFetchRejection;\n  /**\n   * {@link LRUCache.OptionsBase.noDeleteOnStaleGet}\n   */\n  noDeleteOnStaleGet;\n  /**\n   * {@link LRUCache.OptionsBase.allowStaleOnFetchAbort}\n   */\n  allowStaleOnFetchAbort;\n  /**\n   * {@link LRUCache.OptionsBase.allowStaleOnFetchRejection}\n   */\n  allowStaleOnFetchRejection;\n  /**\n   * {@link LRUCache.OptionsBase.ignoreFetchAbort}\n   */\n  ignoreFetchAbort;\n  // computed properties\n  #size;\n  #calculatedSize;\n  #keyMap;\n  #keyList;\n  #valList;\n  #next;\n  #prev;\n  #head;\n  #tail;\n  #free;\n  #disposed;\n  #sizes;\n  #starts;\n  #ttls;\n  #hasDispose;\n  #hasFetchMethod;\n  #hasDisposeAfter;\n  /**\n   * Do not call this method unless you need to inspect the\n   * inner workings of the cache.  If anything returned by this\n   * object is modified in any way, strange breakage may occur.\n   *\n   * These fields are private for a reason!\n   *\n   * @internal\n   */\n  static unsafeExposeInternals(c) {\n    return {\n      // properties\n      starts: c.#starts,\n      ttls: c.#ttls,\n      sizes: c.#sizes,\n      keyMap: c.#keyMap,\n      keyList: c.#keyList,\n      valList: c.#valList,\n      next: c.#next,\n      prev: c.#prev,\n      get head() {\n        return c.#head;\n      },\n      get tail() {\n        return c.#tail;\n      },\n      free: c.#free,\n      // methods\n      isBackgroundFetch: p => c.#isBackgroundFetch(p),\n      backgroundFetch: (k, index, options, context) => c.#backgroundFetch(k, index, options, context),\n      moveToTail: index => c.#moveToTail(index),\n      indexes: options => c.#indexes(options),\n      rindexes: options => c.#rindexes(options),\n      isStale: index => c.#isStale(index)\n    };\n  }\n  // Protected read-only members\n  /**\n   * {@link LRUCache.OptionsBase.max} (read-only)\n   */\n  get max() {\n    return this.#max;\n  }\n  /**\n   * {@link LRUCache.OptionsBase.maxSize} (read-only)\n   */\n  get maxSize() {\n    return this.#maxSize;\n  }\n  /**\n   * The total computed size of items in the cache (read-only)\n   */\n  get calculatedSize() {\n    return this.#calculatedSize;\n  }\n  /**\n   * The number of items stored in the cache (read-only)\n   */\n  get size() {\n    return this.#size;\n  }\n  /**\n   * {@link LRUCache.OptionsBase.fetchMethod} (read-only)\n   */\n  get fetchMethod() {\n    return this.#fetchMethod;\n  }\n  get memoMethod() {\n    return this.#memoMethod;\n  }\n  /**\n   * {@link LRUCache.OptionsBase.dispose} (read-only)\n   */\n  get dispose() {\n    return this.#dispose;\n  }\n  /**\n   * {@link LRUCache.OptionsBase.disposeAfter} (read-only)\n   */\n  get disposeAfter() {\n    return this.#disposeAfter;\n  }\n  constructor(options) {\n    const {\n      max = 0,\n      ttl,\n      ttlResolution = 1,\n      ttlAutopurge,\n      updateAgeOnGet,\n      updateAgeOnHas,\n      allowStale,\n      dispose,\n      disposeAfter,\n      noDisposeOnSet,\n      noUpdateTTL,\n      maxSize = 0,\n      maxEntrySize = 0,\n      sizeCalculation,\n      fetchMethod,\n      memoMethod,\n      noDeleteOnFetchRejection,\n      noDeleteOnStaleGet,\n      allowStaleOnFetchRejection,\n      allowStaleOnFetchAbort,\n      ignoreFetchAbort\n    } = options;\n    if (max !== 0 && !isPosInt(max)) {\n      throw new TypeError('max option must be a nonnegative integer');\n    }\n    const UintArray = max ? getUintArray(max) : Array;\n    if (!UintArray) {\n      throw new Error('invalid max value: ' + max);\n    }\n    this.#max = max;\n    this.#maxSize = maxSize;\n    this.maxEntrySize = maxEntrySize || this.#maxSize;\n    this.sizeCalculation = sizeCalculation;\n    if (this.sizeCalculation) {\n      if (!this.#maxSize && !this.maxEntrySize) {\n        throw new TypeError('cannot set sizeCalculation without setting maxSize or maxEntrySize');\n      }\n      if (typeof this.sizeCalculation !== 'function') {\n        throw new TypeError('sizeCalculation set to non-function');\n      }\n    }\n    if (memoMethod !== undefined && typeof memoMethod !== 'function') {\n      throw new TypeError('memoMethod must be a function if defined');\n    }\n    this.#memoMethod = memoMethod;\n    if (fetchMethod !== undefined && typeof fetchMethod !== 'function') {\n      throw new TypeError('fetchMethod must be a function if specified');\n    }\n    this.#fetchMethod = fetchMethod;\n    this.#hasFetchMethod = !!fetchMethod;\n    this.#keyMap = new Map();\n    this.#keyList = new Array(max).fill(undefined);\n    this.#valList = new Array(max).fill(undefined);\n    this.#next = new UintArray(max);\n    this.#prev = new UintArray(max);\n    this.#head = 0;\n    this.#tail = 0;\n    this.#free = Stack.create(max);\n    this.#size = 0;\n    this.#calculatedSize = 0;\n    if (typeof dispose === 'function') {\n      this.#dispose = dispose;\n    }\n    if (typeof disposeAfter === 'function') {\n      this.#disposeAfter = disposeAfter;\n      this.#disposed = [];\n    } else {\n      this.#disposeAfter = undefined;\n      this.#disposed = undefined;\n    }\n    this.#hasDispose = !!this.#dispose;\n    this.#hasDisposeAfter = !!this.#disposeAfter;\n    this.noDisposeOnSet = !!noDisposeOnSet;\n    this.noUpdateTTL = !!noUpdateTTL;\n    this.noDeleteOnFetchRejection = !!noDeleteOnFetchRejection;\n    this.allowStaleOnFetchRejection = !!allowStaleOnFetchRejection;\n    this.allowStaleOnFetchAbort = !!allowStaleOnFetchAbort;\n    this.ignoreFetchAbort = !!ignoreFetchAbort;\n    // NB: maxEntrySize is set to maxSize if it's set\n    if (this.maxEntrySize !== 0) {\n      if (this.#maxSize !== 0) {\n        if (!isPosInt(this.#maxSize)) {\n          throw new TypeError('maxSize must be a positive integer if specified');\n        }\n      }\n      if (!isPosInt(this.maxEntrySize)) {\n        throw new TypeError('maxEntrySize must be a positive integer if specified');\n      }\n      this.#initializeSizeTracking();\n    }\n    this.allowStale = !!allowStale;\n    this.noDeleteOnStaleGet = !!noDeleteOnStaleGet;\n    this.updateAgeOnGet = !!updateAgeOnGet;\n    this.updateAgeOnHas = !!updateAgeOnHas;\n    this.ttlResolution = isPosInt(ttlResolution) || ttlResolution === 0 ? ttlResolution : 1;\n    this.ttlAutopurge = !!ttlAutopurge;\n    this.ttl = ttl || 0;\n    if (this.ttl) {\n      if (!isPosInt(this.ttl)) {\n        throw new TypeError('ttl must be a positive integer if specified');\n      }\n      this.#initializeTTLTracking();\n    }\n    // do not allow completely unbounded caches\n    if (this.#max === 0 && this.ttl === 0 && this.#maxSize === 0) {\n      throw new TypeError('At least one of max, maxSize, or ttl is required');\n    }\n    if (!this.ttlAutopurge && !this.#max && !this.#maxSize) {\n      const code = 'LRU_CACHE_UNBOUNDED';\n      if (shouldWarn(code)) {\n        warned.add(code);\n        const msg = 'TTL caching without ttlAutopurge, max, or maxSize can ' + 'result in unbounded memory consumption.';\n        emitWarning(msg, 'UnboundedCacheWarning', code, LRUCache);\n      }\n    }\n  }\n  /**\n   * Return the number of ms left in the item's TTL. If item is not in cache,\n   * returns `0`. Returns `Infinity` if item is in cache without a defined TTL.\n   */\n  getRemainingTTL(key) {\n    return this.#keyMap.has(key) ? Infinity : 0;\n  }\n  #initializeTTLTracking() {\n    const ttls = new ZeroArray(this.#max);\n    const starts = new ZeroArray(this.#max);\n    this.#ttls = ttls;\n    this.#starts = starts;\n    this.#setItemTTL = (index, ttl, start = perf.now()) => {\n      starts[index] = ttl !== 0 ? start : 0;\n      ttls[index] = ttl;\n      if (ttl !== 0 && this.ttlAutopurge) {\n        const t = setTimeout(() => {\n          if (this.#isStale(index)) {\n            this.#delete(this.#keyList[index], 'expire');\n          }\n        }, ttl + 1);\n        // unref() not supported on all platforms\n        /* c8 ignore start */\n        if (t.unref) {\n          t.unref();\n        }\n        /* c8 ignore stop */\n      }\n    };\n    this.#updateItemAge = index => {\n      starts[index] = ttls[index] !== 0 ? perf.now() : 0;\n    };\n    this.#statusTTL = (status, index) => {\n      if (ttls[index]) {\n        const ttl = ttls[index];\n        const start = starts[index];\n        /* c8 ignore next */\n        if (!ttl || !start) return;\n        status.ttl = ttl;\n        status.start = start;\n        status.now = cachedNow || getNow();\n        const age = status.now - start;\n        status.remainingTTL = ttl - age;\n      }\n    };\n    // debounce calls to perf.now() to 1s so we're not hitting\n    // that costly call repeatedly.\n    let cachedNow = 0;\n    const getNow = () => {\n      const n = perf.now();\n      if (this.ttlResolution > 0) {\n        cachedNow = n;\n        const t = setTimeout(() => cachedNow = 0, this.ttlResolution);\n        // not available on all platforms\n        /* c8 ignore start */\n        if (t.unref) {\n          t.unref();\n        }\n        /* c8 ignore stop */\n      }\n      return n;\n    };\n    this.getRemainingTTL = key => {\n      const index = this.#keyMap.get(key);\n      if (index === undefined) {\n        return 0;\n      }\n      const ttl = ttls[index];\n      const start = starts[index];\n      if (!ttl || !start) {\n        return Infinity;\n      }\n      const age = (cachedNow || getNow()) - start;\n      return ttl - age;\n    };\n    this.#isStale = index => {\n      const s = starts[index];\n      const t = ttls[index];\n      return !!t && !!s && (cachedNow || getNow()) - s > t;\n    };\n  }\n  // conditionally set private methods related to TTL\n  #updateItemAge = () => {};\n  #statusTTL = () => {};\n  #setItemTTL = () => {};\n  /* c8 ignore stop */\n  #isStale = () => false;\n  #initializeSizeTracking() {\n    const sizes = new ZeroArray(this.#max);\n    this.#calculatedSize = 0;\n    this.#sizes = sizes;\n    this.#removeItemSize = index => {\n      this.#calculatedSize -= sizes[index];\n      sizes[index] = 0;\n    };\n    this.#requireSize = (k, v, size, sizeCalculation) => {\n      // provisionally accept background fetches.\n      // actual value size will be checked when they return.\n      if (this.#isBackgroundFetch(v)) {\n        return 0;\n      }\n      if (!isPosInt(size)) {\n        if (sizeCalculation) {\n          if (typeof sizeCalculation !== 'function') {\n            throw new TypeError('sizeCalculation must be a function');\n          }\n          size = sizeCalculation(v, k);\n          if (!isPosInt(size)) {\n            throw new TypeError('sizeCalculation return invalid (expect positive integer)');\n          }\n        } else {\n          throw new TypeError('invalid size value (must be positive integer). ' + 'When maxSize or maxEntrySize is used, sizeCalculation ' + 'or size must be set.');\n        }\n      }\n      return size;\n    };\n    this.#addItemSize = (index, size, status) => {\n      sizes[index] = size;\n      if (this.#maxSize) {\n        const maxSize = this.#maxSize - sizes[index];\n        while (this.#calculatedSize > maxSize) {\n          this.#evict(true);\n        }\n      }\n      this.#calculatedSize += sizes[index];\n      if (status) {\n        status.entrySize = size;\n        status.totalCalculatedSize = this.#calculatedSize;\n      }\n    };\n  }\n  #removeItemSize = _i => {};\n  #addItemSize = (_i, _s, _st) => {};\n  #requireSize = (_k, _v, size, sizeCalculation) => {\n    if (size || sizeCalculation) {\n      throw new TypeError('cannot set size without setting maxSize or maxEntrySize on cache');\n    }\n    return 0;\n  };\n  *#indexes({\n    allowStale = this.allowStale\n  } = {}) {\n    if (this.#size) {\n      for (let i = this.#tail; true;) {\n        if (!this.#isValidIndex(i)) {\n          break;\n        }\n        if (allowStale || !this.#isStale(i)) {\n          yield i;\n        }\n        if (i === this.#head) {\n          break;\n        } else {\n          i = this.#prev[i];\n        }\n      }\n    }\n  }\n  *#rindexes({\n    allowStale = this.allowStale\n  } = {}) {\n    if (this.#size) {\n      for (let i = this.#head; true;) {\n        if (!this.#isValidIndex(i)) {\n          break;\n        }\n        if (allowStale || !this.#isStale(i)) {\n          yield i;\n        }\n        if (i === this.#tail) {\n          break;\n        } else {\n          i = this.#next[i];\n        }\n      }\n    }\n  }\n  #isValidIndex(index) {\n    return index !== undefined && this.#keyMap.get(this.#keyList[index]) === index;\n  }\n  /**\n   * Return a generator yielding `[key, value]` pairs,\n   * in order from most recently used to least recently used.\n   */\n  *entries() {\n    for (const i of this.#indexes()) {\n      if (this.#valList[i] !== undefined && this.#keyList[i] !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {\n        yield [this.#keyList[i], this.#valList[i]];\n      }\n    }\n  }\n  /**\n   * Inverse order version of {@link LRUCache.entries}\n   *\n   * Return a generator yielding `[key, value]` pairs,\n   * in order from least recently used to most recently used.\n   */\n  *rentries() {\n    for (const i of this.#rindexes()) {\n      if (this.#valList[i] !== undefined && this.#keyList[i] !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {\n        yield [this.#keyList[i], this.#valList[i]];\n      }\n    }\n  }\n  /**\n   * Return a generator yielding the keys in the cache,\n   * in order from most recently used to least recently used.\n   */\n  *keys() {\n    for (const i of this.#indexes()) {\n      const k = this.#keyList[i];\n      if (k !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {\n        yield k;\n      }\n    }\n  }\n  /**\n   * Inverse order version of {@link LRUCache.keys}\n   *\n   * Return a generator yielding the keys in the cache,\n   * in order from least recently used to most recently used.\n   */\n  *rkeys() {\n    for (const i of this.#rindexes()) {\n      const k = this.#keyList[i];\n      if (k !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {\n        yield k;\n      }\n    }\n  }\n  /**\n   * Return a generator yielding the values in the cache,\n   * in order from most recently used to least recently used.\n   */\n  *values() {\n    for (const i of this.#indexes()) {\n      const v = this.#valList[i];\n      if (v !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {\n        yield this.#valList[i];\n      }\n    }\n  }\n  /**\n   * Inverse order version of {@link LRUCache.values}\n   *\n   * Return a generator yielding the values in the cache,\n   * in order from least recently used to most recently used.\n   */\n  *rvalues() {\n    for (const i of this.#rindexes()) {\n      const v = this.#valList[i];\n      if (v !== undefined && !this.#isBackgroundFetch(this.#valList[i])) {\n        yield this.#valList[i];\n      }\n    }\n  }\n  /**\n   * Iterating over the cache itself yields the same results as\n   * {@link LRUCache.entries}\n   */\n  [Symbol.iterator]() {\n    return this.entries();\n  }\n  /**\n   * A String value that is used in the creation of the default string\n   * description of an object. Called by the built-in method\n   * `Object.prototype.toString`.\n   */\n  [Symbol.toStringTag] = 'LRUCache';\n  /**\n   * Find a value for which the supplied fn method returns a truthy value,\n   * similar to `Array.find()`. fn is called as `fn(value, key, cache)`.\n   */\n  find(fn, getOptions = {}) {\n    for (const i of this.#indexes()) {\n      const v = this.#valList[i];\n      const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;\n      if (value === undefined) continue;\n      if (fn(value, this.#keyList[i], this)) {\n        return this.get(this.#keyList[i], getOptions);\n      }\n    }\n  }\n  /**\n   * Call the supplied function on each item in the cache, in order from most\n   * recently used to least recently used.\n   *\n   * `fn` is called as `fn(value, key, cache)`.\n   *\n   * If `thisp` is provided, function will be called in the `this`-context of\n   * the provided object, or the cache if no `thisp` object is provided.\n   *\n   * Does not update age or recenty of use, or iterate over stale values.\n   */\n  forEach(fn, thisp = this) {\n    for (const i of this.#indexes()) {\n      const v = this.#valList[i];\n      const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;\n      if (value === undefined) continue;\n      fn.call(thisp, value, this.#keyList[i], this);\n    }\n  }\n  /**\n   * The same as {@link LRUCache.forEach} but items are iterated over in\n   * reverse order.  (ie, less recently used items are iterated over first.)\n   */\n  rforEach(fn, thisp = this) {\n    for (const i of this.#rindexes()) {\n      const v = this.#valList[i];\n      const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;\n      if (value === undefined) continue;\n      fn.call(thisp, value, this.#keyList[i], this);\n    }\n  }\n  /**\n   * Delete any stale entries. Returns true if anything was removed,\n   * false otherwise.\n   */\n  purgeStale() {\n    let deleted = false;\n    for (const i of this.#rindexes({\n      allowStale: true\n    })) {\n      if (this.#isStale(i)) {\n        this.#delete(this.#keyList[i], 'expire');\n        deleted = true;\n      }\n    }\n    return deleted;\n  }\n  /**\n   * Get the extended info about a given entry, to get its value, size, and\n   * TTL info simultaneously. Returns `undefined` if the key is not present.\n   *\n   * Unlike {@link LRUCache#dump}, which is designed to be portable and survive\n   * serialization, the `start` value is always the current timestamp, and the\n   * `ttl` is a calculated remaining time to live (negative if expired).\n   *\n   * Always returns stale values, if their info is found in the cache, so be\n   * sure to check for expirations (ie, a negative {@link LRUCache.Entry#ttl})\n   * if relevant.\n   */\n  info(key) {\n    const i = this.#keyMap.get(key);\n    if (i === undefined) return undefined;\n    const v = this.#valList[i];\n    const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;\n    if (value === undefined) return undefined;\n    const entry = {\n      value\n    };\n    if (this.#ttls && this.#starts) {\n      const ttl = this.#ttls[i];\n      const start = this.#starts[i];\n      if (ttl && start) {\n        const remain = ttl - (perf.now() - start);\n        entry.ttl = remain;\n        entry.start = Date.now();\n      }\n    }\n    if (this.#sizes) {\n      entry.size = this.#sizes[i];\n    }\n    return entry;\n  }\n  /**\n   * Return an array of [key, {@link LRUCache.Entry}] tuples which can be\n   * passed to {@link LRLUCache#load}.\n   *\n   * The `start` fields are calculated relative to a portable `Date.now()`\n   * timestamp, even if `performance.now()` is available.\n   *\n   * Stale entries are always included in the `dump`, even if\n   * {@link LRUCache.OptionsBase.allowStale} is false.\n   *\n   * Note: this returns an actual array, not a generator, so it can be more\n   * easily passed around.\n   */\n  dump() {\n    const arr = [];\n    for (const i of this.#indexes({\n      allowStale: true\n    })) {\n      const key = this.#keyList[i];\n      const v = this.#valList[i];\n      const value = this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;\n      if (value === undefined || key === undefined) continue;\n      const entry = {\n        value\n      };\n      if (this.#ttls && this.#starts) {\n        entry.ttl = this.#ttls[i];\n        // always dump the start relative to a portable timestamp\n        // it's ok for this to be a bit slow, it's a rare operation.\n        const age = perf.now() - this.#starts[i];\n        entry.start = Math.floor(Date.now() - age);\n      }\n      if (this.#sizes) {\n        entry.size = this.#sizes[i];\n      }\n      arr.unshift([key, entry]);\n    }\n    return arr;\n  }\n  /**\n   * Reset the cache and load in the items in entries in the order listed.\n   *\n   * The shape of the resulting cache may be different if the same options are\n   * not used in both caches.\n   *\n   * The `start` fields are assumed to be calculated relative to a portable\n   * `Date.now()` timestamp, even if `performance.now()` is available.\n   */\n  load(arr) {\n    this.clear();\n    for (const [key, entry] of arr) {\n      if (entry.start) {\n        // entry.start is a portable timestamp, but we may be using\n        // node's performance.now(), so calculate the offset, so that\n        // we get the intended remaining TTL, no matter how long it's\n        // been on ice.\n        //\n        // it's ok for this to be a bit slow, it's a rare operation.\n        const age = Date.now() - entry.start;\n        entry.start = perf.now() - age;\n      }\n      this.set(key, entry.value, entry);\n    }\n  }\n  /**\n   * Add a value to the cache.\n   *\n   * Note: if `undefined` is specified as a value, this is an alias for\n   * {@link LRUCache#delete}\n   *\n   * Fields on the {@link LRUCache.SetOptions} options param will override\n   * their corresponding values in the constructor options for the scope\n   * of this single `set()` operation.\n   *\n   * If `start` is provided, then that will set the effective start\n   * time for the TTL calculation. Note that this must be a previous\n   * value of `performance.now()` if supported, or a previous value of\n   * `Date.now()` if not.\n   *\n   * Options object may also include `size`, which will prevent\n   * calling the `sizeCalculation` function and just use the specified\n   * number if it is a positive integer, and `noDisposeOnSet` which\n   * will prevent calling a `dispose` function in the case of\n   * overwrites.\n   *\n   * If the `size` (or return value of `sizeCalculation`) for a given\n   * entry is greater than `maxEntrySize`, then the item will not be\n   * added to the cache.\n   *\n   * Will update the recency of the entry.\n   *\n   * If the value is `undefined`, then this is an alias for\n   * `cache.delete(key)`. `undefined` is never stored in the cache.\n   */\n  set(k, v, setOptions = {}) {\n    if (v === undefined) {\n      this.delete(k);\n      return this;\n    }\n    const {\n      ttl = this.ttl,\n      start,\n      noDisposeOnSet = this.noDisposeOnSet,\n      sizeCalculation = this.sizeCalculation,\n      status\n    } = setOptions;\n    let {\n      noUpdateTTL = this.noUpdateTTL\n    } = setOptions;\n    const size = this.#requireSize(k, v, setOptions.size || 0, sizeCalculation);\n    // if the item doesn't fit, don't do anything\n    // NB: maxEntrySize set to maxSize by default\n    if (this.maxEntrySize && size > this.maxEntrySize) {\n      if (status) {\n        status.set = 'miss';\n        status.maxEntrySizeExceeded = true;\n      }\n      // have to delete, in case something is there already.\n      this.#delete(k, 'set');\n      return this;\n    }\n    let index = this.#size === 0 ? undefined : this.#keyMap.get(k);\n    if (index === undefined) {\n      // addition\n      index = this.#size === 0 ? this.#tail : this.#free.length !== 0 ? this.#free.pop() : this.#size === this.#max ? this.#evict(false) : this.#size;\n      this.#keyList[index] = k;\n      this.#valList[index] = v;\n      this.#keyMap.set(k, index);\n      this.#next[this.#tail] = index;\n      this.#prev[index] = this.#tail;\n      this.#tail = index;\n      this.#size++;\n      this.#addItemSize(index, size, status);\n      if (status) status.set = 'add';\n      noUpdateTTL = false;\n    } else {\n      // update\n      this.#moveToTail(index);\n      const oldVal = this.#valList[index];\n      if (v !== oldVal) {\n        if (this.#hasFetchMethod && this.#isBackgroundFetch(oldVal)) {\n          oldVal.__abortController.abort(new Error('replaced'));\n          const {\n            __staleWhileFetching: s\n          } = oldVal;\n          if (s !== undefined && !noDisposeOnSet) {\n            if (this.#hasDispose) {\n              this.#dispose?.(s, k, 'set');\n            }\n            if (this.#hasDisposeAfter) {\n              this.#disposed?.push([s, k, 'set']);\n            }\n          }\n        } else if (!noDisposeOnSet) {\n          if (this.#hasDispose) {\n            this.#dispose?.(oldVal, k, 'set');\n          }\n          if (this.#hasDisposeAfter) {\n            this.#disposed?.push([oldVal, k, 'set']);\n          }\n        }\n        this.#removeItemSize(index);\n        this.#addItemSize(index, size, status);\n        this.#valList[index] = v;\n        if (status) {\n          status.set = 'replace';\n          const oldValue = oldVal && this.#isBackgroundFetch(oldVal) ? oldVal.__staleWhileFetching : oldVal;\n          if (oldValue !== undefined) status.oldValue = oldValue;\n        }\n      } else if (status) {\n        status.set = 'update';\n      }\n    }\n    if (ttl !== 0 && !this.#ttls) {\n      this.#initializeTTLTracking();\n    }\n    if (this.#ttls) {\n      if (!noUpdateTTL) {\n        this.#setItemTTL(index, ttl, start);\n      }\n      if (status) this.#statusTTL(status, index);\n    }\n    if (!noDisposeOnSet && this.#hasDisposeAfter && this.#disposed) {\n      const dt = this.#disposed;\n      let task;\n      while (task = dt?.shift()) {\n        this.#disposeAfter?.(...task);\n      }\n    }\n    return this;\n  }\n  /**\n   * Evict the least recently used item, returning its value or\n   * `undefined` if cache is empty.\n   */\n  pop() {\n    try {\n      while (this.#size) {\n        const val = this.#valList[this.#head];\n        this.#evict(true);\n        if (this.#isBackgroundFetch(val)) {\n          if (val.__staleWhileFetching) {\n            return val.__staleWhileFetching;\n          }\n        } else if (val !== undefined) {\n          return val;\n        }\n      }\n    } finally {\n      if (this.#hasDisposeAfter && this.#disposed) {\n        const dt = this.#disposed;\n        let task;\n        while (task = dt?.shift()) {\n          this.#disposeAfter?.(...task);\n        }\n      }\n    }\n  }\n  #evict(free) {\n    const head = this.#head;\n    const k = this.#keyList[head];\n    const v = this.#valList[head];\n    if (this.#hasFetchMethod && this.#isBackgroundFetch(v)) {\n      v.__abortController.abort(new Error('evicted'));\n    } else if (this.#hasDispose || this.#hasDisposeAfter) {\n      if (this.#hasDispose) {\n        this.#dispose?.(v, k, 'evict');\n      }\n      if (this.#hasDisposeAfter) {\n        this.#disposed?.push([v, k, 'evict']);\n      }\n    }\n    this.#removeItemSize(head);\n    // if we aren't about to use the index, then null these out\n    if (free) {\n      this.#keyList[head] = undefined;\n      this.#valList[head] = undefined;\n      this.#free.push(head);\n    }\n    if (this.#size === 1) {\n      this.#head = this.#tail = 0;\n      this.#free.length = 0;\n    } else {\n      this.#head = this.#next[head];\n    }\n    this.#keyMap.delete(k);\n    this.#size--;\n    return head;\n  }\n  /**\n   * Check if a key is in the cache, without updating the recency of use.\n   * Will return false if the item is stale, even though it is technically\n   * in the cache.\n   *\n   * Check if a key is in the cache, without updating the recency of\n   * use. Age is updated if {@link LRUCache.OptionsBase.updateAgeOnHas} is set\n   * to `true` in either the options or the constructor.\n   *\n   * Will return `false` if the item is stale, even though it is technically in\n   * the cache. The difference can be determined (if it matters) by using a\n   * `status` argument, and inspecting the `has` field.\n   *\n   * Will not update item age unless\n   * {@link LRUCache.OptionsBase.updateAgeOnHas} is set.\n   */\n  has(k, hasOptions = {}) {\n    const {\n      updateAgeOnHas = this.updateAgeOnHas,\n      status\n    } = hasOptions;\n    const index = this.#keyMap.get(k);\n    if (index !== undefined) {\n      const v = this.#valList[index];\n      if (this.#isBackgroundFetch(v) && v.__staleWhileFetching === undefined) {\n        return false;\n      }\n      if (!this.#isStale(index)) {\n        if (updateAgeOnHas) {\n          this.#updateItemAge(index);\n        }\n        if (status) {\n          status.has = 'hit';\n          this.#statusTTL(status, index);\n        }\n        return true;\n      } else if (status) {\n        status.has = 'stale';\n        this.#statusTTL(status, index);\n      }\n    } else if (status) {\n      status.has = 'miss';\n    }\n    return false;\n  }\n  /**\n   * Like {@link LRUCache#get} but doesn't update recency or delete stale\n   * items.\n   *\n   * Returns `undefined` if the item is stale, unless\n   * {@link LRUCache.OptionsBase.allowStale} is set.\n   */\n  peek(k, peekOptions = {}) {\n    const {\n      allowStale = this.allowStale\n    } = peekOptions;\n    const index = this.#keyMap.get(k);\n    if (index === undefined || !allowStale && this.#isStale(index)) {\n      return;\n    }\n    const v = this.#valList[index];\n    // either stale and allowed, or forcing a refresh of non-stale value\n    return this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v;\n  }\n  #backgroundFetch(k, index, options, context) {\n    const v = index === undefined ? undefined : this.#valList[index];\n    if (this.#isBackgroundFetch(v)) {\n      return v;\n    }\n    const ac = new AC();\n    const {\n      signal\n    } = options;\n    // when/if our AC signals, then stop listening to theirs.\n    signal?.addEventListener('abort', () => ac.abort(signal.reason), {\n      signal: ac.signal\n    });\n    const fetchOpts = {\n      signal: ac.signal,\n      options,\n      context\n    };\n    const cb = (v, updateCache = false) => {\n      const {\n        aborted\n      } = ac.signal;\n      const ignoreAbort = options.ignoreFetchAbort && v !== undefined;\n      if (options.status) {\n        if (aborted && !updateCache) {\n          options.status.fetchAborted = true;\n          options.status.fetchError = ac.signal.reason;\n          if (ignoreAbort) options.status.fetchAbortIgnored = true;\n        } else {\n          options.status.fetchResolved = true;\n        }\n      }\n      if (aborted && !ignoreAbort && !updateCache) {\n        return fetchFail(ac.signal.reason);\n      }\n      // either we didn't abort, and are still here, or we did, and ignored\n      const bf = p;\n      if (this.#valList[index] === p) {\n        if (v === undefined) {\n          if (bf.__staleWhileFetching) {\n            this.#valList[index] = bf.__staleWhileFetching;\n          } else {\n            this.#delete(k, 'fetch');\n          }\n        } else {\n          if (options.status) options.status.fetchUpdated = true;\n          this.set(k, v, fetchOpts.options);\n        }\n      }\n      return v;\n    };\n    const eb = er => {\n      if (options.status) {\n        options.status.fetchRejected = true;\n        options.status.fetchError = er;\n      }\n      return fetchFail(er);\n    };\n    const fetchFail = er => {\n      const {\n        aborted\n      } = ac.signal;\n      const allowStaleAborted = aborted && options.allowStaleOnFetchAbort;\n      const allowStale = allowStaleAborted || options.allowStaleOnFetchRejection;\n      const noDelete = allowStale || options.noDeleteOnFetchRejection;\n      const bf = p;\n      if (this.#valList[index] === p) {\n        // if we allow stale on fetch rejections, then we need to ensure that\n        // the stale value is not removed from the cache when the fetch fails.\n        const del = !noDelete || bf.__staleWhileFetching === undefined;\n        if (del) {\n          this.#delete(k, 'fetch');\n        } else if (!allowStaleAborted) {\n          // still replace the *promise* with the stale value,\n          // since we are done with the promise at this point.\n          // leave it untouched if we're still waiting for an\n          // aborted background fetch that hasn't yet returned.\n          this.#valList[index] = bf.__staleWhileFetching;\n        }\n      }\n      if (allowStale) {\n        if (options.status && bf.__staleWhileFetching !== undefined) {\n          options.status.returnedStale = true;\n        }\n        return bf.__staleWhileFetching;\n      } else if (bf.__returned === bf) {\n        throw er;\n      }\n    };\n    const pcall = (res, rej) => {\n      const fmp = this.#fetchMethod?.(k, v, fetchOpts);\n      if (fmp && fmp instanceof Promise) {\n        fmp.then(v => res(v === undefined ? undefined : v), rej);\n      }\n      // ignored, we go until we finish, regardless.\n      // defer check until we are actually aborting,\n      // so fetchMethod can override.\n      ac.signal.addEventListener('abort', () => {\n        if (!options.ignoreFetchAbort || options.allowStaleOnFetchAbort) {\n          res(undefined);\n          // when it eventually resolves, update the cache.\n          if (options.allowStaleOnFetchAbort) {\n            res = v => cb(v, true);\n          }\n        }\n      });\n    };\n    if (options.status) options.status.fetchDispatched = true;\n    const p = new Promise(pcall).then(cb, eb);\n    const bf = Object.assign(p, {\n      __abortController: ac,\n      __staleWhileFetching: v,\n      __returned: undefined\n    });\n    if (index === undefined) {\n      // internal, don't expose status.\n      this.set(k, bf, {\n        ...fetchOpts.options,\n        status: undefined\n      });\n      index = this.#keyMap.get(k);\n    } else {\n      this.#valList[index] = bf;\n    }\n    return bf;\n  }\n  #isBackgroundFetch(p) {\n    if (!this.#hasFetchMethod) return false;\n    const b = p;\n    return !!b && b instanceof Promise && b.hasOwnProperty('__staleWhileFetching') && b.__abortController instanceof AC;\n  }\n  async fetch(k, fetchOptions = {}) {\n    const {\n      // get options\n      allowStale = this.allowStale,\n      updateAgeOnGet = this.updateAgeOnGet,\n      noDeleteOnStaleGet = this.noDeleteOnStaleGet,\n      // set options\n      ttl = this.ttl,\n      noDisposeOnSet = this.noDisposeOnSet,\n      size = 0,\n      sizeCalculation = this.sizeCalculation,\n      noUpdateTTL = this.noUpdateTTL,\n      // fetch exclusive options\n      noDeleteOnFetchRejection = this.noDeleteOnFetchRejection,\n      allowStaleOnFetchRejection = this.allowStaleOnFetchRejection,\n      ignoreFetchAbort = this.ignoreFetchAbort,\n      allowStaleOnFetchAbort = this.allowStaleOnFetchAbort,\n      context,\n      forceRefresh = false,\n      status,\n      signal\n    } = fetchOptions;\n    if (!this.#hasFetchMethod) {\n      if (status) status.fetch = 'get';\n      return this.get(k, {\n        allowStale,\n        updateAgeOnGet,\n        noDeleteOnStaleGet,\n        status\n      });\n    }\n    const options = {\n      allowStale,\n      updateAgeOnGet,\n      noDeleteOnStaleGet,\n      ttl,\n      noDisposeOnSet,\n      size,\n      sizeCalculation,\n      noUpdateTTL,\n      noDeleteOnFetchRejection,\n      allowStaleOnFetchRejection,\n      allowStaleOnFetchAbort,\n      ignoreFetchAbort,\n      status,\n      signal\n    };\n    let index = this.#keyMap.get(k);\n    if (index === undefined) {\n      if (status) status.fetch = 'miss';\n      const p = this.#backgroundFetch(k, index, options, context);\n      return p.__returned = p;\n    } else {\n      // in cache, maybe already fetching\n      const v = this.#valList[index];\n      if (this.#isBackgroundFetch(v)) {\n        const stale = allowStale && v.__staleWhileFetching !== undefined;\n        if (status) {\n          status.fetch = 'inflight';\n          if (stale) status.returnedStale = true;\n        }\n        return stale ? v.__staleWhileFetching : v.__returned = v;\n      }\n      // if we force a refresh, that means do NOT serve the cached value,\n      // unless we are already in the process of refreshing the cache.\n      const isStale = this.#isStale(index);\n      if (!forceRefresh && !isStale) {\n        if (status) status.fetch = 'hit';\n        this.#moveToTail(index);\n        if (updateAgeOnGet) {\n          this.#updateItemAge(index);\n        }\n        if (status) this.#statusTTL(status, index);\n        return v;\n      }\n      // ok, it is stale or a forced refresh, and not already fetching.\n      // refresh the cache.\n      const p = this.#backgroundFetch(k, index, options, context);\n      const hasStale = p.__staleWhileFetching !== undefined;\n      const staleVal = hasStale && allowStale;\n      if (status) {\n        status.fetch = isStale ? 'stale' : 'refresh';\n        if (staleVal && isStale) status.returnedStale = true;\n      }\n      return staleVal ? p.__staleWhileFetching : p.__returned = p;\n    }\n  }\n  async forceFetch(k, fetchOptions = {}) {\n    const v = await this.fetch(k, fetchOptions);\n    if (v === undefined) throw new Error('fetch() returned undefined');\n    return v;\n  }\n  memo(k, memoOptions = {}) {\n    const memoMethod = this.#memoMethod;\n    if (!memoMethod) {\n      throw new Error('no memoMethod provided to constructor');\n    }\n    const {\n      context,\n      forceRefresh,\n      ...options\n    } = memoOptions;\n    const v = this.get(k, options);\n    if (!forceRefresh && v !== undefined) return v;\n    const vv = memoMethod(k, v, {\n      options,\n      context\n    });\n    this.set(k, vv, options);\n    return vv;\n  }\n  /**\n   * Return a value from the cache. Will update the recency of the cache\n   * entry found.\n   *\n   * If the key is not found, get() will return `undefined`.\n   */\n  get(k, getOptions = {}) {\n    const {\n      allowStale = this.allowStale,\n      updateAgeOnGet = this.updateAgeOnGet,\n      noDeleteOnStaleGet = this.noDeleteOnStaleGet,\n      status\n    } = getOptions;\n    const index = this.#keyMap.get(k);\n    if (index !== undefined) {\n      const value = this.#valList[index];\n      const fetching = this.#isBackgroundFetch(value);\n      if (status) this.#statusTTL(status, index);\n      if (this.#isStale(index)) {\n        if (status) status.get = 'stale';\n        // delete only if not an in-flight background fetch\n        if (!fetching) {\n          if (!noDeleteOnStaleGet) {\n            this.#delete(k, 'expire');\n          }\n          if (status && allowStale) status.returnedStale = true;\n          return allowStale ? value : undefined;\n        } else {\n          if (status && allowStale && value.__staleWhileFetching !== undefined) {\n            status.returnedStale = true;\n          }\n          return allowStale ? value.__staleWhileFetching : undefined;\n        }\n      } else {\n        if (status) status.get = 'hit';\n        // if we're currently fetching it, we don't actually have it yet\n        // it's not stale, which means this isn't a staleWhileRefetching.\n        // If it's not stale, and fetching, AND has a __staleWhileFetching\n        // value, then that means the user fetched with {forceRefresh:true},\n        // so it's safe to return that value.\n        if (fetching) {\n          return value.__staleWhileFetching;\n        }\n        this.#moveToTail(index);\n        if (updateAgeOnGet) {\n          this.#updateItemAge(index);\n        }\n        return value;\n      }\n    } else if (status) {\n      status.get = 'miss';\n    }\n  }\n  #connect(p, n) {\n    this.#prev[n] = p;\n    this.#next[p] = n;\n  }\n  #moveToTail(index) {\n    // if tail already, nothing to do\n    // if head, move head to next[index]\n    // else\n    //   move next[prev[index]] to next[index] (head has no prev)\n    //   move prev[next[index]] to prev[index]\n    // prev[index] = tail\n    // next[tail] = index\n    // tail = index\n    if (index !== this.#tail) {\n      if (index === this.#head) {\n        this.#head = this.#next[index];\n      } else {\n        this.#connect(this.#prev[index], this.#next[index]);\n      }\n      this.#connect(this.#tail, index);\n      this.#tail = index;\n    }\n  }\n  /**\n   * Deletes a key out of the cache.\n   *\n   * Returns true if the key was deleted, false otherwise.\n   */\n  delete(k) {\n    return this.#delete(k, 'delete');\n  }\n  #delete(k, reason) {\n    let deleted = false;\n    if (this.#size !== 0) {\n      const index = this.#keyMap.get(k);\n      if (index !== undefined) {\n        deleted = true;\n        if (this.#size === 1) {\n          this.#clear(reason);\n        } else {\n          this.#removeItemSize(index);\n          const v = this.#valList[index];\n          if (this.#isBackgroundFetch(v)) {\n            v.__abortController.abort(new Error('deleted'));\n          } else if (this.#hasDispose || this.#hasDisposeAfter) {\n            if (this.#hasDispose) {\n              this.#dispose?.(v, k, reason);\n            }\n            if (this.#hasDisposeAfter) {\n              this.#disposed?.push([v, k, reason]);\n            }\n          }\n          this.#keyMap.delete(k);\n          this.#keyList[index] = undefined;\n          this.#valList[index] = undefined;\n          if (index === this.#tail) {\n            this.#tail = this.#prev[index];\n          } else if (index === this.#head) {\n            this.#head = this.#next[index];\n          } else {\n            const pi = this.#prev[index];\n            this.#next[pi] = this.#next[index];\n            const ni = this.#next[index];\n            this.#prev[ni] = this.#prev[index];\n          }\n          this.#size--;\n          this.#free.push(index);\n        }\n      }\n    }\n    if (this.#hasDisposeAfter && this.#disposed?.length) {\n      const dt = this.#disposed;\n      let task;\n      while (task = dt?.shift()) {\n        this.#disposeAfter?.(...task);\n      }\n    }\n    return deleted;\n  }\n  /**\n   * Clear the cache entirely, throwing away all values.\n   */\n  clear() {\n    return this.#clear('delete');\n  }\n  #clear(reason) {\n    for (const index of this.#rindexes({\n      allowStale: true\n    })) {\n      const v = this.#valList[index];\n      if (this.#isBackgroundFetch(v)) {\n        v.__abortController.abort(new Error('deleted'));\n      } else {\n        const k = this.#keyList[index];\n        if (this.#hasDispose) {\n          this.#dispose?.(v, k, reason);\n        }\n        if (this.#hasDisposeAfter) {\n          this.#disposed?.push([v, k, reason]);\n        }\n      }\n    }\n    this.#keyMap.clear();\n    this.#valList.fill(undefined);\n    this.#keyList.fill(undefined);\n    if (this.#ttls && this.#starts) {\n      this.#ttls.fill(0);\n      this.#starts.fill(0);\n    }\n    if (this.#sizes) {\n      this.#sizes.fill(0);\n    }\n    this.#head = 0;\n    this.#tail = 0;\n    this.#free.length = 0;\n    this.#calculatedSize = 0;\n    this.#size = 0;\n    if (this.#hasDisposeAfter && this.#disposed) {\n      const dt = this.#disposed;\n      let task;\n      while (task = dt?.shift()) {\n        this.#disposeAfter?.(...task);\n      }\n    }\n  }\n}","map":{"version":3,"names":["perf","performance","now","Date","warned","Set","PROCESS","process","emitWarning","msg","type","code","fn","console","error","AC","globalThis","AbortController","AS","AbortSignal","onabort","_onabort","reason","aborted","addEventListener","_","push","constructor","warnACPolyfill","signal","abort","printACPolyfillWarning","env","LRU_CACHE_IGNORE_AC_WARNING","shouldWarn","has","TYPE","Symbol","isPosInt","n","Math","floor","isFinite","getUintArray","max","pow","Uint8Array","Uint16Array","Uint32Array","Number","MAX_SAFE_INTEGER","ZeroArray","Array","size","fill","Stack","heap","length","constructing","create","HeapCls","s","TypeError","pop","LRUCache","maxSize","dispose","disposeAfter","fetchMethod","memoMethod","ttl","ttlResolution","ttlAutopurge","updateAgeOnGet","updateAgeOnHas","allowStale","noDisposeOnSet","noUpdateTTL","maxEntrySize","sizeCalculation","noDeleteOnFetchRejection","noDeleteOnStaleGet","allowStaleOnFetchAbort","allowStaleOnFetchRejection","ignoreFetchAbort","calculatedSize","keyMap","keyList","valList","next","prev","head","tail","free","disposed","sizes","starts","ttls","hasDispose","hasFetchMethod","hasDisposeAfter","unsafeExposeInternals","c","isBackgroundFetch","p","backgroundFetch","k","index","options","context","moveToTail","indexes","rindexes","isStale","UintArray","Error","undefined","Map","initializeSizeTracking","initializeTTLTracking","add","getRemainingTTL","key","Infinity","#initializeTTLTracking","setItemTTL","start","t","setTimeout","delete","unref","updateItemAge","statusTTL","status","cachedNow","getNow","age","remainingTTL","get","#updateItemAge","#statusTTL","#setItemTTL","#isStale","#initializeSizeTracking","removeItemSize","requireSize","v","addItemSize","evict","entrySize","totalCalculatedSize","_i","#addItemSize","_s","_st","#requireSize","_k","_v","#indexes","i","isValidIndex","#rindexes","#isValidIndex","entries","rentries","keys","rkeys","values","rvalues","iterator","toStringTag","find","getOptions","value","__staleWhileFetching","forEach","thisp","call","rforEach","purgeStale","deleted","info","entry","remain","dump","arr","unshift","load","clear","set","setOptions","maxEntrySizeExceeded","oldVal","__abortController","oldValue","dt","task","shift","val","#evict","hasOptions","peek","peekOptions","#backgroundFetch","ac","fetchOpts","cb","updateCache","ignoreAbort","fetchAborted","fetchError","fetchAbortIgnored","fetchResolved","fetchFail","bf","fetchUpdated","eb","er","fetchRejected","allowStaleAborted","noDelete","del","returnedStale","__returned","pcall","res","rej","fmp","Promise","then","fetchDispatched","Object","assign","#isBackgroundFetch","b","hasOwnProperty","fetch","fetchOptions","forceRefresh","stale","hasStale","staleVal","forceFetch","memo","memoOptions","vv","fetching","connect","#connect","#moveToTail","#delete","pi","ni","#clear"],"sources":["C:\\Users\\hp\\OneDrive\\Desktop\\r\\sui-workshop\\node_modules\\lru-cache\\src\\index.ts"],"sourcesContent":["/**\n * @module LRUCache\n */\n\n// module-private names and types\ntype Perf = { now: () => number }\nconst perf: Perf =\n  typeof performance === 'object' &&\n  performance &&\n  typeof performance.now === 'function'\n    ? performance\n    : Date\n\nconst warned = new Set<string>()\n\n// either a function or a class\ntype ForC = ((...a: any[]) => any) | { new (...a: any[]): any }\n\n/* c8 ignore start */\nconst PROCESS = (\n  typeof process === 'object' && !!process ? process : {}\n) as { [k: string]: any }\n/* c8 ignore start */\n\nconst emitWarning = (\n  msg: string,\n  type: string,\n  code: string,\n  fn: ForC\n) => {\n  typeof PROCESS.emitWarning === 'function'\n    ? PROCESS.emitWarning(msg, type, code, fn)\n    : console.error(`[${code}] ${type}: ${msg}`)\n}\n\nlet AC = globalThis.AbortController\nlet AS = globalThis.AbortSignal\n\n/* c8 ignore start */\nif (typeof AC === 'undefined') {\n  //@ts-ignore\n  AS = class AbortSignal {\n    onabort?: (...a: any[]) => any\n    _onabort: ((...a: any[]) => any)[] = []\n    reason?: any\n    aborted: boolean = false\n    addEventListener(_: string, fn: (...a: any[]) => any) {\n      this._onabort.push(fn)\n    }\n  }\n  //@ts-ignore\n  AC = class AbortController {\n    constructor() {\n      warnACPolyfill()\n    }\n    signal = new AS()\n    abort(reason: any) {\n      if (this.signal.aborted) return\n      //@ts-ignore\n      this.signal.reason = reason\n      //@ts-ignore\n      this.signal.aborted = true\n      //@ts-ignore\n      for (const fn of this.signal._onabort) {\n        fn(reason)\n      }\n      this.signal.onabort?.(reason)\n    }\n  }\n  let printACPolyfillWarning =\n    PROCESS.env?.LRU_CACHE_IGNORE_AC_WARNING !== '1'\n  const warnACPolyfill = () => {\n    if (!printACPolyfillWarning) return\n    printACPolyfillWarning = false\n    emitWarning(\n      'AbortController is not defined. If using lru-cache in ' +\n        'node 14, load an AbortController polyfill from the ' +\n        '`node-abort-controller` package. A minimal polyfill is ' +\n        'provided for use by LRUCache.fetch(), but it should not be ' +\n        'relied upon in other contexts (eg, passing it to other APIs that ' +\n        'use AbortController/AbortSignal might have undesirable effects). ' +\n        'You may disable this with LRU_CACHE_IGNORE_AC_WARNING=1 in the env.',\n      'NO_ABORT_CONTROLLER',\n      'ENOTSUP',\n      warnACPolyfill\n    )\n  }\n}\n/* c8 ignore stop */\n\nconst shouldWarn = (code: string) => !warned.has(code)\n\nconst TYPE = Symbol('type')\nexport type PosInt = number & { [TYPE]: 'Positive Integer' }\nexport type Index = number & { [TYPE]: 'LRUCache Index' }\n\nconst isPosInt = (n: any): n is PosInt =>\n  n && n === Math.floor(n) && n > 0 && isFinite(n)\n\nexport type UintArray = Uint8Array | Uint16Array | Uint32Array\nexport type NumberArray = UintArray | number[]\n\n/* c8 ignore start */\n// This is a little bit ridiculous, tbh.\n// The maximum array length is 2^32-1 or thereabouts on most JS impls.\n// And well before that point, you're caching the entire world, I mean,\n// that's ~32GB of just integers for the next/prev links, plus whatever\n// else to hold that many keys and values.  Just filling the memory with\n// zeroes at init time is brutal when you get that big.\n// But why not be complete?\n// Maybe in the future, these limits will have expanded.\nconst getUintArray = (max: number) =>\n  !isPosInt(max)\n    ? null\n    : max <= Math.pow(2, 8)\n    ? Uint8Array\n    : max <= Math.pow(2, 16)\n    ? Uint16Array\n    : max <= Math.pow(2, 32)\n    ? Uint32Array\n    : max <= Number.MAX_SAFE_INTEGER\n    ? ZeroArray\n    : null\n/* c8 ignore stop */\n\nclass ZeroArray extends Array<number> {\n  constructor(size: number) {\n    super(size)\n    this.fill(0)\n  }\n}\nexport type { ZeroArray }\nexport type { Stack }\n\nexport type StackLike = Stack | Index[]\nclass Stack {\n  heap: NumberArray\n  length: number\n  // private constructor\n  static #constructing: boolean = false\n  static create(max: number): StackLike {\n    const HeapCls = getUintArray(max)\n    if (!HeapCls) return []\n    Stack.#constructing = true\n    const s = new Stack(max, HeapCls)\n    Stack.#constructing = false\n    return s\n  }\n  constructor(\n    max: number,\n    HeapCls: { new (n: number): NumberArray }\n  ) {\n    /* c8 ignore start */\n    if (!Stack.#constructing) {\n      throw new TypeError('instantiate Stack using Stack.create(n)')\n    }\n    /* c8 ignore stop */\n    this.heap = new HeapCls(max)\n    this.length = 0\n  }\n  push(n: Index) {\n    this.heap[this.length++] = n\n  }\n  pop(): Index {\n    return this.heap[--this.length] as Index\n  }\n}\n\n/**\n * Promise representing an in-progress {@link LRUCache#fetch} call\n */\nexport type BackgroundFetch<V> = Promise<V | undefined> & {\n  __returned: BackgroundFetch<V> | undefined\n  __abortController: AbortController\n  __staleWhileFetching: V | undefined\n}\n\nexport type DisposeTask<K, V> = [\n  value: V,\n  key: K,\n  reason: LRUCache.DisposeReason\n]\n\nexport namespace LRUCache {\n  /**\n   * An integer greater than 0, reflecting the calculated size of items\n   */\n  export type Size = number\n\n  /**\n   * Integer greater than 0, representing some number of milliseconds, or the\n   * time at which a TTL started counting from.\n   */\n  export type Milliseconds = number\n\n  /**\n   * An integer greater than 0, reflecting a number of items\n   */\n  export type Count = number\n\n  /**\n   * The reason why an item was removed from the cache, passed\n   * to the {@link Disposer} methods.\n   *\n   * - `evict`: The item was evicted because it is the least recently used,\n   *   and the cache is full.\n   * - `set`: A new value was set, overwriting the old value being disposed.\n   * - `delete`: The item was explicitly deleted, either by calling\n   *   {@link LRUCache#delete}, {@link LRUCache#clear}, or\n   *   {@link LRUCache#set} with an undefined value.\n   * - `expire`: The item was removed due to exceeding its TTL.\n   * - `fetch`: A {@link OptionsBase#fetchMethod} operation returned\n   *   `undefined` or was aborted, causing the item to be deleted.\n   */\n  export type DisposeReason =\n    | 'evict'\n    | 'set'\n    | 'delete'\n    | 'expire'\n    | 'fetch'\n  /**\n   * A method called upon item removal, passed as the\n   * {@link OptionsBase.dispose} and/or\n   * {@link OptionsBase.disposeAfter} options.\n   */\n  export type Disposer<K, V> = (\n    value: V,\n    key: K,\n    reason: DisposeReason\n  ) => void\n\n  /**\n   * A function that returns the effective calculated size\n   * of an entry in the cache.\n   */\n  export type SizeCalculator<K, V> = (value: V, key: K) => Size\n\n  /**\n   * Options provided to the\n   * {@link OptionsBase.fetchMethod} function.\n   */\n  export interface FetcherOptions<K, V, FC = unknown> {\n    signal: AbortSignal\n    options: FetcherFetchOptions<K, V, FC>\n    /**\n     * Object provided in the {@link FetchOptions.context} option to\n     * {@link LRUCache#fetch}\n     */\n    context: FC\n  }\n\n  /**\n   * Occasionally, it may be useful to track the internal behavior of the\n   * cache, particularly for logging, debugging, or for behavior within the\n   * `fetchMethod`. To do this, you can pass a `status` object to the\n   * {@link LRUCache#fetch}, {@link LRUCache#get}, {@link LRUCache#set},\n   * {@link LRUCache#memo}, and {@link LRUCache#has} methods.\n   *\n   * The `status` option should be a plain JavaScript object. The following\n   * fields will be set on it appropriately, depending on the situation.\n   */\n  export interface Status<V> {\n    /**\n     * The status of a set() operation.\n     *\n     * - add: the item was not found in the cache, and was added\n     * - update: the item was in the cache, with the same value provided\n     * - replace: the item was in the cache, and replaced\n     * - miss: the item was not added to the cache for some reason\n     */\n    set?: 'add' | 'update' | 'replace' | 'miss'\n\n    /**\n     * the ttl stored for the item, or undefined if ttls are not used.\n     */\n    ttl?: Milliseconds\n\n    /**\n     * the start time for the item, or undefined if ttls are not used.\n     */\n    start?: Milliseconds\n\n    /**\n     * The timestamp used for TTL calculation\n     */\n    now?: Milliseconds\n\n    /**\n     * the remaining ttl for the item, or undefined if ttls are not used.\n     */\n    remainingTTL?: Milliseconds\n\n    /**\n     * The calculated size for the item, if sizes are used.\n     */\n    entrySize?: Size\n\n    /**\n     * The total calculated size of the cache, if sizes are used.\n     */\n    totalCalculatedSize?: Size\n\n    /**\n     * A flag indicating that the item was not stored, due to exceeding the\n     * {@link OptionsBase.maxEntrySize}\n     */\n    maxEntrySizeExceeded?: true\n\n    /**\n     * The old value, specified in the case of `set:'update'` or\n     * `set:'replace'`\n     */\n    oldValue?: V\n\n    /**\n     * The results of a {@link LRUCache#has} operation\n     *\n     * - hit: the item was found in the cache\n     * - stale: the item was found in the cache, but is stale\n     * - miss: the item was not found in the cache\n     */\n    has?: 'hit' | 'stale' | 'miss'\n\n    /**\n     * The status of a {@link LRUCache#fetch} operation.\n     * Note that this can change as the underlying fetch() moves through\n     * various states.\n     *\n     * - inflight: there is another fetch() for this key which is in process\n     * - get: there is no {@link OptionsBase.fetchMethod}, so\n     *   {@link LRUCache#get} was called.\n     * - miss: the item is not in cache, and will be fetched.\n     * - hit: the item is in the cache, and was resolved immediately.\n     * - stale: the item is in the cache, but stale.\n     * - refresh: the item is in the cache, and not stale, but\n     *   {@link FetchOptions.forceRefresh} was specified.\n     */\n    fetch?: 'get' | 'inflight' | 'miss' | 'hit' | 'stale' | 'refresh'\n\n    /**\n     * The {@link OptionsBase.fetchMethod} was called\n     */\n    fetchDispatched?: true\n\n    /**\n     * The cached value was updated after a successful call to\n     * {@link OptionsBase.fetchMethod}\n     */\n    fetchUpdated?: true\n\n    /**\n     * The reason for a fetch() rejection.  Either the error raised by the\n     * {@link OptionsBase.fetchMethod}, or the reason for an\n     * AbortSignal.\n     */\n    fetchError?: Error\n\n    /**\n     * The fetch received an abort signal\n     */\n    fetchAborted?: true\n\n    /**\n     * The abort signal received was ignored, and the fetch was allowed to\n     * continue.\n     */\n    fetchAbortIgnored?: true\n\n    /**\n     * The fetchMethod promise resolved successfully\n     */\n    fetchResolved?: true\n\n    /**\n     * The fetchMethod promise was rejected\n     */\n    fetchRejected?: true\n\n    /**\n     * The status of a {@link LRUCache#get} operation.\n     *\n     * - fetching: The item is currently being fetched.  If a previous value\n     *   is present and allowed, that will be returned.\n     * - stale: The item is in the cache, and is stale.\n     * - hit: the item is in the cache\n     * - miss: the item is not in the cache\n     */\n    get?: 'stale' | 'hit' | 'miss'\n\n    /**\n     * A fetch or get operation returned a stale value.\n     */\n    returnedStale?: true\n  }\n\n  /**\n   * options which override the options set in the LRUCache constructor\n   * when calling {@link LRUCache#fetch}.\n   *\n   * This is the union of {@link GetOptions} and {@link SetOptions}, plus\n   * {@link OptionsBase.noDeleteOnFetchRejection},\n   * {@link OptionsBase.allowStaleOnFetchRejection},\n   * {@link FetchOptions.forceRefresh}, and\n   * {@link FetcherOptions.context}\n   *\n   * Any of these may be modified in the {@link OptionsBase.fetchMethod}\n   * function, but the {@link GetOptions} fields will of course have no\n   * effect, as the {@link LRUCache#get} call already happened by the time\n   * the fetchMethod is called.\n   */\n  export interface FetcherFetchOptions<K, V, FC = unknown>\n    extends Pick<\n      OptionsBase<K, V, FC>,\n      | 'allowStale'\n      | 'updateAgeOnGet'\n      | 'noDeleteOnStaleGet'\n      | 'sizeCalculation'\n      | 'ttl'\n      | 'noDisposeOnSet'\n      | 'noUpdateTTL'\n      | 'noDeleteOnFetchRejection'\n      | 'allowStaleOnFetchRejection'\n      | 'ignoreFetchAbort'\n      | 'allowStaleOnFetchAbort'\n    > {\n    status?: Status<V>\n    size?: Size\n  }\n\n  /**\n   * Options that may be passed to the {@link LRUCache#fetch} method.\n   */\n  export interface FetchOptions<K, V, FC>\n    extends FetcherFetchOptions<K, V, FC> {\n    /**\n     * Set to true to force a re-load of the existing data, even if it\n     * is not yet stale.\n     */\n    forceRefresh?: boolean\n    /**\n     * Context provided to the {@link OptionsBase.fetchMethod} as\n     * the {@link FetcherOptions.context} param.\n     *\n     * If the FC type is specified as unknown (the default),\n     * undefined or void, then this is optional.  Otherwise, it will\n     * be required.\n     */\n    context?: FC\n    signal?: AbortSignal\n    status?: Status<V>\n  }\n  /**\n   * Options provided to {@link LRUCache#fetch} when the FC type is something\n   * other than `unknown`, `undefined`, or `void`\n   */\n  export interface FetchOptionsWithContext<K, V, FC>\n    extends FetchOptions<K, V, FC> {\n    context: FC\n  }\n  /**\n   * Options provided to {@link LRUCache#fetch} when the FC type is\n   * `undefined` or `void`\n   */\n  export interface FetchOptionsNoContext<K, V>\n    extends FetchOptions<K, V, undefined> {\n    context?: undefined\n  }\n\n  export interface MemoOptions<K, V, FC = unknown>\n    extends Pick<\n      OptionsBase<K, V, FC>,\n      | 'allowStale'\n      | 'updateAgeOnGet'\n      | 'noDeleteOnStaleGet'\n      | 'sizeCalculation'\n      | 'ttl'\n      | 'noDisposeOnSet'\n      | 'noUpdateTTL'\n      | 'noDeleteOnFetchRejection'\n      | 'allowStaleOnFetchRejection'\n      | 'ignoreFetchAbort'\n      | 'allowStaleOnFetchAbort'\n    > {\n    /**\n     * Set to true to force a re-load of the existing data, even if it\n     * is not yet stale.\n     */\n    forceRefresh?: boolean\n    /**\n     * Context provided to the {@link OptionsBase.memoMethod} as\n     * the {@link MemoizerOptions.context} param.\n     *\n     * If the FC type is specified as unknown (the default),\n     * undefined or void, then this is optional.  Otherwise, it will\n     * be required.\n     */\n    context?: FC\n    status?: Status<V>\n  }\n  /**\n   * Options provided to {@link LRUCache#memo} when the FC type is something\n   * other than `unknown`, `undefined`, or `void`\n   */\n  export interface MemoOptionsWithContext<K, V, FC>\n    extends MemoOptions<K, V, FC> {\n    context: FC\n  }\n  /**\n   * Options provided to {@link LRUCache#memo} when the FC type is\n   * `undefined` or `void`\n   */\n  export interface MemoOptionsNoContext<K, V>\n    extends MemoOptions<K, V, undefined> {\n    context?: undefined\n  }\n\n  /**\n   * Options provided to the\n   * {@link OptionsBase.memoMethod} function.\n   */\n  export interface MemoizerOptions<K, V, FC = unknown> {\n    options: MemoizerMemoOptions<K, V, FC>\n    /**\n     * Object provided in the {@link MemoOptions.context} option to\n     * {@link LRUCache#memo}\n     */\n    context: FC\n  }\n\n  /**\n   * options which override the options set in the LRUCache constructor\n   * when calling {@link LRUCache#memo}.\n   *\n   * This is the union of {@link GetOptions} and {@link SetOptions}, plus\n   * {@link MemoOptions.forceRefresh}, and\n   * {@link MemoerOptions.context}\n   *\n   * Any of these may be modified in the {@link OptionsBase.memoMethod}\n   * function, but the {@link GetOptions} fields will of course have no\n   * effect, as the {@link LRUCache#get} call already happened by the time\n   * the memoMethod is called.\n   */\n  export interface MemoizerMemoOptions<K, V, FC = unknown>\n    extends Pick<\n      OptionsBase<K, V, FC>,\n      | 'allowStale'\n      | 'updateAgeOnGet'\n      | 'noDeleteOnStaleGet'\n      | 'sizeCalculation'\n      | 'ttl'\n      | 'noDisposeOnSet'\n      | 'noUpdateTTL'\n    > {\n    status?: Status<V>\n    size?: Size\n    start?: Milliseconds\n  }\n\n  /**\n   * Options that may be passed to the {@link LRUCache#has} method.\n   */\n  export interface HasOptions<K, V, FC>\n    extends Pick<OptionsBase<K, V, FC>, 'updateAgeOnHas'> {\n    status?: Status<V>\n  }\n\n  /**\n   * Options that may be passed to the {@link LRUCache#get} method.\n   */\n  export interface GetOptions<K, V, FC>\n    extends Pick<\n      OptionsBase<K, V, FC>,\n      'allowStale' | 'updateAgeOnGet' | 'noDeleteOnStaleGet'\n    > {\n    status?: Status<V>\n  }\n\n  /**\n   * Options that may be passed to the {@link LRUCache#peek} method.\n   */\n  export interface PeekOptions<K, V, FC>\n    extends Pick<OptionsBase<K, V, FC>, 'allowStale'> {}\n\n  /**\n   * Options that may be passed to the {@link LRUCache#set} method.\n   */\n  export interface SetOptions<K, V, FC>\n    extends Pick<\n      OptionsBase<K, V, FC>,\n      'sizeCalculation' | 'ttl' | 'noDisposeOnSet' | 'noUpdateTTL'\n    > {\n    /**\n     * If size tracking is enabled, then setting an explicit size\n     * in the {@link LRUCache#set} call will prevent calling the\n     * {@link OptionsBase.sizeCalculation} function.\n     */\n    size?: Size\n    /**\n     * If TTL tracking is enabled, then setting an explicit start\n     * time in the {@link LRUCache#set} call will override the\n     * default time from `performance.now()` or `Date.now()`.\n     *\n     * Note that it must be a valid value for whichever time-tracking\n     * method is in use.\n     */\n    start?: Milliseconds\n    status?: Status<V>\n  }\n\n  /**\n   * The type signature for the {@link OptionsBase.fetchMethod} option.\n   */\n  export type Fetcher<K, V, FC = unknown> = (\n    key: K,\n    staleValue: V | undefined,\n    options: FetcherOptions<K, V, FC>\n  ) => Promise<V | undefined | void> | V | undefined | void\n\n  /**\n   * the type signature for the {@link OptionsBase.memoMethod} option.\n   */\n  export type Memoizer<K, V, FC = unknown> = (\n    key: K,\n    staleValue: V | undefined,\n    options: MemoizerOptions<K, V, FC>\n  ) => V\n\n  /**\n   * Options which may be passed to the {@link LRUCache} constructor.\n   *\n   * Most of these may be overridden in the various options that use\n   * them.\n   *\n   * Despite all being technically optional, the constructor requires that\n   * a cache is at minimum limited by one or more of {@link OptionsBase.max},\n   * {@link OptionsBase.ttl}, or {@link OptionsBase.maxSize}.\n   *\n   * If {@link OptionsBase.ttl} is used alone, then it is strongly advised\n   * (and in fact required by the type definitions here) that the cache\n   * also set {@link OptionsBase.ttlAutopurge}, to prevent potentially\n   * unbounded storage.\n   *\n   * All options are also available on the {@link LRUCache} instance, making\n   * it safe to pass an LRUCache instance as the options argumemnt to\n   * make another empty cache of the same type.\n   *\n   * Some options are marked as read-only, because changing them after\n   * instantiation is not safe. Changing any of the other options will of\n   * course only have an effect on subsequent method calls.\n   */\n  export interface OptionsBase<K, V, FC> {\n    /**\n     * The maximum number of items to store in the cache before evicting\n     * old entries. This is read-only on the {@link LRUCache} instance,\n     * and may not be overridden.\n     *\n     * If set, then storage space will be pre-allocated at construction\n     * time, and the cache will perform significantly faster.\n     *\n     * Note that significantly fewer items may be stored, if\n     * {@link OptionsBase.maxSize} and/or {@link OptionsBase.ttl} are also\n     * set.\n     *\n     * **It is strongly recommended to set a `max` to prevent unbounded growth\n     * of the cache.**\n     */\n    max?: Count\n\n    /**\n     * Max time in milliseconds for items to live in cache before they are\n     * considered stale.  Note that stale items are NOT preemptively removed by\n     * default, and MAY live in the cache, contributing to its LRU max, long\n     * after they have expired, unless {@link OptionsBase.ttlAutopurge} is\n     * set.\n     *\n     * If set to `0` (the default value), then that means \"do not track\n     * TTL\", not \"expire immediately\".\n     *\n     * Also, as this cache is optimized for LRU/MRU operations, some of\n     * the staleness/TTL checks will reduce performance, as they will incur\n     * overhead by deleting items.\n     *\n     * This is not primarily a TTL cache, and does not make strong TTL\n     * guarantees. There is no pre-emptive pruning of expired items, but you\n     * _may_ set a TTL on the cache, and it will treat expired items as missing\n     * when they are fetched, and delete them.\n     *\n     * Optional, but must be a non-negative integer in ms if specified.\n     *\n     * This may be overridden by passing an options object to `cache.set()`.\n     *\n     * At least one of `max`, `maxSize`, or `TTL` is required. This must be a\n     * positive integer if set.\n     *\n     * Even if ttl tracking is enabled, **it is strongly recommended to set a\n     * `max` to prevent unbounded growth of the cache.**\n     *\n     * If ttl tracking is enabled, and `max` and `maxSize` are not set,\n     * and `ttlAutopurge` is not set, then a warning will be emitted\n     * cautioning about the potential for unbounded memory consumption.\n     * (The TypeScript definitions will also discourage this.)\n     */\n    ttl?: Milliseconds\n\n    /**\n     * Minimum amount of time in ms in which to check for staleness.\n     * Defaults to 1, which means that the current time is checked\n     * at most once per millisecond.\n     *\n     * Set to 0 to check the current time every time staleness is tested.\n     * (This reduces performance, and is theoretically unnecessary.)\n     *\n     * Setting this to a higher value will improve performance somewhat\n     * while using ttl tracking, albeit at the expense of keeping stale\n     * items around a bit longer than their TTLs would indicate.\n     *\n     * @default 1\n     */\n    ttlResolution?: Milliseconds\n\n    /**\n     * Preemptively remove stale items from the cache.\n     *\n     * Note that this may *significantly* degrade performance, especially if\n     * the cache is storing a large number of items. It is almost always best\n     * to just leave the stale items in the cache, and let them fall out as new\n     * items are added.\n     *\n     * Note that this means that {@link OptionsBase.allowStale} is a bit\n     * pointless, as stale items will be deleted almost as soon as they\n     * expire.\n     *\n     * Use with caution!\n     */\n    ttlAutopurge?: boolean\n\n    /**\n     * When using time-expiring entries with `ttl`, setting this to `true` will\n     * make each item's age reset to 0 whenever it is retrieved from cache with\n     * {@link LRUCache#get}, causing it to not expire. (It can still fall out\n     * of cache based on recency of use, of course.)\n     *\n     * Has no effect if {@link OptionsBase.ttl} is not set.\n     *\n     * This may be overridden by passing an options object to `cache.get()`.\n     */\n    updateAgeOnGet?: boolean\n\n    /**\n     * When using time-expiring entries with `ttl`, setting this to `true` will\n     * make each item's age reset to 0 whenever its presence in the cache is\n     * checked with {@link LRUCache#has}, causing it to not expire. (It can\n     * still fall out of cache based on recency of use, of course.)\n     *\n     * Has no effect if {@link OptionsBase.ttl} is not set.\n     */\n    updateAgeOnHas?: boolean\n\n    /**\n     * Allow {@link LRUCache#get} and {@link LRUCache#fetch} calls to return\n     * stale data, if available.\n     *\n     * By default, if you set `ttl`, stale items will only be deleted from the\n     * cache when you `get(key)`. That is, it's not preemptively pruning items,\n     * unless {@link OptionsBase.ttlAutopurge} is set.\n     *\n     * If you set `allowStale:true`, it'll return the stale value *as well as*\n     * deleting it. If you don't set this, then it'll return `undefined` when\n     * you try to get a stale entry.\n     *\n     * Note that when a stale entry is fetched, _even if it is returned due to\n     * `allowStale` being set_, it is removed from the cache immediately. You\n     * can suppress this behavior by setting\n     * {@link OptionsBase.noDeleteOnStaleGet}, either in the constructor, or in\n     * the options provided to {@link LRUCache#get}.\n     *\n     * This may be overridden by passing an options object to `cache.get()`.\n     * The `cache.has()` method will always return `false` for stale items.\n     *\n     * Only relevant if a ttl is set.\n     */\n    allowStale?: boolean\n\n    /**\n     * Function that is called on items when they are dropped from the\n     * cache, as `dispose(value, key, reason)`.\n     *\n     * This can be handy if you want to close file descriptors or do\n     * other cleanup tasks when items are no longer stored in the cache.\n     *\n     * **NOTE**: It is called _before_ the item has been fully removed\n     * from the cache, so if you want to put it right back in, you need\n     * to wait until the next tick. If you try to add it back in during\n     * the `dispose()` function call, it will break things in subtle and\n     * weird ways.\n     *\n     * Unlike several other options, this may _not_ be overridden by\n     * passing an option to `set()`, for performance reasons.\n     *\n     * The `reason` will be one of the following strings, corresponding\n     * to the reason for the item's deletion:\n     *\n     * - `evict` Item was evicted to make space for a new addition\n     * - `set` Item was overwritten by a new value\n     * - `expire` Item expired its TTL\n     * - `fetch` Item was deleted due to a failed or aborted fetch, or a\n     *   fetchMethod returning `undefined.\n     * - `delete` Item was removed by explicit `cache.delete(key)`,\n     *   `cache.clear()`, or `cache.set(key, undefined)`.\n     */\n    dispose?: Disposer<K, V>\n\n    /**\n     * The same as {@link OptionsBase.dispose}, but called *after* the entry\n     * is completely removed and the cache is once again in a clean state.\n     *\n     * It is safe to add an item right back into the cache at this point.\n     * However, note that it is *very* easy to inadvertently create infinite\n     * recursion this way.\n     */\n    disposeAfter?: Disposer<K, V>\n\n    /**\n     * Set to true to suppress calling the\n     * {@link OptionsBase.dispose} function if the entry key is\n     * still accessible within the cache.\n     *\n     * This may be overridden by passing an options object to\n     * {@link LRUCache#set}.\n     *\n     * Only relevant if `dispose` or `disposeAfter` are set.\n     */\n    noDisposeOnSet?: boolean\n\n    /**\n     * Boolean flag to tell the cache to not update the TTL when setting a new\n     * value for an existing key (ie, when updating a value rather than\n     * inserting a new value).  Note that the TTL value is _always_ set (if\n     * provided) when adding a new entry into the cache.\n     *\n     * Has no effect if a {@link OptionsBase.ttl} is not set.\n     *\n     * May be passed as an option to {@link LRUCache#set}.\n     */\n    noUpdateTTL?: boolean\n\n    /**\n     * Set to a positive integer to track the sizes of items added to the\n     * cache, and automatically evict items in order to stay below this size.\n     * Note that this may result in fewer than `max` items being stored.\n     *\n     * Attempting to add an item to the cache whose calculated size is greater\n     * that this amount will be a no-op. The item will not be cached, and no\n     * other items will be evicted.\n     *\n     * Optional, must be a positive integer if provided.\n     *\n     * Sets `maxEntrySize` to the same value, unless a different value is\n     * provided for `maxEntrySize`.\n     *\n     * At least one of `max`, `maxSize`, or `TTL` is required. This must be a\n     * positive integer if set.\n     *\n     * Even if size tracking is enabled, **it is strongly recommended to set a\n     * `max` to prevent unbounded growth of the cache.**\n     *\n     * Note also that size tracking can negatively impact performance,\n     * though for most cases, only minimally.\n     */\n    maxSize?: Size\n\n    /**\n     * The maximum allowed size for any single item in the cache.\n     *\n     * If a larger item is passed to {@link LRUCache#set} or returned by a\n     * {@link OptionsBase.fetchMethod} or {@link OptionsBase.memoMethod}, then\n     * it will not be stored in the cache.\n     *\n     * Attempting to add an item whose calculated size is greater than\n     * this amount will not cache the item or evict any old items, but\n     * WILL delete an existing value if one is already present.\n     *\n     * Optional, must be a positive integer if provided. Defaults to\n     * the value of `maxSize` if provided.\n     */\n    maxEntrySize?: Size\n\n    /**\n     * A function that returns a number indicating the item's size.\n     *\n     * Requires {@link OptionsBase.maxSize} to be set.\n     *\n     * If not provided, and {@link OptionsBase.maxSize} or\n     * {@link OptionsBase.maxEntrySize} are set, then all\n     * {@link LRUCache#set} calls **must** provide an explicit\n     * {@link SetOptions.size} or sizeCalculation param.\n     */\n    sizeCalculation?: SizeCalculator<K, V>\n\n    /**\n     * Method that provides the implementation for {@link LRUCache#fetch}\n     *\n     * ```ts\n     * fetchMethod(key, staleValue, { signal, options, context })\n     * ```\n     *\n     * If `fetchMethod` is not provided, then `cache.fetch(key)` is equivalent\n     * to `Promise.resolve(cache.get(key))`.\n     *\n     * If at any time, `signal.aborted` is set to `true`, or if the\n     * `signal.onabort` method is called, or if it emits an `'abort'` event\n     * which you can listen to with `addEventListener`, then that means that\n     * the fetch should be abandoned. This may be passed along to async\n     * functions aware of AbortController/AbortSignal behavior.\n     *\n     * The `fetchMethod` should **only** return `undefined` or a Promise\n     * resolving to `undefined` if the AbortController signaled an `abort`\n     * event. In all other cases, it should return or resolve to a value\n     * suitable for adding to the cache.\n     *\n     * The `options` object is a union of the options that may be provided to\n     * `set()` and `get()`. If they are modified, then that will result in\n     * modifying the settings to `cache.set()` when the value is resolved, and\n     * in the case of\n     * {@link OptionsBase.noDeleteOnFetchRejection} and\n     * {@link OptionsBase.allowStaleOnFetchRejection}, the handling of\n     * `fetchMethod` failures.\n     *\n     * For example, a DNS cache may update the TTL based on the value returned\n     * from a remote DNS server by changing `options.ttl` in the `fetchMethod`.\n     */\n    fetchMethod?: Fetcher<K, V, FC>\n\n    /**\n     * Method that provides the implementation for {@link LRUCache#memo}\n     */\n    memoMethod?: Memoizer<K, V, FC>\n\n    /**\n     * Set to true to suppress the deletion of stale data when a\n     * {@link OptionsBase.fetchMethod} returns a rejected promise.\n     */\n    noDeleteOnFetchRejection?: boolean\n\n    /**\n     * Do not delete stale items when they are retrieved with\n     * {@link LRUCache#get}.\n     *\n     * Note that the `get` return value will still be `undefined`\n     * unless {@link OptionsBase.allowStale} is true.\n     *\n     * When using time-expiring entries with `ttl`, by default stale\n     * items will be removed from the cache when the key is accessed\n     * with `cache.get()`.\n     *\n     * Setting this option will cause stale items to remain in the cache, until\n     * they are explicitly deleted with `cache.delete(key)`, or retrieved with\n     * `noDeleteOnStaleGet` set to `false`.\n     *\n     * This may be overridden by passing an options object to `cache.get()`.\n     *\n     * Only relevant if a ttl is used.\n     */\n    noDeleteOnStaleGet?: boolean\n\n    /**\n     * Set to true to allow returning stale data when a\n     * {@link OptionsBase.fetchMethod} throws an error or returns a rejected\n     * promise.\n     *\n     * This differs from using {@link OptionsBase.allowStale} in that stale\n     * data will ONLY be returned in the case that the {@link LRUCache#fetch}\n     * fails, not any other times.\n     *\n     * If a `fetchMethod` fails, and there is no stale value available, the\n     * `fetch()` will resolve to `undefined`. Ie, all `fetchMethod` errors are\n     * suppressed.\n     *\n     * Implies `noDeleteOnFetchRejection`.\n     *\n     * This may be set in calls to `fetch()`, or defaulted on the constructor,\n     * or overridden by modifying the options object in the `fetchMethod`.\n     */\n    allowStaleOnFetchRejection?: boolean\n\n    /**\n     * Set to true to return a stale value from the cache when the\n     * `AbortSignal` passed to the {@link OptionsBase.fetchMethod} dispatches\n     * an `'abort'` event, whether user-triggered, or due to internal cache\n     * behavior.\n     *\n     * Unless {@link OptionsBase.ignoreFetchAbort} is also set, the underlying\n     * {@link OptionsBase.fetchMethod} will still be considered canceled, and\n     * any value it returns will be ignored and not cached.\n     *\n     * Caveat: since fetches are aborted when a new value is explicitly\n     * set in the cache, this can lead to fetch returning a stale value,\n     * since that was the fallback value _at the moment the `fetch()` was\n     * initiated_, even though the new updated value is now present in\n     * the cache.\n     *\n     * For example:\n     *\n     * ```ts\n     * const cache = new LRUCache<string, any>({\n     *   ttl: 100,\n     *   fetchMethod: async (url, oldValue, { signal }) =>  {\n     *     const res = await fetch(url, { signal })\n     *     return await res.json()\n     *   }\n     * })\n     * cache.set('https://example.com/', { some: 'data' })\n     * // 100ms go by...\n     * const result = cache.fetch('https://example.com/')\n     * cache.set('https://example.com/', { other: 'thing' })\n     * console.log(await result) // { some: 'data' }\n     * console.log(cache.get('https://example.com/')) // { other: 'thing' }\n     * ```\n     */\n    allowStaleOnFetchAbort?: boolean\n\n    /**\n     * Set to true to ignore the `abort` event emitted by the `AbortSignal`\n     * object passed to {@link OptionsBase.fetchMethod}, and still cache the\n     * resulting resolution value, as long as it is not `undefined`.\n     *\n     * When used on its own, this means aborted {@link LRUCache#fetch} calls\n     * are not immediately resolved or rejected when they are aborted, and\n     * instead take the full time to await.\n     *\n     * When used with {@link OptionsBase.allowStaleOnFetchAbort}, aborted\n     * {@link LRUCache#fetch} calls will resolve immediately to their stale\n     * cached value or `undefined`, and will continue to process and eventually\n     * update the cache when they resolve, as long as the resulting value is\n     * not `undefined`, thus supporting a \"return stale on timeout while\n     * refreshing\" mechanism by passing `AbortSignal.timeout(n)` as the signal.\n     *\n     * For example:\n     *\n     * ```ts\n     * const c = new LRUCache({\n     *   ttl: 100,\n     *   ignoreFetchAbort: true,\n     *   allowStaleOnFetchAbort: true,\n     *   fetchMethod: async (key, oldValue, { signal }) => {\n     *     // note: do NOT pass the signal to fetch()!\n     *     // let's say this fetch can take a long time.\n     *     const res = await fetch(`https://slow-backend-server/${key}`)\n     *     return await res.json()\n     *   },\n     * })\n     *\n     * // this will return the stale value after 100ms, while still\n     * // updating in the background for next time.\n     * const val = await c.fetch('key', { signal: AbortSignal.timeout(100) })\n     * ```\n     *\n     * **Note**: regardless of this setting, an `abort` event _is still\n     * emitted on the `AbortSignal` object_, so may result in invalid results\n     * when passed to other underlying APIs that use AbortSignals.\n     *\n     * This may be overridden in the {@link OptionsBase.fetchMethod} or the\n     * call to {@link LRUCache#fetch}.\n     */\n    ignoreFetchAbort?: boolean\n  }\n\n  export interface OptionsMaxLimit<K, V, FC>\n    extends OptionsBase<K, V, FC> {\n    max: Count\n  }\n  export interface OptionsTTLLimit<K, V, FC>\n    extends OptionsBase<K, V, FC> {\n    ttl: Milliseconds\n    ttlAutopurge: boolean\n  }\n  export interface OptionsSizeLimit<K, V, FC>\n    extends OptionsBase<K, V, FC> {\n    maxSize: Size\n  }\n\n  /**\n   * The valid safe options for the {@link LRUCache} constructor\n   */\n  export type Options<K, V, FC> =\n    | OptionsMaxLimit<K, V, FC>\n    | OptionsSizeLimit<K, V, FC>\n    | OptionsTTLLimit<K, V, FC>\n\n  /**\n   * Entry objects used by {@link LRUCache#load} and {@link LRUCache#dump},\n   * and returned by {@link LRUCache#info}.\n   */\n  export interface Entry<V> {\n    value: V\n    ttl?: Milliseconds\n    size?: Size\n    start?: Milliseconds\n  }\n}\n\n/**\n * Default export, the thing you're using this module to get.\n *\n * The `K` and `V` types define the key and value types, respectively. The\n * optional `FC` type defines the type of the `context` object passed to\n * `cache.fetch()` and `cache.memo()`.\n *\n * Keys and values **must not** be `null` or `undefined`.\n *\n * All properties from the options object (with the exception of `max`,\n * `maxSize`, `fetchMethod`, `memoMethod`, `dispose` and `disposeAfter`) are\n * added as normal public members. (The listed options are read-only getters.)\n *\n * Changing any of these will alter the defaults for subsequent method calls.\n */\nexport class LRUCache<K extends {}, V extends {}, FC = unknown>\n  implements Map<K, V>\n{\n  // options that cannot be changed without disaster\n  readonly #max: LRUCache.Count\n  readonly #maxSize: LRUCache.Size\n  readonly #dispose?: LRUCache.Disposer<K, V>\n  readonly #disposeAfter?: LRUCache.Disposer<K, V>\n  readonly #fetchMethod?: LRUCache.Fetcher<K, V, FC>\n  readonly #memoMethod?: LRUCache.Memoizer<K, V, FC>\n\n  /**\n   * {@link LRUCache.OptionsBase.ttl}\n   */\n  ttl: LRUCache.Milliseconds\n\n  /**\n   * {@link LRUCache.OptionsBase.ttlResolution}\n   */\n  ttlResolution: LRUCache.Milliseconds\n  /**\n   * {@link LRUCache.OptionsBase.ttlAutopurge}\n   */\n  ttlAutopurge: boolean\n  /**\n   * {@link LRUCache.OptionsBase.updateAgeOnGet}\n   */\n  updateAgeOnGet: boolean\n  /**\n   * {@link LRUCache.OptionsBase.updateAgeOnHas}\n   */\n  updateAgeOnHas: boolean\n  /**\n   * {@link LRUCache.OptionsBase.allowStale}\n   */\n  allowStale: boolean\n\n  /**\n   * {@link LRUCache.OptionsBase.noDisposeOnSet}\n   */\n  noDisposeOnSet: boolean\n  /**\n   * {@link LRUCache.OptionsBase.noUpdateTTL}\n   */\n  noUpdateTTL: boolean\n  /**\n   * {@link LRUCache.OptionsBase.maxEntrySize}\n   */\n  maxEntrySize: LRUCache.Size\n  /**\n   * {@link LRUCache.OptionsBase.sizeCalculation}\n   */\n  sizeCalculation?: LRUCache.SizeCalculator<K, V>\n  /**\n   * {@link LRUCache.OptionsBase.noDeleteOnFetchRejection}\n   */\n  noDeleteOnFetchRejection: boolean\n  /**\n   * {@link LRUCache.OptionsBase.noDeleteOnStaleGet}\n   */\n  noDeleteOnStaleGet: boolean\n  /**\n   * {@link LRUCache.OptionsBase.allowStaleOnFetchAbort}\n   */\n  allowStaleOnFetchAbort: boolean\n  /**\n   * {@link LRUCache.OptionsBase.allowStaleOnFetchRejection}\n   */\n  allowStaleOnFetchRejection: boolean\n  /**\n   * {@link LRUCache.OptionsBase.ignoreFetchAbort}\n   */\n  ignoreFetchAbort: boolean\n\n  // computed properties\n  #size: LRUCache.Count\n  #calculatedSize: LRUCache.Size\n  #keyMap: Map<K, Index>\n  #keyList: (K | undefined)[]\n  #valList: (V | BackgroundFetch<V> | undefined)[]\n  #next: NumberArray\n  #prev: NumberArray\n  #head: Index\n  #tail: Index\n  #free: StackLike\n  #disposed?: DisposeTask<K, V>[]\n  #sizes?: ZeroArray\n  #starts?: ZeroArray\n  #ttls?: ZeroArray\n\n  #hasDispose: boolean\n  #hasFetchMethod: boolean\n  #hasDisposeAfter: boolean\n\n  /**\n   * Do not call this method unless you need to inspect the\n   * inner workings of the cache.  If anything returned by this\n   * object is modified in any way, strange breakage may occur.\n   *\n   * These fields are private for a reason!\n   *\n   * @internal\n   */\n  static unsafeExposeInternals<\n    K extends {},\n    V extends {},\n    FC extends unknown = unknown\n  >(c: LRUCache<K, V, FC>) {\n    return {\n      // properties\n      starts: c.#starts,\n      ttls: c.#ttls,\n      sizes: c.#sizes,\n      keyMap: c.#keyMap as Map<K, number>,\n      keyList: c.#keyList,\n      valList: c.#valList,\n      next: c.#next,\n      prev: c.#prev,\n      get head() {\n        return c.#head\n      },\n      get tail() {\n        return c.#tail\n      },\n      free: c.#free,\n      // methods\n      isBackgroundFetch: (p: any) => c.#isBackgroundFetch(p),\n      backgroundFetch: (\n        k: K,\n        index: number | undefined,\n        options: LRUCache.FetchOptions<K, V, FC>,\n        context: any\n      ): BackgroundFetch<V> =>\n        c.#backgroundFetch(\n          k,\n          index as Index | undefined,\n          options,\n          context\n        ),\n      moveToTail: (index: number): void =>\n        c.#moveToTail(index as Index),\n      indexes: (options?: { allowStale: boolean }) =>\n        c.#indexes(options),\n      rindexes: (options?: { allowStale: boolean }) =>\n        c.#rindexes(options),\n      isStale: (index: number | undefined) =>\n        c.#isStale(index as Index),\n    }\n  }\n\n  // Protected read-only members\n\n  /**\n   * {@link LRUCache.OptionsBase.max} (read-only)\n   */\n  get max(): LRUCache.Count {\n    return this.#max\n  }\n  /**\n   * {@link LRUCache.OptionsBase.maxSize} (read-only)\n   */\n  get maxSize(): LRUCache.Count {\n    return this.#maxSize\n  }\n  /**\n   * The total computed size of items in the cache (read-only)\n   */\n  get calculatedSize(): LRUCache.Size {\n    return this.#calculatedSize\n  }\n  /**\n   * The number of items stored in the cache (read-only)\n   */\n  get size(): LRUCache.Count {\n    return this.#size\n  }\n  /**\n   * {@link LRUCache.OptionsBase.fetchMethod} (read-only)\n   */\n  get fetchMethod(): LRUCache.Fetcher<K, V, FC> | undefined {\n    return this.#fetchMethod\n  }\n  get memoMethod(): LRUCache.Memoizer<K, V, FC> | undefined {\n    return this.#memoMethod\n  }\n  /**\n   * {@link LRUCache.OptionsBase.dispose} (read-only)\n   */\n  get dispose() {\n    return this.#dispose\n  }\n  /**\n   * {@link LRUCache.OptionsBase.disposeAfter} (read-only)\n   */\n  get disposeAfter() {\n    return this.#disposeAfter\n  }\n\n  constructor(\n    options: LRUCache.Options<K, V, FC> | LRUCache<K, V, FC>\n  ) {\n    const {\n      max = 0,\n      ttl,\n      ttlResolution = 1,\n      ttlAutopurge,\n      updateAgeOnGet,\n      updateAgeOnHas,\n      allowStale,\n      dispose,\n      disposeAfter,\n      noDisposeOnSet,\n      noUpdateTTL,\n      maxSize = 0,\n      maxEntrySize = 0,\n      sizeCalculation,\n      fetchMethod,\n      memoMethod,\n      noDeleteOnFetchRejection,\n      noDeleteOnStaleGet,\n      allowStaleOnFetchRejection,\n      allowStaleOnFetchAbort,\n      ignoreFetchAbort,\n    } = options\n\n    if (max !== 0 && !isPosInt(max)) {\n      throw new TypeError('max option must be a nonnegative integer')\n    }\n\n    const UintArray = max ? getUintArray(max) : Array\n    if (!UintArray) {\n      throw new Error('invalid max value: ' + max)\n    }\n\n    this.#max = max\n    this.#maxSize = maxSize\n    this.maxEntrySize = maxEntrySize || this.#maxSize\n    this.sizeCalculation = sizeCalculation\n    if (this.sizeCalculation) {\n      if (!this.#maxSize && !this.maxEntrySize) {\n        throw new TypeError(\n          'cannot set sizeCalculation without setting maxSize or maxEntrySize'\n        )\n      }\n      if (typeof this.sizeCalculation !== 'function') {\n        throw new TypeError('sizeCalculation set to non-function')\n      }\n    }\n\n    if (\n      memoMethod !== undefined &&\n      typeof memoMethod !== 'function'\n    ) {\n      throw new TypeError('memoMethod must be a function if defined')\n    }\n    this.#memoMethod = memoMethod\n\n    if (\n      fetchMethod !== undefined &&\n      typeof fetchMethod !== 'function'\n    ) {\n      throw new TypeError(\n        'fetchMethod must be a function if specified'\n      )\n    }\n    this.#fetchMethod = fetchMethod\n    this.#hasFetchMethod = !!fetchMethod\n\n    this.#keyMap = new Map()\n    this.#keyList = new Array(max).fill(undefined)\n    this.#valList = new Array(max).fill(undefined)\n    this.#next = new UintArray(max)\n    this.#prev = new UintArray(max)\n    this.#head = 0 as Index\n    this.#tail = 0 as Index\n    this.#free = Stack.create(max)\n    this.#size = 0\n    this.#calculatedSize = 0\n\n    if (typeof dispose === 'function') {\n      this.#dispose = dispose\n    }\n    if (typeof disposeAfter === 'function') {\n      this.#disposeAfter = disposeAfter\n      this.#disposed = []\n    } else {\n      this.#disposeAfter = undefined\n      this.#disposed = undefined\n    }\n    this.#hasDispose = !!this.#dispose\n    this.#hasDisposeAfter = !!this.#disposeAfter\n\n    this.noDisposeOnSet = !!noDisposeOnSet\n    this.noUpdateTTL = !!noUpdateTTL\n    this.noDeleteOnFetchRejection = !!noDeleteOnFetchRejection\n    this.allowStaleOnFetchRejection = !!allowStaleOnFetchRejection\n    this.allowStaleOnFetchAbort = !!allowStaleOnFetchAbort\n    this.ignoreFetchAbort = !!ignoreFetchAbort\n\n    // NB: maxEntrySize is set to maxSize if it's set\n    if (this.maxEntrySize !== 0) {\n      if (this.#maxSize !== 0) {\n        if (!isPosInt(this.#maxSize)) {\n          throw new TypeError(\n            'maxSize must be a positive integer if specified'\n          )\n        }\n      }\n      if (!isPosInt(this.maxEntrySize)) {\n        throw new TypeError(\n          'maxEntrySize must be a positive integer if specified'\n        )\n      }\n      this.#initializeSizeTracking()\n    }\n\n    this.allowStale = !!allowStale\n    this.noDeleteOnStaleGet = !!noDeleteOnStaleGet\n    this.updateAgeOnGet = !!updateAgeOnGet\n    this.updateAgeOnHas = !!updateAgeOnHas\n    this.ttlResolution =\n      isPosInt(ttlResolution) || ttlResolution === 0\n        ? ttlResolution\n        : 1\n    this.ttlAutopurge = !!ttlAutopurge\n    this.ttl = ttl || 0\n    if (this.ttl) {\n      if (!isPosInt(this.ttl)) {\n        throw new TypeError(\n          'ttl must be a positive integer if specified'\n        )\n      }\n      this.#initializeTTLTracking()\n    }\n\n    // do not allow completely unbounded caches\n    if (this.#max === 0 && this.ttl === 0 && this.#maxSize === 0) {\n      throw new TypeError(\n        'At least one of max, maxSize, or ttl is required'\n      )\n    }\n    if (!this.ttlAutopurge && !this.#max && !this.#maxSize) {\n      const code = 'LRU_CACHE_UNBOUNDED'\n      if (shouldWarn(code)) {\n        warned.add(code)\n        const msg =\n          'TTL caching without ttlAutopurge, max, or maxSize can ' +\n          'result in unbounded memory consumption.'\n        emitWarning(msg, 'UnboundedCacheWarning', code, LRUCache)\n      }\n    }\n  }\n\n  /**\n   * Return the number of ms left in the item's TTL. If item is not in cache,\n   * returns `0`. Returns `Infinity` if item is in cache without a defined TTL.\n   */\n  getRemainingTTL(key: K) {\n    return this.#keyMap.has(key) ? Infinity : 0\n  }\n\n  #initializeTTLTracking() {\n    const ttls = new ZeroArray(this.#max)\n    const starts = new ZeroArray(this.#max)\n    this.#ttls = ttls\n    this.#starts = starts\n\n    this.#setItemTTL = (index, ttl, start = perf.now()) => {\n      starts[index] = ttl !== 0 ? start : 0\n      ttls[index] = ttl\n      if (ttl !== 0 && this.ttlAutopurge) {\n        const t = setTimeout(() => {\n          if (this.#isStale(index)) {\n            this.#delete(this.#keyList[index] as K, 'expire')\n          }\n        }, ttl + 1)\n        // unref() not supported on all platforms\n        /* c8 ignore start */\n        if (t.unref) {\n          t.unref()\n        }\n        /* c8 ignore stop */\n      }\n    }\n\n    this.#updateItemAge = index => {\n      starts[index] = ttls[index] !== 0 ? perf.now() : 0\n    }\n\n    this.#statusTTL = (status, index) => {\n      if (ttls[index]) {\n        const ttl = ttls[index]\n        const start = starts[index]\n        /* c8 ignore next */\n        if (!ttl || !start) return\n        status.ttl = ttl\n        status.start = start\n        status.now = cachedNow || getNow()\n        const age = status.now - start\n        status.remainingTTL = ttl - age\n      }\n    }\n\n    // debounce calls to perf.now() to 1s so we're not hitting\n    // that costly call repeatedly.\n    let cachedNow = 0\n    const getNow = () => {\n      const n = perf.now()\n      if (this.ttlResolution > 0) {\n        cachedNow = n\n        const t = setTimeout(\n          () => (cachedNow = 0),\n          this.ttlResolution\n        )\n        // not available on all platforms\n        /* c8 ignore start */\n        if (t.unref) {\n          t.unref()\n        }\n        /* c8 ignore stop */\n      }\n      return n\n    }\n\n    this.getRemainingTTL = key => {\n      const index = this.#keyMap.get(key)\n      if (index === undefined) {\n        return 0\n      }\n      const ttl = ttls[index]\n      const start = starts[index]\n      if (!ttl || !start) {\n        return Infinity\n      }\n      const age = (cachedNow || getNow()) - start\n      return ttl - age\n    }\n\n    this.#isStale = index => {\n      const s = starts[index]\n      const t = ttls[index]\n      return !!t && !!s && (cachedNow || getNow()) - s > t\n    }\n  }\n\n  // conditionally set private methods related to TTL\n  #updateItemAge: (index: Index) => void = () => {}\n  #statusTTL: (status: LRUCache.Status<V>, index: Index) => void =\n    () => {}\n  #setItemTTL: (\n    index: Index,\n    ttl: LRUCache.Milliseconds,\n    start?: LRUCache.Milliseconds\n    // ignore because we never call this if we're not already in TTL mode\n    /* c8 ignore start */\n  ) => void = () => {}\n  /* c8 ignore stop */\n\n  #isStale: (index: Index) => boolean = () => false\n\n  #initializeSizeTracking() {\n    const sizes = new ZeroArray(this.#max)\n    this.#calculatedSize = 0\n    this.#sizes = sizes\n    this.#removeItemSize = index => {\n      this.#calculatedSize -= sizes[index] as number\n      sizes[index] = 0\n    }\n    this.#requireSize = (k, v, size, sizeCalculation) => {\n      // provisionally accept background fetches.\n      // actual value size will be checked when they return.\n      if (this.#isBackgroundFetch(v)) {\n        return 0\n      }\n      if (!isPosInt(size)) {\n        if (sizeCalculation) {\n          if (typeof sizeCalculation !== 'function') {\n            throw new TypeError('sizeCalculation must be a function')\n          }\n          size = sizeCalculation(v, k)\n          if (!isPosInt(size)) {\n            throw new TypeError(\n              'sizeCalculation return invalid (expect positive integer)'\n            )\n          }\n        } else {\n          throw new TypeError(\n            'invalid size value (must be positive integer). ' +\n              'When maxSize or maxEntrySize is used, sizeCalculation ' +\n              'or size must be set.'\n          )\n        }\n      }\n      return size\n    }\n    this.#addItemSize = (\n      index: Index,\n      size: LRUCache.Size,\n      status?: LRUCache.Status<V>\n    ) => {\n      sizes[index] = size\n      if (this.#maxSize) {\n        const maxSize = this.#maxSize - (sizes[index] as number)\n        while (this.#calculatedSize > maxSize) {\n          this.#evict(true)\n        }\n      }\n      this.#calculatedSize += sizes[index] as number\n      if (status) {\n        status.entrySize = size\n        status.totalCalculatedSize = this.#calculatedSize\n      }\n    }\n  }\n\n  #removeItemSize: (index: Index) => void = _i => {}\n  #addItemSize: (\n    index: Index,\n    size: LRUCache.Size,\n    status?: LRUCache.Status<V>\n  ) => void = (_i, _s, _st) => {}\n  #requireSize: (\n    k: K,\n    v: V | BackgroundFetch<V>,\n    size?: LRUCache.Size,\n    sizeCalculation?: LRUCache.SizeCalculator<K, V>\n  ) => LRUCache.Size = (\n    _k: K,\n    _v: V | BackgroundFetch<V>,\n    size?: LRUCache.Size,\n    sizeCalculation?: LRUCache.SizeCalculator<K, V>\n  ) => {\n    if (size || sizeCalculation) {\n      throw new TypeError(\n        'cannot set size without setting maxSize or maxEntrySize on cache'\n      )\n    }\n    return 0\n  };\n\n  *#indexes({ allowStale = this.allowStale } = {}) {\n    if (this.#size) {\n      for (let i = this.#tail; true; ) {\n        if (!this.#isValidIndex(i)) {\n          break\n        }\n        if (allowStale || !this.#isStale(i)) {\n          yield i\n        }\n        if (i === this.#head) {\n          break\n        } else {\n          i = this.#prev[i] as Index\n        }\n      }\n    }\n  }\n\n  *#rindexes({ allowStale = this.allowStale } = {}) {\n    if (this.#size) {\n      for (let i = this.#head; true; ) {\n        if (!this.#isValidIndex(i)) {\n          break\n        }\n        if (allowStale || !this.#isStale(i)) {\n          yield i\n        }\n        if (i === this.#tail) {\n          break\n        } else {\n          i = this.#next[i] as Index\n        }\n      }\n    }\n  }\n\n  #isValidIndex(index: Index) {\n    return (\n      index !== undefined &&\n      this.#keyMap.get(this.#keyList[index] as K) === index\n    )\n  }\n\n  /**\n   * Return a generator yielding `[key, value]` pairs,\n   * in order from most recently used to least recently used.\n   */\n  *entries() {\n    for (const i of this.#indexes()) {\n      if (\n        this.#valList[i] !== undefined &&\n        this.#keyList[i] !== undefined &&\n        !this.#isBackgroundFetch(this.#valList[i])\n      ) {\n        yield [this.#keyList[i], this.#valList[i]] as [K, V]\n      }\n    }\n  }\n\n  /**\n   * Inverse order version of {@link LRUCache.entries}\n   *\n   * Return a generator yielding `[key, value]` pairs,\n   * in order from least recently used to most recently used.\n   */\n  *rentries() {\n    for (const i of this.#rindexes()) {\n      if (\n        this.#valList[i] !== undefined &&\n        this.#keyList[i] !== undefined &&\n        !this.#isBackgroundFetch(this.#valList[i])\n      ) {\n        yield [this.#keyList[i], this.#valList[i]]\n      }\n    }\n  }\n\n  /**\n   * Return a generator yielding the keys in the cache,\n   * in order from most recently used to least recently used.\n   */\n  *keys() {\n    for (const i of this.#indexes()) {\n      const k = this.#keyList[i]\n      if (\n        k !== undefined &&\n        !this.#isBackgroundFetch(this.#valList[i])\n      ) {\n        yield k\n      }\n    }\n  }\n\n  /**\n   * Inverse order version of {@link LRUCache.keys}\n   *\n   * Return a generator yielding the keys in the cache,\n   * in order from least recently used to most recently used.\n   */\n  *rkeys() {\n    for (const i of this.#rindexes()) {\n      const k = this.#keyList[i]\n      if (\n        k !== undefined &&\n        !this.#isBackgroundFetch(this.#valList[i])\n      ) {\n        yield k\n      }\n    }\n  }\n\n  /**\n   * Return a generator yielding the values in the cache,\n   * in order from most recently used to least recently used.\n   */\n  *values() {\n    for (const i of this.#indexes()) {\n      const v = this.#valList[i]\n      if (\n        v !== undefined &&\n        !this.#isBackgroundFetch(this.#valList[i])\n      ) {\n        yield this.#valList[i] as V\n      }\n    }\n  }\n\n  /**\n   * Inverse order version of {@link LRUCache.values}\n   *\n   * Return a generator yielding the values in the cache,\n   * in order from least recently used to most recently used.\n   */\n  *rvalues() {\n    for (const i of this.#rindexes()) {\n      const v = this.#valList[i]\n      if (\n        v !== undefined &&\n        !this.#isBackgroundFetch(this.#valList[i])\n      ) {\n        yield this.#valList[i]\n      }\n    }\n  }\n\n  /**\n   * Iterating over the cache itself yields the same results as\n   * {@link LRUCache.entries}\n   */\n  [Symbol.iterator]() {\n    return this.entries()\n  }\n\n  /**\n   * A String value that is used in the creation of the default string\n   * description of an object. Called by the built-in method\n   * `Object.prototype.toString`.\n   */\n  [Symbol.toStringTag] = 'LRUCache'\n\n  /**\n   * Find a value for which the supplied fn method returns a truthy value,\n   * similar to `Array.find()`. fn is called as `fn(value, key, cache)`.\n   */\n  find(\n    fn: (v: V, k: K, self: LRUCache<K, V, FC>) => boolean,\n    getOptions: LRUCache.GetOptions<K, V, FC> = {}\n  ) {\n    for (const i of this.#indexes()) {\n      const v = this.#valList[i]\n      const value = this.#isBackgroundFetch(v)\n        ? v.__staleWhileFetching\n        : v\n      if (value === undefined) continue\n      if (fn(value, this.#keyList[i] as K, this)) {\n        return this.get(this.#keyList[i] as K, getOptions)\n      }\n    }\n  }\n\n  /**\n   * Call the supplied function on each item in the cache, in order from most\n   * recently used to least recently used.\n   *\n   * `fn` is called as `fn(value, key, cache)`.\n   *\n   * If `thisp` is provided, function will be called in the `this`-context of\n   * the provided object, or the cache if no `thisp` object is provided.\n   *\n   * Does not update age or recenty of use, or iterate over stale values.\n   */\n  forEach(\n    fn: (v: V, k: K, self: LRUCache<K, V, FC>) => any,\n    thisp: any = this\n  ) {\n    for (const i of this.#indexes()) {\n      const v = this.#valList[i]\n      const value = this.#isBackgroundFetch(v)\n        ? v.__staleWhileFetching\n        : v\n      if (value === undefined) continue\n      fn.call(thisp, value, this.#keyList[i] as K, this)\n    }\n  }\n\n  /**\n   * The same as {@link LRUCache.forEach} but items are iterated over in\n   * reverse order.  (ie, less recently used items are iterated over first.)\n   */\n  rforEach(\n    fn: (v: V, k: K, self: LRUCache<K, V, FC>) => any,\n    thisp: any = this\n  ) {\n    for (const i of this.#rindexes()) {\n      const v = this.#valList[i]\n      const value = this.#isBackgroundFetch(v)\n        ? v.__staleWhileFetching\n        : v\n      if (value === undefined) continue\n      fn.call(thisp, value, this.#keyList[i] as K, this)\n    }\n  }\n\n  /**\n   * Delete any stale entries. Returns true if anything was removed,\n   * false otherwise.\n   */\n  purgeStale() {\n    let deleted = false\n    for (const i of this.#rindexes({ allowStale: true })) {\n      if (this.#isStale(i)) {\n        this.#delete(this.#keyList[i] as K, 'expire')\n        deleted = true\n      }\n    }\n    return deleted\n  }\n\n  /**\n   * Get the extended info about a given entry, to get its value, size, and\n   * TTL info simultaneously. Returns `undefined` if the key is not present.\n   *\n   * Unlike {@link LRUCache#dump}, which is designed to be portable and survive\n   * serialization, the `start` value is always the current timestamp, and the\n   * `ttl` is a calculated remaining time to live (negative if expired).\n   *\n   * Always returns stale values, if their info is found in the cache, so be\n   * sure to check for expirations (ie, a negative {@link LRUCache.Entry#ttl})\n   * if relevant.\n   */\n  info(key: K): LRUCache.Entry<V> | undefined {\n    const i = this.#keyMap.get(key)\n    if (i === undefined) return undefined\n    const v = this.#valList[i]\n    const value: V | undefined = this.#isBackgroundFetch(v)\n      ? v.__staleWhileFetching\n      : v\n    if (value === undefined) return undefined\n    const entry: LRUCache.Entry<V> = { value }\n    if (this.#ttls && this.#starts) {\n      const ttl = this.#ttls[i]\n      const start = this.#starts[i]\n      if (ttl && start) {\n        const remain = ttl - (perf.now() - start)\n        entry.ttl = remain\n        entry.start = Date.now()\n      }\n    }\n    if (this.#sizes) {\n      entry.size = this.#sizes[i]\n    }\n    return entry\n  }\n\n  /**\n   * Return an array of [key, {@link LRUCache.Entry}] tuples which can be\n   * passed to {@link LRLUCache#load}.\n   *\n   * The `start` fields are calculated relative to a portable `Date.now()`\n   * timestamp, even if `performance.now()` is available.\n   *\n   * Stale entries are always included in the `dump`, even if\n   * {@link LRUCache.OptionsBase.allowStale} is false.\n   *\n   * Note: this returns an actual array, not a generator, so it can be more\n   * easily passed around.\n   */\n  dump() {\n    const arr: [K, LRUCache.Entry<V>][] = []\n    for (const i of this.#indexes({ allowStale: true })) {\n      const key = this.#keyList[i]\n      const v = this.#valList[i]\n      const value: V | undefined = this.#isBackgroundFetch(v)\n        ? v.__staleWhileFetching\n        : v\n      if (value === undefined || key === undefined) continue\n      const entry: LRUCache.Entry<V> = { value }\n      if (this.#ttls && this.#starts) {\n        entry.ttl = this.#ttls[i]\n        // always dump the start relative to a portable timestamp\n        // it's ok for this to be a bit slow, it's a rare operation.\n        const age = perf.now() - (this.#starts[i] as number)\n        entry.start = Math.floor(Date.now() - age)\n      }\n      if (this.#sizes) {\n        entry.size = this.#sizes[i]\n      }\n      arr.unshift([key, entry])\n    }\n    return arr\n  }\n\n  /**\n   * Reset the cache and load in the items in entries in the order listed.\n   *\n   * The shape of the resulting cache may be different if the same options are\n   * not used in both caches.\n   *\n   * The `start` fields are assumed to be calculated relative to a portable\n   * `Date.now()` timestamp, even if `performance.now()` is available.\n   */\n  load(arr: [K, LRUCache.Entry<V>][]) {\n    this.clear()\n    for (const [key, entry] of arr) {\n      if (entry.start) {\n        // entry.start is a portable timestamp, but we may be using\n        // node's performance.now(), so calculate the offset, so that\n        // we get the intended remaining TTL, no matter how long it's\n        // been on ice.\n        //\n        // it's ok for this to be a bit slow, it's a rare operation.\n        const age = Date.now() - entry.start\n        entry.start = perf.now() - age\n      }\n      this.set(key, entry.value, entry)\n    }\n  }\n\n  /**\n   * Add a value to the cache.\n   *\n   * Note: if `undefined` is specified as a value, this is an alias for\n   * {@link LRUCache#delete}\n   *\n   * Fields on the {@link LRUCache.SetOptions} options param will override\n   * their corresponding values in the constructor options for the scope\n   * of this single `set()` operation.\n   *\n   * If `start` is provided, then that will set the effective start\n   * time for the TTL calculation. Note that this must be a previous\n   * value of `performance.now()` if supported, or a previous value of\n   * `Date.now()` if not.\n   *\n   * Options object may also include `size`, which will prevent\n   * calling the `sizeCalculation` function and just use the specified\n   * number if it is a positive integer, and `noDisposeOnSet` which\n   * will prevent calling a `dispose` function in the case of\n   * overwrites.\n   *\n   * If the `size` (or return value of `sizeCalculation`) for a given\n   * entry is greater than `maxEntrySize`, then the item will not be\n   * added to the cache.\n   *\n   * Will update the recency of the entry.\n   *\n   * If the value is `undefined`, then this is an alias for\n   * `cache.delete(key)`. `undefined` is never stored in the cache.\n   */\n  set(\n    k: K,\n    v: V | BackgroundFetch<V> | undefined,\n    setOptions: LRUCache.SetOptions<K, V, FC> = {}\n  ) {\n    if (v === undefined) {\n      this.delete(k)\n      return this\n    }\n    const {\n      ttl = this.ttl,\n      start,\n      noDisposeOnSet = this.noDisposeOnSet,\n      sizeCalculation = this.sizeCalculation,\n      status,\n    } = setOptions\n    let { noUpdateTTL = this.noUpdateTTL } = setOptions\n\n    const size = this.#requireSize(\n      k,\n      v,\n      setOptions.size || 0,\n      sizeCalculation\n    )\n    // if the item doesn't fit, don't do anything\n    // NB: maxEntrySize set to maxSize by default\n    if (this.maxEntrySize && size > this.maxEntrySize) {\n      if (status) {\n        status.set = 'miss'\n        status.maxEntrySizeExceeded = true\n      }\n      // have to delete, in case something is there already.\n      this.#delete(k, 'set')\n      return this\n    }\n    let index = this.#size === 0 ? undefined : this.#keyMap.get(k)\n    if (index === undefined) {\n      // addition\n      index = (\n        this.#size === 0\n          ? this.#tail\n          : this.#free.length !== 0\n          ? this.#free.pop()\n          : this.#size === this.#max\n          ? this.#evict(false)\n          : this.#size\n      ) as Index\n      this.#keyList[index] = k\n      this.#valList[index] = v\n      this.#keyMap.set(k, index)\n      this.#next[this.#tail] = index\n      this.#prev[index] = this.#tail\n      this.#tail = index\n      this.#size++\n      this.#addItemSize(index, size, status)\n      if (status) status.set = 'add'\n      noUpdateTTL = false\n    } else {\n      // update\n      this.#moveToTail(index)\n      const oldVal = this.#valList[index] as V | BackgroundFetch<V>\n      if (v !== oldVal) {\n        if (this.#hasFetchMethod && this.#isBackgroundFetch(oldVal)) {\n          oldVal.__abortController.abort(new Error('replaced'))\n          const { __staleWhileFetching: s } = oldVal\n          if (s !== undefined && !noDisposeOnSet) {\n            if (this.#hasDispose) {\n              this.#dispose?.(s as V, k, 'set')\n            }\n            if (this.#hasDisposeAfter) {\n              this.#disposed?.push([s as V, k, 'set'])\n            }\n          }\n        } else if (!noDisposeOnSet) {\n          if (this.#hasDispose) {\n            this.#dispose?.(oldVal as V, k, 'set')\n          }\n          if (this.#hasDisposeAfter) {\n            this.#disposed?.push([oldVal as V, k, 'set'])\n          }\n        }\n        this.#removeItemSize(index)\n        this.#addItemSize(index, size, status)\n        this.#valList[index] = v\n        if (status) {\n          status.set = 'replace'\n          const oldValue =\n            oldVal && this.#isBackgroundFetch(oldVal)\n              ? oldVal.__staleWhileFetching\n              : oldVal\n          if (oldValue !== undefined) status.oldValue = oldValue\n        }\n      } else if (status) {\n        status.set = 'update'\n      }\n    }\n    if (ttl !== 0 && !this.#ttls) {\n      this.#initializeTTLTracking()\n    }\n    if (this.#ttls) {\n      if (!noUpdateTTL) {\n        this.#setItemTTL(index, ttl, start)\n      }\n      if (status) this.#statusTTL(status, index)\n    }\n    if (!noDisposeOnSet && this.#hasDisposeAfter && this.#disposed) {\n      const dt = this.#disposed\n      let task: DisposeTask<K, V> | undefined\n      while ((task = dt?.shift())) {\n        this.#disposeAfter?.(...task)\n      }\n    }\n    return this\n  }\n\n  /**\n   * Evict the least recently used item, returning its value or\n   * `undefined` if cache is empty.\n   */\n  pop(): V | undefined {\n    try {\n      while (this.#size) {\n        const val = this.#valList[this.#head]\n        this.#evict(true)\n        if (this.#isBackgroundFetch(val)) {\n          if (val.__staleWhileFetching) {\n            return val.__staleWhileFetching\n          }\n        } else if (val !== undefined) {\n          return val\n        }\n      }\n    } finally {\n      if (this.#hasDisposeAfter && this.#disposed) {\n        const dt = this.#disposed\n        let task: DisposeTask<K, V> | undefined\n        while ((task = dt?.shift())) {\n          this.#disposeAfter?.(...task)\n        }\n      }\n    }\n  }\n\n  #evict(free: boolean) {\n    const head = this.#head\n    const k = this.#keyList[head] as K\n    const v = this.#valList[head] as V\n    if (this.#hasFetchMethod && this.#isBackgroundFetch(v)) {\n      v.__abortController.abort(new Error('evicted'))\n    } else if (this.#hasDispose || this.#hasDisposeAfter) {\n      if (this.#hasDispose) {\n        this.#dispose?.(v, k, 'evict')\n      }\n      if (this.#hasDisposeAfter) {\n        this.#disposed?.push([v, k, 'evict'])\n      }\n    }\n    this.#removeItemSize(head)\n    // if we aren't about to use the index, then null these out\n    if (free) {\n      this.#keyList[head] = undefined\n      this.#valList[head] = undefined\n      this.#free.push(head)\n    }\n    if (this.#size === 1) {\n      this.#head = this.#tail = 0 as Index\n      this.#free.length = 0\n    } else {\n      this.#head = this.#next[head] as Index\n    }\n    this.#keyMap.delete(k)\n    this.#size--\n    return head\n  }\n\n  /**\n   * Check if a key is in the cache, without updating the recency of use.\n   * Will return false if the item is stale, even though it is technically\n   * in the cache.\n   *\n   * Check if a key is in the cache, without updating the recency of\n   * use. Age is updated if {@link LRUCache.OptionsBase.updateAgeOnHas} is set\n   * to `true` in either the options or the constructor.\n   *\n   * Will return `false` if the item is stale, even though it is technically in\n   * the cache. The difference can be determined (if it matters) by using a\n   * `status` argument, and inspecting the `has` field.\n   *\n   * Will not update item age unless\n   * {@link LRUCache.OptionsBase.updateAgeOnHas} is set.\n   */\n  has(k: K, hasOptions: LRUCache.HasOptions<K, V, FC> = {}) {\n    const { updateAgeOnHas = this.updateAgeOnHas, status } =\n      hasOptions\n    const index = this.#keyMap.get(k)\n    if (index !== undefined) {\n      const v = this.#valList[index]\n      if (\n        this.#isBackgroundFetch(v) &&\n        v.__staleWhileFetching === undefined\n      ) {\n        return false\n      }\n      if (!this.#isStale(index)) {\n        if (updateAgeOnHas) {\n          this.#updateItemAge(index)\n        }\n        if (status) {\n          status.has = 'hit'\n          this.#statusTTL(status, index)\n        }\n        return true\n      } else if (status) {\n        status.has = 'stale'\n        this.#statusTTL(status, index)\n      }\n    } else if (status) {\n      status.has = 'miss'\n    }\n    return false\n  }\n\n  /**\n   * Like {@link LRUCache#get} but doesn't update recency or delete stale\n   * items.\n   *\n   * Returns `undefined` if the item is stale, unless\n   * {@link LRUCache.OptionsBase.allowStale} is set.\n   */\n  peek(k: K, peekOptions: LRUCache.PeekOptions<K, V, FC> = {}) {\n    const { allowStale = this.allowStale } = peekOptions\n    const index = this.#keyMap.get(k)\n    if (\n      index === undefined ||\n      (!allowStale && this.#isStale(index))\n    ) {\n      return\n    }\n    const v = this.#valList[index]\n    // either stale and allowed, or forcing a refresh of non-stale value\n    return this.#isBackgroundFetch(v) ? v.__staleWhileFetching : v\n  }\n\n  #backgroundFetch(\n    k: K,\n    index: Index | undefined,\n    options: LRUCache.FetchOptions<K, V, FC>,\n    context: any\n  ): BackgroundFetch<V> {\n    const v = index === undefined ? undefined : this.#valList[index]\n    if (this.#isBackgroundFetch(v)) {\n      return v\n    }\n\n    const ac = new AC()\n    const { signal } = options\n    // when/if our AC signals, then stop listening to theirs.\n    signal?.addEventListener('abort', () => ac.abort(signal.reason), {\n      signal: ac.signal,\n    })\n\n    const fetchOpts = {\n      signal: ac.signal,\n      options,\n      context,\n    }\n\n    const cb = (\n      v: V | undefined,\n      updateCache = false\n    ): V | undefined => {\n      const { aborted } = ac.signal\n      const ignoreAbort = options.ignoreFetchAbort && v !== undefined\n      if (options.status) {\n        if (aborted && !updateCache) {\n          options.status.fetchAborted = true\n          options.status.fetchError = ac.signal.reason\n          if (ignoreAbort) options.status.fetchAbortIgnored = true\n        } else {\n          options.status.fetchResolved = true\n        }\n      }\n      if (aborted && !ignoreAbort && !updateCache) {\n        return fetchFail(ac.signal.reason)\n      }\n      // either we didn't abort, and are still here, or we did, and ignored\n      const bf = p as BackgroundFetch<V>\n      if (this.#valList[index as Index] === p) {\n        if (v === undefined) {\n          if (bf.__staleWhileFetching) {\n            this.#valList[index as Index] = bf.__staleWhileFetching\n          } else {\n            this.#delete(k, 'fetch')\n          }\n        } else {\n          if (options.status) options.status.fetchUpdated = true\n          this.set(k, v, fetchOpts.options)\n        }\n      }\n      return v\n    }\n\n    const eb = (er: any) => {\n      if (options.status) {\n        options.status.fetchRejected = true\n        options.status.fetchError = er\n      }\n      return fetchFail(er)\n    }\n\n    const fetchFail = (er: any): V | undefined => {\n      const { aborted } = ac.signal\n      const allowStaleAborted =\n        aborted && options.allowStaleOnFetchAbort\n      const allowStale =\n        allowStaleAborted || options.allowStaleOnFetchRejection\n      const noDelete = allowStale || options.noDeleteOnFetchRejection\n      const bf = p as BackgroundFetch<V>\n      if (this.#valList[index as Index] === p) {\n        // if we allow stale on fetch rejections, then we need to ensure that\n        // the stale value is not removed from the cache when the fetch fails.\n        const del = !noDelete || bf.__staleWhileFetching === undefined\n        if (del) {\n          this.#delete(k, 'fetch')\n        } else if (!allowStaleAborted) {\n          // still replace the *promise* with the stale value,\n          // since we are done with the promise at this point.\n          // leave it untouched if we're still waiting for an\n          // aborted background fetch that hasn't yet returned.\n          this.#valList[index as Index] = bf.__staleWhileFetching\n        }\n      }\n      if (allowStale) {\n        if (options.status && bf.__staleWhileFetching !== undefined) {\n          options.status.returnedStale = true\n        }\n        return bf.__staleWhileFetching\n      } else if (bf.__returned === bf) {\n        throw er\n      }\n    }\n\n    const pcall = (\n      res: (v: V | undefined) => void,\n      rej: (e: any) => void\n    ) => {\n      const fmp = this.#fetchMethod?.(k, v, fetchOpts)\n      if (fmp && fmp instanceof Promise) {\n        fmp.then(v => res(v === undefined ? undefined : v), rej)\n      }\n      // ignored, we go until we finish, regardless.\n      // defer check until we are actually aborting,\n      // so fetchMethod can override.\n      ac.signal.addEventListener('abort', () => {\n        if (\n          !options.ignoreFetchAbort ||\n          options.allowStaleOnFetchAbort\n        ) {\n          res(undefined)\n          // when it eventually resolves, update the cache.\n          if (options.allowStaleOnFetchAbort) {\n            res = v => cb(v, true)\n          }\n        }\n      })\n    }\n\n    if (options.status) options.status.fetchDispatched = true\n    const p = new Promise(pcall).then(cb, eb)\n    const bf: BackgroundFetch<V> = Object.assign(p, {\n      __abortController: ac,\n      __staleWhileFetching: v,\n      __returned: undefined,\n    })\n\n    if (index === undefined) {\n      // internal, don't expose status.\n      this.set(k, bf, { ...fetchOpts.options, status: undefined })\n      index = this.#keyMap.get(k)\n    } else {\n      this.#valList[index] = bf\n    }\n    return bf\n  }\n\n  #isBackgroundFetch(p: any): p is BackgroundFetch<V> {\n    if (!this.#hasFetchMethod) return false\n    const b = p as BackgroundFetch<V>\n    return (\n      !!b &&\n      b instanceof Promise &&\n      b.hasOwnProperty('__staleWhileFetching') &&\n      b.__abortController instanceof AC\n    )\n  }\n\n  /**\n   * Make an asynchronous cached fetch using the\n   * {@link LRUCache.OptionsBase.fetchMethod} function.\n   *\n   * If the value is in the cache and not stale, then the returned\n   * Promise resolves to the value.\n   *\n   * If not in the cache, or beyond its TTL staleness, then\n   * `fetchMethod(key, staleValue, { options, signal, context })` is\n   * called, and the value returned will be added to the cache once\n   * resolved.\n   *\n   * If called with `allowStale`, and an asynchronous fetch is\n   * currently in progress to reload a stale value, then the former\n   * stale value will be returned.\n   *\n   * If called with `forceRefresh`, then the cached item will be\n   * re-fetched, even if it is not stale. However, if `allowStale` is also\n   * set, then the old value will still be returned. This is useful\n   * in cases where you want to force a reload of a cached value. If\n   * a background fetch is already in progress, then `forceRefresh`\n   * has no effect.\n   *\n   * If multiple fetches for the same key are issued, then they will all be\n   * coalesced into a single call to fetchMethod.\n   *\n   * Note that this means that handling options such as\n   * {@link LRUCache.OptionsBase.allowStaleOnFetchAbort},\n   * {@link LRUCache.FetchOptions.signal},\n   * and {@link LRUCache.OptionsBase.allowStaleOnFetchRejection} will be\n   * determined by the FIRST fetch() call for a given key.\n   *\n   * This is a known (fixable) shortcoming which will be addresed on when\n   * someone complains about it, as the fix would involve added complexity and\n   * may not be worth the costs for this edge case.\n   *\n   * If {@link LRUCache.OptionsBase.fetchMethod} is not specified, then this is\n   * effectively an alias for `Promise.resolve(cache.get(key))`.\n   *\n   * When the fetch method resolves to a value, if the fetch has not\n   * been aborted due to deletion, eviction, or being overwritten,\n   * then it is added to the cache using the options provided.\n   *\n   * If the key is evicted or deleted before the `fetchMethod`\n   * resolves, then the AbortSignal passed to the `fetchMethod` will\n   * receive an `abort` event, and the promise returned by `fetch()`\n   * will reject with the reason for the abort.\n   *\n   * If a `signal` is passed to the `fetch()` call, then aborting the\n   * signal will abort the fetch and cause the `fetch()` promise to\n   * reject with the reason provided.\n   *\n   * **Setting `context`**\n   *\n   * If an `FC` type is set to a type other than `unknown`, `void`, or\n   * `undefined` in the {@link LRUCache} constructor, then all\n   * calls to `cache.fetch()` _must_ provide a `context` option. If\n   * set to `undefined` or `void`, then calls to fetch _must not_\n   * provide a `context` option.\n   *\n   * The `context` param allows you to provide arbitrary data that\n   * might be relevant in the course of fetching the data. It is only\n   * relevant for the course of a single `fetch()` operation, and\n   * discarded afterwards.\n   *\n   * **Note: `fetch()` calls are inflight-unique**\n   *\n   * If you call `fetch()` multiple times with the same key value,\n   * then every call after the first will resolve on the same\n   * promise<sup>1</sup>,\n   * _even if they have different settings that would otherwise change\n   * the behavior of the fetch_, such as `noDeleteOnFetchRejection`\n   * or `ignoreFetchAbort`.\n   *\n   * In most cases, this is not a problem (in fact, only fetching\n   * something once is what you probably want, if you're caching in\n   * the first place). If you are changing the fetch() options\n   * dramatically between runs, there's a good chance that you might\n   * be trying to fit divergent semantics into a single object, and\n   * would be better off with multiple cache instances.\n   *\n   * **1**: Ie, they're not the \"same Promise\", but they resolve at\n   * the same time, because they're both waiting on the same\n   * underlying fetchMethod response.\n   */\n\n  fetch(\n    k: K,\n    fetchOptions: unknown extends FC\n      ? LRUCache.FetchOptions<K, V, FC>\n      : FC extends undefined | void\n      ? LRUCache.FetchOptionsNoContext<K, V>\n      : LRUCache.FetchOptionsWithContext<K, V, FC>\n  ): Promise<undefined | V>\n\n  // this overload not allowed if context is required\n  fetch(\n    k: unknown extends FC\n      ? K\n      : FC extends undefined | void\n      ? K\n      : never,\n    fetchOptions?: unknown extends FC\n      ? LRUCache.FetchOptions<K, V, FC>\n      : FC extends undefined | void\n      ? LRUCache.FetchOptionsNoContext<K, V>\n      : never\n  ): Promise<undefined | V>\n\n  async fetch(\n    k: K,\n    fetchOptions: LRUCache.FetchOptions<K, V, FC> = {}\n  ): Promise<undefined | V> {\n    const {\n      // get options\n      allowStale = this.allowStale,\n      updateAgeOnGet = this.updateAgeOnGet,\n      noDeleteOnStaleGet = this.noDeleteOnStaleGet,\n      // set options\n      ttl = this.ttl,\n      noDisposeOnSet = this.noDisposeOnSet,\n      size = 0,\n      sizeCalculation = this.sizeCalculation,\n      noUpdateTTL = this.noUpdateTTL,\n      // fetch exclusive options\n      noDeleteOnFetchRejection = this.noDeleteOnFetchRejection,\n      allowStaleOnFetchRejection = this.allowStaleOnFetchRejection,\n      ignoreFetchAbort = this.ignoreFetchAbort,\n      allowStaleOnFetchAbort = this.allowStaleOnFetchAbort,\n      context,\n      forceRefresh = false,\n      status,\n      signal,\n    } = fetchOptions\n\n    if (!this.#hasFetchMethod) {\n      if (status) status.fetch = 'get'\n      return this.get(k, {\n        allowStale,\n        updateAgeOnGet,\n        noDeleteOnStaleGet,\n        status,\n      })\n    }\n\n    const options = {\n      allowStale,\n      updateAgeOnGet,\n      noDeleteOnStaleGet,\n      ttl,\n      noDisposeOnSet,\n      size,\n      sizeCalculation,\n      noUpdateTTL,\n      noDeleteOnFetchRejection,\n      allowStaleOnFetchRejection,\n      allowStaleOnFetchAbort,\n      ignoreFetchAbort,\n      status,\n      signal,\n    }\n\n    let index = this.#keyMap.get(k)\n    if (index === undefined) {\n      if (status) status.fetch = 'miss'\n      const p = this.#backgroundFetch(k, index, options, context)\n      return (p.__returned = p)\n    } else {\n      // in cache, maybe already fetching\n      const v = this.#valList[index]\n      if (this.#isBackgroundFetch(v)) {\n        const stale =\n          allowStale && v.__staleWhileFetching !== undefined\n        if (status) {\n          status.fetch = 'inflight'\n          if (stale) status.returnedStale = true\n        }\n        return stale ? v.__staleWhileFetching : (v.__returned = v)\n      }\n\n      // if we force a refresh, that means do NOT serve the cached value,\n      // unless we are already in the process of refreshing the cache.\n      const isStale = this.#isStale(index)\n      if (!forceRefresh && !isStale) {\n        if (status) status.fetch = 'hit'\n        this.#moveToTail(index)\n        if (updateAgeOnGet) {\n          this.#updateItemAge(index)\n        }\n        if (status) this.#statusTTL(status, index)\n        return v\n      }\n\n      // ok, it is stale or a forced refresh, and not already fetching.\n      // refresh the cache.\n      const p = this.#backgroundFetch(k, index, options, context)\n      const hasStale = p.__staleWhileFetching !== undefined\n      const staleVal = hasStale && allowStale\n      if (status) {\n        status.fetch = isStale ? 'stale' : 'refresh'\n        if (staleVal && isStale) status.returnedStale = true\n      }\n      return staleVal ? p.__staleWhileFetching : (p.__returned = p)\n    }\n  }\n\n  /**\n   * In some cases, `cache.fetch()` may resolve to `undefined`, either because\n   * a {@link LRUCache.OptionsBase#fetchMethod} was not provided (turning\n   * `cache.fetch(k)` into just an async wrapper around `cache.get(k)`) or\n   * because `ignoreFetchAbort` was specified (either to the constructor or\n   * in the {@link LRUCache.FetchOptions}). Also, the\n   * {@link OptionsBase.fetchMethod} may return `undefined` or `void`, making\n   * the test even more complicated.\n   *\n   * Because inferring the cases where `undefined` might be returned are so\n   * cumbersome, but testing for `undefined` can also be annoying, this method\n   * can be used, which will reject if `this.fetch()` resolves to undefined.\n   */\n  forceFetch(\n    k: K,\n    fetchOptions: unknown extends FC\n      ? LRUCache.FetchOptions<K, V, FC>\n      : FC extends undefined | void\n      ? LRUCache.FetchOptionsNoContext<K, V>\n      : LRUCache.FetchOptionsWithContext<K, V, FC>\n  ): Promise<V>\n  // this overload not allowed if context is required\n  forceFetch(\n    k: unknown extends FC\n      ? K\n      : FC extends undefined | void\n      ? K\n      : never,\n    fetchOptions?: unknown extends FC\n      ? LRUCache.FetchOptions<K, V, FC>\n      : FC extends undefined | void\n      ? LRUCache.FetchOptionsNoContext<K, V>\n      : never\n  ): Promise<V>\n  async forceFetch(\n    k: K,\n    fetchOptions: LRUCache.FetchOptions<K, V, FC> = {}\n  ): Promise<V> {\n    const v = await this.fetch(\n      k,\n      fetchOptions as unknown extends FC\n        ? LRUCache.FetchOptions<K, V, FC>\n        : FC extends undefined | void\n        ? LRUCache.FetchOptionsNoContext<K, V>\n        : LRUCache.FetchOptionsWithContext<K, V, FC>\n    )\n    if (v === undefined) throw new Error('fetch() returned undefined')\n    return v\n  }\n\n  /**\n   * If the key is found in the cache, then this is equivalent to\n   * {@link LRUCache#get}. If not, in the cache, then calculate the value using\n   * the {@link LRUCache.OptionsBase.memoMethod}, and add it to the cache.\n   *\n   * If an `FC` type is set to a type other than `unknown`, `void`, or\n   * `undefined` in the LRUCache constructor, then all calls to `cache.memo()`\n   * _must_ provide a `context` option. If set to `undefined` or `void`, then\n   * calls to memo _must not_ provide a `context` option.\n   *\n   * The `context` param allows you to provide arbitrary data that might be\n   * relevant in the course of fetching the data. It is only relevant for the\n   * course of a single `memo()` operation, and discarded afterwards.\n   */\n  memo(\n    k: K,\n    memoOptions: unknown extends FC\n      ? LRUCache.MemoOptions<K, V, FC>\n      : FC extends undefined | void\n      ? LRUCache.MemoOptionsNoContext<K, V>\n      : LRUCache.MemoOptionsWithContext<K, V, FC>\n  ): V\n  // this overload not allowed if context is required\n  memo(\n    k: unknown extends FC\n      ? K\n      : FC extends undefined | void\n      ? K\n      : never,\n    memoOptions?: unknown extends FC\n      ? LRUCache.MemoOptions<K, V, FC>\n      : FC extends undefined | void\n      ? LRUCache.MemoOptionsNoContext<K, V>\n      : never\n  ): V\n  memo(k: K, memoOptions: LRUCache.MemoOptions<K, V, FC> = {}) {\n    const memoMethod = this.#memoMethod\n    if (!memoMethod) {\n      throw new Error('no memoMethod provided to constructor')\n    }\n    const { context, forceRefresh, ...options } = memoOptions\n    const v = this.get(k, options)\n    if (!forceRefresh && v !== undefined) return v\n    const vv = memoMethod(k, v, {\n      options,\n      context,\n    } as LRUCache.MemoizerOptions<K, V, FC>)\n    this.set(k, vv, options)\n    return vv\n  }\n\n  /**\n   * Return a value from the cache. Will update the recency of the cache\n   * entry found.\n   *\n   * If the key is not found, get() will return `undefined`.\n   */\n  get(k: K, getOptions: LRUCache.GetOptions<K, V, FC> = {}) {\n    const {\n      allowStale = this.allowStale,\n      updateAgeOnGet = this.updateAgeOnGet,\n      noDeleteOnStaleGet = this.noDeleteOnStaleGet,\n      status,\n    } = getOptions\n    const index = this.#keyMap.get(k)\n    if (index !== undefined) {\n      const value = this.#valList[index]\n      const fetching = this.#isBackgroundFetch(value)\n      if (status) this.#statusTTL(status, index)\n      if (this.#isStale(index)) {\n        if (status) status.get = 'stale'\n        // delete only if not an in-flight background fetch\n        if (!fetching) {\n          if (!noDeleteOnStaleGet) {\n            this.#delete(k, 'expire')\n          }\n          if (status && allowStale) status.returnedStale = true\n          return allowStale ? value : undefined\n        } else {\n          if (\n            status &&\n            allowStale &&\n            value.__staleWhileFetching !== undefined\n          ) {\n            status.returnedStale = true\n          }\n          return allowStale ? value.__staleWhileFetching : undefined\n        }\n      } else {\n        if (status) status.get = 'hit'\n        // if we're currently fetching it, we don't actually have it yet\n        // it's not stale, which means this isn't a staleWhileRefetching.\n        // If it's not stale, and fetching, AND has a __staleWhileFetching\n        // value, then that means the user fetched with {forceRefresh:true},\n        // so it's safe to return that value.\n        if (fetching) {\n          return value.__staleWhileFetching\n        }\n        this.#moveToTail(index)\n        if (updateAgeOnGet) {\n          this.#updateItemAge(index)\n        }\n        return value\n      }\n    } else if (status) {\n      status.get = 'miss'\n    }\n  }\n\n  #connect(p: Index, n: Index) {\n    this.#prev[n] = p\n    this.#next[p] = n\n  }\n\n  #moveToTail(index: Index): void {\n    // if tail already, nothing to do\n    // if head, move head to next[index]\n    // else\n    //   move next[prev[index]] to next[index] (head has no prev)\n    //   move prev[next[index]] to prev[index]\n    // prev[index] = tail\n    // next[tail] = index\n    // tail = index\n    if (index !== this.#tail) {\n      if (index === this.#head) {\n        this.#head = this.#next[index] as Index\n      } else {\n        this.#connect(\n          this.#prev[index] as Index,\n          this.#next[index] as Index\n        )\n      }\n      this.#connect(this.#tail, index)\n      this.#tail = index\n    }\n  }\n\n  /**\n   * Deletes a key out of the cache.\n   *\n   * Returns true if the key was deleted, false otherwise.\n   */\n  delete(k: K) {\n    return this.#delete(k, 'delete')\n  }\n\n  #delete(k: K, reason: LRUCache.DisposeReason) {\n    let deleted = false\n    if (this.#size !== 0) {\n      const index = this.#keyMap.get(k)\n      if (index !== undefined) {\n        deleted = true\n        if (this.#size === 1) {\n          this.#clear(reason)\n        } else {\n          this.#removeItemSize(index)\n          const v = this.#valList[index]\n          if (this.#isBackgroundFetch(v)) {\n            v.__abortController.abort(new Error('deleted'))\n          } else if (this.#hasDispose || this.#hasDisposeAfter) {\n            if (this.#hasDispose) {\n              this.#dispose?.(v as V, k, reason)\n            }\n            if (this.#hasDisposeAfter) {\n              this.#disposed?.push([v as V, k, reason])\n            }\n          }\n          this.#keyMap.delete(k)\n          this.#keyList[index] = undefined\n          this.#valList[index] = undefined\n          if (index === this.#tail) {\n            this.#tail = this.#prev[index] as Index\n          } else if (index === this.#head) {\n            this.#head = this.#next[index] as Index\n          } else {\n            const pi = this.#prev[index] as number\n            this.#next[pi] = this.#next[index] as number\n            const ni = this.#next[index] as number\n            this.#prev[ni] = this.#prev[index] as number\n          }\n          this.#size--\n          this.#free.push(index)\n        }\n      }\n    }\n    if (this.#hasDisposeAfter && this.#disposed?.length) {\n      const dt = this.#disposed\n      let task: DisposeTask<K, V> | undefined\n      while ((task = dt?.shift())) {\n        this.#disposeAfter?.(...task)\n      }\n    }\n    return deleted\n  }\n\n  /**\n   * Clear the cache entirely, throwing away all values.\n   */\n  clear() {\n    return this.#clear('delete')\n  }\n  #clear(reason: LRUCache.DisposeReason) {\n    for (const index of this.#rindexes({ allowStale: true })) {\n      const v = this.#valList[index]\n      if (this.#isBackgroundFetch(v)) {\n        v.__abortController.abort(new Error('deleted'))\n      } else {\n        const k = this.#keyList[index]\n        if (this.#hasDispose) {\n          this.#dispose?.(v as V, k as K, reason)\n        }\n        if (this.#hasDisposeAfter) {\n          this.#disposed?.push([v as V, k as K, reason])\n        }\n      }\n    }\n\n    this.#keyMap.clear()\n    this.#valList.fill(undefined)\n    this.#keyList.fill(undefined)\n    if (this.#ttls && this.#starts) {\n      this.#ttls.fill(0)\n      this.#starts.fill(0)\n    }\n    if (this.#sizes) {\n      this.#sizes.fill(0)\n    }\n    this.#head = 0 as Index\n    this.#tail = 0 as Index\n    this.#free.length = 0\n    this.#calculatedSize = 0\n    this.#size = 0\n    if (this.#hasDisposeAfter && this.#disposed) {\n      const dt = this.#disposed\n      let task: DisposeTask<K, V> | undefined\n      while ((task = dt?.shift())) {\n        this.#disposeAfter?.(...task)\n      }\n    }\n  }\n}\n"],"mappings":"AAAA;;;AAMA,MAAMA,IAAI,GACR,OAAOC,WAAW,KAAK,QAAQ,IAC/BA,WAAW,IACX,OAAOA,WAAW,CAACC,GAAG,KAAK,UAAU,GACjCD,WAAW,GACXE,IAAI;AAEV,MAAMC,MAAM,GAAG,IAAIC,GAAG,EAAU;AAKhC;AACA,MAAMC,OAAO,GACX,OAAOC,OAAO,KAAK,QAAQ,IAAI,CAAC,CAACA,OAAO,GAAGA,OAAO,GAAG,EAC9B;AACzB;AAEA,MAAMC,WAAW,GAAGA,CAClBC,GAAW,EACXC,IAAY,EACZC,IAAY,EACZC,EAAQ,KACN;EACF,OAAON,OAAO,CAACE,WAAW,KAAK,UAAU,GACrCF,OAAO,CAACE,WAAW,CAACC,GAAG,EAAEC,IAAI,EAAEC,IAAI,EAAEC,EAAE,CAAC,GACxCC,OAAO,CAACC,KAAK,CAAC,IAAIH,IAAI,KAAKD,IAAI,KAAKD,GAAG,EAAE,CAAC;AAChD,CAAC;AAED,IAAIM,EAAE,GAAGC,UAAU,CAACC,eAAe;AACnC,IAAIC,EAAE,GAAGF,UAAU,CAACG,WAAW;AAE/B;AACA,IAAI,OAAOJ,EAAE,KAAK,WAAW,EAAE;EAC7B;EACAG,EAAE,GAAG,MAAMC,WAAW;IACpBC,OAAO;IACPC,QAAQ,GAA6B,EAAE;IACvCC,MAAM;IACNC,OAAO,GAAY,KAAK;IACxBC,gBAAgBA,CAACC,CAAS,EAAEb,EAAwB;MAClD,IAAI,CAACS,QAAQ,CAACK,IAAI,CAACd,EAAE,CAAC;IACxB;GACD;EACD;EACAG,EAAE,GAAG,MAAME,eAAe;IACxBU,YAAA;MACEC,cAAc,EAAE;IAClB;IACAC,MAAM,GAAG,IAAIX,EAAE,EAAE;IACjBY,KAAKA,CAACR,MAAW;MACf,IAAI,IAAI,CAACO,MAAM,CAACN,OAAO,EAAE;MACzB;MACA,IAAI,CAACM,MAAM,CAACP,MAAM,GAAGA,MAAM;MAC3B;MACA,IAAI,CAACO,MAAM,CAACN,OAAO,GAAG,IAAI;MAC1B;MACA,KAAK,MAAMX,EAAE,IAAI,IAAI,CAACiB,MAAM,CAACR,QAAQ,EAAE;QACrCT,EAAE,CAACU,MAAM,CAAC;;MAEZ,IAAI,CAACO,MAAM,CAACT,OAAO,GAAGE,MAAM,CAAC;IAC/B;GACD;EACD,IAAIS,sBAAsB,GACxBzB,OAAO,CAAC0B,GAAG,EAAEC,2BAA2B,KAAK,GAAG;EAClD,MAAML,cAAc,GAAGA,CAAA,KAAK;IAC1B,IAAI,CAACG,sBAAsB,EAAE;IAC7BA,sBAAsB,GAAG,KAAK;IAC9BvB,WAAW,CACT,wDAAwD,GACtD,qDAAqD,GACrD,yDAAyD,GACzD,6DAA6D,GAC7D,mEAAmE,GACnE,mEAAmE,GACnE,qEAAqE,EACvE,qBAAqB,EACrB,SAAS,EACToB,cAAc,CACf;EACH,CAAC;;AAEH;AAEA,MAAMM,UAAU,GAAIvB,IAAY,IAAK,CAACP,MAAM,CAAC+B,GAAG,CAACxB,IAAI,CAAC;AAEtD,MAAMyB,IAAI,GAAGC,MAAM,CAAC,MAAM,CAAC;AAI3B,MAAMC,QAAQ,GAAIC,CAAM,IACtBA,CAAC,IAAIA,CAAC,KAAKC,IAAI,CAACC,KAAK,CAACF,CAAC,CAAC,IAAIA,CAAC,GAAG,CAAC,IAAIG,QAAQ,CAACH,CAAC,CAAC;AAKlD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAMI,YAAY,GAAIC,GAAW,IAC/B,CAACN,QAAQ,CAACM,GAAG,CAAC,GACV,IAAI,GACJA,GAAG,IAAIJ,IAAI,CAACK,GAAG,CAAC,CAAC,EAAE,CAAC,CAAC,GACrBC,UAAU,GACVF,GAAG,IAAIJ,IAAI,CAACK,GAAG,CAAC,CAAC,EAAE,EAAE,CAAC,GACtBE,WAAW,GACXH,GAAG,IAAIJ,IAAI,CAACK,GAAG,CAAC,CAAC,EAAE,EAAE,CAAC,GACtBG,WAAW,GACXJ,GAAG,IAAIK,MAAM,CAACC,gBAAgB,GAC9BC,SAAS,GACT,IAAI;AACV;AAEA,MAAMA,SAAU,SAAQC,KAAa;EACnCzB,YAAY0B,IAAY;IACtB,KAAK,CAACA,IAAI,CAAC;IACX,IAAI,CAACC,IAAI,CAAC,CAAC,CAAC;EACd;;AAMF,MAAMC,KAAK;EACTC,IAAI;EACJC,MAAM;EACN;EACA,OAAO,CAAAC,YAAa,GAAY,KAAK;EACrC,OAAOC,MAAMA,CAACf,GAAW;IACvB,MAAMgB,OAAO,GAAGjB,YAAY,CAACC,GAAG,CAAC;IACjC,IAAI,CAACgB,OAAO,EAAE,OAAO,EAAE;IACvBL,KAAK,CAAC,CAAAG,YAAa,GAAG,IAAI;IAC1B,MAAMG,CAAC,GAAG,IAAIN,KAAK,CAACX,GAAG,EAAEgB,OAAO,CAAC;IACjCL,KAAK,CAAC,CAAAG,YAAa,GAAG,KAAK;IAC3B,OAAOG,CAAC;EACV;EACAlC,YACEiB,GAAW,EACXgB,OAAyC;IAEzC;IACA,IAAI,CAACL,KAAK,CAAC,CAAAG,YAAa,EAAE;MACxB,MAAM,IAAII,SAAS,CAAC,yCAAyC,CAAC;;IAEhE;IACA,IAAI,CAACN,IAAI,GAAG,IAAII,OAAO,CAAChB,GAAG,CAAC;IAC5B,IAAI,CAACa,MAAM,GAAG,CAAC;EACjB;EACA/B,IAAIA,CAACa,CAAQ;IACX,IAAI,CAACiB,IAAI,CAAC,IAAI,CAACC,MAAM,EAAE,CAAC,GAAGlB,CAAC;EAC9B;EACAwB,GAAGA,CAAA;IACD,OAAO,IAAI,CAACP,IAAI,CAAC,EAAE,IAAI,CAACC,MAAM,CAAU;EAC1C;;AAw6BF;;;;;;;;;;;;;;;AAeA,OAAM,MAAOO,QAAQ;EAGnB;EACS,CAAApB,GAAI;EACJ,CAAAqB,OAAQ;EACR,CAAAC,OAAQ;EACR,CAAAC,YAAa;EACb,CAAAC,WAAY;EACZ,CAAAC,UAAW;EAEpB;;;EAGAC,GAAG;EAEH;;;EAGAC,aAAa;EACb;;;EAGAC,YAAY;EACZ;;;EAGAC,cAAc;EACd;;;EAGAC,cAAc;EACd;;;EAGAC,UAAU;EAEV;;;EAGAC,cAAc;EACd;;;EAGAC,WAAW;EACX;;;EAGAC,YAAY;EACZ;;;EAGAC,eAAe;EACf;;;EAGAC,wBAAwB;EACxB;;;EAGAC,kBAAkB;EAClB;;;EAGAC,sBAAsB;EACtB;;;EAGAC,0BAA0B;EAC1B;;;EAGAC,gBAAgB;EAEhB;EACA,CAAA/B,IAAK;EACL,CAAAgC,cAAe;EACf,CAAAC,MAAO;EACP,CAAAC,OAAQ;EACR,CAAAC,OAAQ;EACR,CAAAC,IAAK;EACL,CAAAC,IAAK;EACL,CAAAC,IAAK;EACL,CAAAC,IAAK;EACL,CAAAC,IAAK;EACL,CAAAC,QAAS;EACT,CAAAC,KAAM;EACN,CAAAC,MAAO;EACP,CAAAC,IAAK;EAEL,CAAAC,UAAW;EACX,CAAAC,cAAe;EACf,CAAAC,eAAgB;EAEhB;;;;;;;;;EASA,OAAOC,qBAAqBA,CAI1BC,CAAqB;IACrB,OAAO;MACL;MACAN,MAAM,EAAEM,CAAC,CAAC,CAAAN,MAAO;MACjBC,IAAI,EAAEK,CAAC,CAAC,CAAAL,IAAK;MACbF,KAAK,EAAEO,CAAC,CAAC,CAAAP,KAAM;MACfT,MAAM,EAAEgB,CAAC,CAAC,CAAAhB,MAAyB;MACnCC,OAAO,EAAEe,CAAC,CAAC,CAAAf,OAAQ;MACnBC,OAAO,EAAEc,CAAC,CAAC,CAAAd,OAAQ;MACnBC,IAAI,EAAEa,CAAC,CAAC,CAAAb,IAAK;MACbC,IAAI,EAAEY,CAAC,CAAC,CAAAZ,IAAK;MACb,IAAIC,IAAIA,CAAA;QACN,OAAOW,CAAC,CAAC,CAAAX,IAAK;MAChB,CAAC;MACD,IAAIC,IAAIA,CAAA;QACN,OAAOU,CAAC,CAAC,CAAAV,IAAK;MAChB,CAAC;MACDC,IAAI,EAAES,CAAC,CAAC,CAAAT,IAAK;MACb;MACAU,iBAAiB,EAAGC,CAAM,IAAKF,CAAC,CAAC,CAAAC,iBAAkB,CAACC,CAAC,CAAC;MACtDC,eAAe,EAAEA,CACfC,CAAI,EACJC,KAAyB,EACzBC,OAAwC,EACxCC,OAAY,KAEZP,CAAC,CAAC,CAAAG,eAAgB,CAChBC,CAAC,EACDC,KAA0B,EAC1BC,OAAO,EACPC,OAAO,CACR;MACHC,UAAU,EAAGH,KAAa,IACxBL,CAAC,CAAC,CAAAQ,UAAW,CAACH,KAAc,CAAC;MAC/BI,OAAO,EAAGH,OAAiC,IACzCN,CAAC,CAAC,CAAAS,OAAQ,CAACH,OAAO,CAAC;MACrBI,QAAQ,EAAGJ,OAAiC,IAC1CN,CAAC,CAAC,CAAAU,QAAS,CAACJ,OAAO,CAAC;MACtBK,OAAO,EAAGN,KAAyB,IACjCL,CAAC,CAAC,CAAAW,OAAQ,CAACN,KAAc;KAC5B;EACH;EAEA;EAEA;;;EAGA,IAAI/D,GAAGA,CAAA;IACL,OAAO,IAAI,CAAC,CAAAA,GAAI;EAClB;EACA;;;EAGA,IAAIqB,OAAOA,CAAA;IACT,OAAO,IAAI,CAAC,CAAAA,OAAQ;EACtB;EACA;;;EAGA,IAAIoB,cAAcA,CAAA;IAChB,OAAO,IAAI,CAAC,CAAAA,cAAe;EAC7B;EACA;;;EAGA,IAAIhC,IAAIA,CAAA;IACN,OAAO,IAAI,CAAC,CAAAA,IAAK;EACnB;EACA;;;EAGA,IAAIe,WAAWA,CAAA;IACb,OAAO,IAAI,CAAC,CAAAA,WAAY;EAC1B;EACA,IAAIC,UAAUA,CAAA;IACZ,OAAO,IAAI,CAAC,CAAAA,UAAW;EACzB;EACA;;;EAGA,IAAIH,OAAOA,CAAA;IACT,OAAO,IAAI,CAAC,CAAAA,OAAQ;EACtB;EACA;;;EAGA,IAAIC,YAAYA,CAAA;IACd,OAAO,IAAI,CAAC,CAAAA,YAAa;EAC3B;EAEAxC,YACEiF,OAAwD;IAExD,MAAM;MACJhE,GAAG,GAAG,CAAC;MACP0B,GAAG;MACHC,aAAa,GAAG,CAAC;MACjBC,YAAY;MACZC,cAAc;MACdC,cAAc;MACdC,UAAU;MACVT,OAAO;MACPC,YAAY;MACZS,cAAc;MACdC,WAAW;MACXZ,OAAO,GAAG,CAAC;MACXa,YAAY,GAAG,CAAC;MAChBC,eAAe;MACfX,WAAW;MACXC,UAAU;MACVW,wBAAwB;MACxBC,kBAAkB;MAClBE,0BAA0B;MAC1BD,sBAAsB;MACtBE;IAAgB,CACjB,GAAGwB,OAAO;IAEX,IAAIhE,GAAG,KAAK,CAAC,IAAI,CAACN,QAAQ,CAACM,GAAG,CAAC,EAAE;MAC/B,MAAM,IAAIkB,SAAS,CAAC,0CAA0C,CAAC;;IAGjE,MAAMoD,SAAS,GAAGtE,GAAG,GAAGD,YAAY,CAACC,GAAG,CAAC,GAAGQ,KAAK;IACjD,IAAI,CAAC8D,SAAS,EAAE;MACd,MAAM,IAAIC,KAAK,CAAC,qBAAqB,GAAGvE,GAAG,CAAC;;IAG9C,IAAI,CAAC,CAAAA,GAAI,GAAGA,GAAG;IACf,IAAI,CAAC,CAAAqB,OAAQ,GAAGA,OAAO;IACvB,IAAI,CAACa,YAAY,GAAGA,YAAY,IAAI,IAAI,CAAC,CAAAb,OAAQ;IACjD,IAAI,CAACc,eAAe,GAAGA,eAAe;IACtC,IAAI,IAAI,CAACA,eAAe,EAAE;MACxB,IAAI,CAAC,IAAI,CAAC,CAAAd,OAAQ,IAAI,CAAC,IAAI,CAACa,YAAY,EAAE;QACxC,MAAM,IAAIhB,SAAS,CACjB,oEAAoE,CACrE;;MAEH,IAAI,OAAO,IAAI,CAACiB,eAAe,KAAK,UAAU,EAAE;QAC9C,MAAM,IAAIjB,SAAS,CAAC,qCAAqC,CAAC;;;IAI9D,IACEO,UAAU,KAAK+C,SAAS,IACxB,OAAO/C,UAAU,KAAK,UAAU,EAChC;MACA,MAAM,IAAIP,SAAS,CAAC,0CAA0C,CAAC;;IAEjE,IAAI,CAAC,CAAAO,UAAW,GAAGA,UAAU;IAE7B,IACED,WAAW,KAAKgD,SAAS,IACzB,OAAOhD,WAAW,KAAK,UAAU,EACjC;MACA,MAAM,IAAIN,SAAS,CACjB,6CAA6C,CAC9C;;IAEH,IAAI,CAAC,CAAAM,WAAY,GAAGA,WAAW;IAC/B,IAAI,CAAC,CAAA+B,cAAe,GAAG,CAAC,CAAC/B,WAAW;IAEpC,IAAI,CAAC,CAAAkB,MAAO,GAAG,IAAI+B,GAAG,EAAE;IACxB,IAAI,CAAC,CAAA9B,OAAQ,GAAG,IAAInC,KAAK,CAACR,GAAG,CAAC,CAACU,IAAI,CAAC8D,SAAS,CAAC;IAC9C,IAAI,CAAC,CAAA5B,OAAQ,GAAG,IAAIpC,KAAK,CAACR,GAAG,CAAC,CAACU,IAAI,CAAC8D,SAAS,CAAC;IAC9C,IAAI,CAAC,CAAA3B,IAAK,GAAG,IAAIyB,SAAS,CAACtE,GAAG,CAAC;IAC/B,IAAI,CAAC,CAAA8C,IAAK,GAAG,IAAIwB,SAAS,CAACtE,GAAG,CAAC;IAC/B,IAAI,CAAC,CAAA+C,IAAK,GAAG,CAAU;IACvB,IAAI,CAAC,CAAAC,IAAK,GAAG,CAAU;IACvB,IAAI,CAAC,CAAAC,IAAK,GAAGtC,KAAK,CAACI,MAAM,CAACf,GAAG,CAAC;IAC9B,IAAI,CAAC,CAAAS,IAAK,GAAG,CAAC;IACd,IAAI,CAAC,CAAAgC,cAAe,GAAG,CAAC;IAExB,IAAI,OAAOnB,OAAO,KAAK,UAAU,EAAE;MACjC,IAAI,CAAC,CAAAA,OAAQ,GAAGA,OAAO;;IAEzB,IAAI,OAAOC,YAAY,KAAK,UAAU,EAAE;MACtC,IAAI,CAAC,CAAAA,YAAa,GAAGA,YAAY;MACjC,IAAI,CAAC,CAAA2B,QAAS,GAAG,EAAE;KACpB,MAAM;MACL,IAAI,CAAC,CAAA3B,YAAa,GAAGiD,SAAS;MAC9B,IAAI,CAAC,CAAAtB,QAAS,GAAGsB,SAAS;;IAE5B,IAAI,CAAC,CAAAlB,UAAW,GAAG,CAAC,CAAC,IAAI,CAAC,CAAAhC,OAAQ;IAClC,IAAI,CAAC,CAAAkC,eAAgB,GAAG,CAAC,CAAC,IAAI,CAAC,CAAAjC,YAAa;IAE5C,IAAI,CAACS,cAAc,GAAG,CAAC,CAACA,cAAc;IACtC,IAAI,CAACC,WAAW,GAAG,CAAC,CAACA,WAAW;IAChC,IAAI,CAACG,wBAAwB,GAAG,CAAC,CAACA,wBAAwB;IAC1D,IAAI,CAACG,0BAA0B,GAAG,CAAC,CAACA,0BAA0B;IAC9D,IAAI,CAACD,sBAAsB,GAAG,CAAC,CAACA,sBAAsB;IACtD,IAAI,CAACE,gBAAgB,GAAG,CAAC,CAACA,gBAAgB;IAE1C;IACA,IAAI,IAAI,CAACN,YAAY,KAAK,CAAC,EAAE;MAC3B,IAAI,IAAI,CAAC,CAAAb,OAAQ,KAAK,CAAC,EAAE;QACvB,IAAI,CAAC3B,QAAQ,CAAC,IAAI,CAAC,CAAA2B,OAAQ,CAAC,EAAE;UAC5B,MAAM,IAAIH,SAAS,CACjB,iDAAiD,CAClD;;;MAGL,IAAI,CAACxB,QAAQ,CAAC,IAAI,CAACwC,YAAY,CAAC,EAAE;QAChC,MAAM,IAAIhB,SAAS,CACjB,sDAAsD,CACvD;;MAEH,IAAI,CAAC,CAAAwD,sBAAuB,EAAE;;IAGhC,IAAI,CAAC3C,UAAU,GAAG,CAAC,CAACA,UAAU;IAC9B,IAAI,CAACM,kBAAkB,GAAG,CAAC,CAACA,kBAAkB;IAC9C,IAAI,CAACR,cAAc,GAAG,CAAC,CAACA,cAAc;IACtC,IAAI,CAACC,cAAc,GAAG,CAAC,CAACA,cAAc;IACtC,IAAI,CAACH,aAAa,GAChBjC,QAAQ,CAACiC,aAAa,CAAC,IAAIA,aAAa,KAAK,CAAC,GAC1CA,aAAa,GACb,CAAC;IACP,IAAI,CAACC,YAAY,GAAG,CAAC,CAACA,YAAY;IAClC,IAAI,CAACF,GAAG,GAAGA,GAAG,IAAI,CAAC;IACnB,IAAI,IAAI,CAACA,GAAG,EAAE;MACZ,IAAI,CAAChC,QAAQ,CAAC,IAAI,CAACgC,GAAG,CAAC,EAAE;QACvB,MAAM,IAAIR,SAAS,CACjB,6CAA6C,CAC9C;;MAEH,IAAI,CAAC,CAAAyD,qBAAsB,EAAE;;IAG/B;IACA,IAAI,IAAI,CAAC,CAAA3E,GAAI,KAAK,CAAC,IAAI,IAAI,CAAC0B,GAAG,KAAK,CAAC,IAAI,IAAI,CAAC,CAAAL,OAAQ,KAAK,CAAC,EAAE;MAC5D,MAAM,IAAIH,SAAS,CACjB,kDAAkD,CACnD;;IAEH,IAAI,CAAC,IAAI,CAACU,YAAY,IAAI,CAAC,IAAI,CAAC,CAAA5B,GAAI,IAAI,CAAC,IAAI,CAAC,CAAAqB,OAAQ,EAAE;MACtD,MAAMtD,IAAI,GAAG,qBAAqB;MAClC,IAAIuB,UAAU,CAACvB,IAAI,CAAC,EAAE;QACpBP,MAAM,CAACoH,GAAG,CAAC7G,IAAI,CAAC;QAChB,MAAMF,GAAG,GACP,wDAAwD,GACxD,yCAAyC;QAC3CD,WAAW,CAACC,GAAG,EAAE,uBAAuB,EAAEE,IAAI,EAAEqD,QAAQ,CAAC;;;EAG/D;EAEA;;;;EAIAyD,eAAeA,CAACC,GAAM;IACpB,OAAO,IAAI,CAAC,CAAApC,MAAO,CAACnD,GAAG,CAACuF,GAAG,CAAC,GAAGC,QAAQ,GAAG,CAAC;EAC7C;EAEA,CAAAJ,qBAAsBK,CAAA;IACpB,MAAM3B,IAAI,GAAG,IAAI9C,SAAS,CAAC,IAAI,CAAC,CAAAP,GAAI,CAAC;IACrC,MAAMoD,MAAM,GAAG,IAAI7C,SAAS,CAAC,IAAI,CAAC,CAAAP,GAAI,CAAC;IACvC,IAAI,CAAC,CAAAqD,IAAK,GAAGA,IAAI;IACjB,IAAI,CAAC,CAAAD,MAAO,GAAGA,MAAM;IAErB,IAAI,CAAC,CAAA6B,UAAW,GAAG,CAAClB,KAAK,EAAErC,GAAG,EAAEwD,KAAK,GAAG9H,IAAI,CAACE,GAAG,EAAE,KAAI;MACpD8F,MAAM,CAACW,KAAK,CAAC,GAAGrC,GAAG,KAAK,CAAC,GAAGwD,KAAK,GAAG,CAAC;MACrC7B,IAAI,CAACU,KAAK,CAAC,GAAGrC,GAAG;MACjB,IAAIA,GAAG,KAAK,CAAC,IAAI,IAAI,CAACE,YAAY,EAAE;QAClC,MAAMuD,CAAC,GAAGC,UAAU,CAAC,MAAK;UACxB,IAAI,IAAI,CAAC,CAAAf,OAAQ,CAACN,KAAK,CAAC,EAAE;YACxB,IAAI,CAAC,CAAAsB,MAAO,CAAC,IAAI,CAAC,CAAA1C,OAAQ,CAACoB,KAAK,CAAM,EAAE,QAAQ,CAAC;;QAErD,CAAC,EAAErC,GAAG,GAAG,CAAC,CAAC;QACX;QACA;QACA,IAAIyD,CAAC,CAACG,KAAK,EAAE;UACXH,CAAC,CAACG,KAAK,EAAE;;QAEX;;IAEJ,CAAC;IAED,IAAI,CAAC,CAAAC,aAAc,GAAGxB,KAAK,IAAG;MAC5BX,MAAM,CAACW,KAAK,CAAC,GAAGV,IAAI,CAACU,KAAK,CAAC,KAAK,CAAC,GAAG3G,IAAI,CAACE,GAAG,EAAE,GAAG,CAAC;IACpD,CAAC;IAED,IAAI,CAAC,CAAAkI,SAAU,GAAG,CAACC,MAAM,EAAE1B,KAAK,KAAI;MAClC,IAAIV,IAAI,CAACU,KAAK,CAAC,EAAE;QACf,MAAMrC,GAAG,GAAG2B,IAAI,CAACU,KAAK,CAAC;QACvB,MAAMmB,KAAK,GAAG9B,MAAM,CAACW,KAAK,CAAC;QAC3B;QACA,IAAI,CAACrC,GAAG,IAAI,CAACwD,KAAK,EAAE;QACpBO,MAAM,CAAC/D,GAAG,GAAGA,GAAG;QAChB+D,MAAM,CAACP,KAAK,GAAGA,KAAK;QACpBO,MAAM,CAACnI,GAAG,GAAGoI,SAAS,IAAIC,MAAM,EAAE;QAClC,MAAMC,GAAG,GAAGH,MAAM,CAACnI,GAAG,GAAG4H,KAAK;QAC9BO,MAAM,CAACI,YAAY,GAAGnE,GAAG,GAAGkE,GAAG;;IAEnC,CAAC;IAED;IACA;IACA,IAAIF,SAAS,GAAG,CAAC;IACjB,MAAMC,MAAM,GAAGA,CAAA,KAAK;MAClB,MAAMhG,CAAC,GAAGvC,IAAI,CAACE,GAAG,EAAE;MACpB,IAAI,IAAI,CAACqE,aAAa,GAAG,CAAC,EAAE;QAC1B+D,SAAS,GAAG/F,CAAC;QACb,MAAMwF,CAAC,GAAGC,UAAU,CAClB,MAAOM,SAAS,GAAG,CAAE,EACrB,IAAI,CAAC/D,aAAa,CACnB;QACD;QACA;QACA,IAAIwD,CAAC,CAACG,KAAK,EAAE;UACXH,CAAC,CAACG,KAAK,EAAE;;QAEX;;MAEF,OAAO3F,CAAC;IACV,CAAC;IAED,IAAI,CAACkF,eAAe,GAAGC,GAAG,IAAG;MAC3B,MAAMf,KAAK,GAAG,IAAI,CAAC,CAAArB,MAAO,CAACoD,GAAG,CAAChB,GAAG,CAAC;MACnC,IAAIf,KAAK,KAAKS,SAAS,EAAE;QACvB,OAAO,CAAC;;MAEV,MAAM9C,GAAG,GAAG2B,IAAI,CAACU,KAAK,CAAC;MACvB,MAAMmB,KAAK,GAAG9B,MAAM,CAACW,KAAK,CAAC;MAC3B,IAAI,CAACrC,GAAG,IAAI,CAACwD,KAAK,EAAE;QAClB,OAAOH,QAAQ;;MAEjB,MAAMa,GAAG,GAAG,CAACF,SAAS,IAAIC,MAAM,EAAE,IAAIT,KAAK;MAC3C,OAAOxD,GAAG,GAAGkE,GAAG;IAClB,CAAC;IAED,IAAI,CAAC,CAAAvB,OAAQ,GAAGN,KAAK,IAAG;MACtB,MAAM9C,CAAC,GAAGmC,MAAM,CAACW,KAAK,CAAC;MACvB,MAAMoB,CAAC,GAAG9B,IAAI,CAACU,KAAK,CAAC;MACrB,OAAO,CAAC,CAACoB,CAAC,IAAI,CAAC,CAAClE,CAAC,IAAI,CAACyE,SAAS,IAAIC,MAAM,EAAE,IAAI1E,CAAC,GAAGkE,CAAC;IACtD,CAAC;EACH;EAEA;EACA,CAAAI,aAAc,GAA2BQ,CAAA,KAAK,CAAE,CAAC;EACjD,CAAAP,SAAU,GACRQ,CAAA,KAAK,CAAE,CAAC;EACV,CAAAf,UAAW,GAMCgB,CAAA,KAAK,CAAE,CAAC;EACpB;EAEA,CAAA5B,OAAQ,GAA8B6B,CAAA,KAAM,KAAK;EAEjD,CAAAxB,sBAAuByB,CAAA;IACrB,MAAMhD,KAAK,GAAG,IAAI5C,SAAS,CAAC,IAAI,CAAC,CAAAP,GAAI,CAAC;IACtC,IAAI,CAAC,CAAAyC,cAAe,GAAG,CAAC;IACxB,IAAI,CAAC,CAAAU,KAAM,GAAGA,KAAK;IACnB,IAAI,CAAC,CAAAiD,cAAe,GAAGrC,KAAK,IAAG;MAC7B,IAAI,CAAC,CAAAtB,cAAe,IAAIU,KAAK,CAACY,KAAK,CAAW;MAC9CZ,KAAK,CAACY,KAAK,CAAC,GAAG,CAAC;IAClB,CAAC;IACD,IAAI,CAAC,CAAAsC,WAAY,GAAG,CAACvC,CAAC,EAAEwC,CAAC,EAAE7F,IAAI,EAAE0B,eAAe,KAAI;MAClD;MACA;MACA,IAAI,IAAI,CAAC,CAAAwB,iBAAkB,CAAC2C,CAAC,CAAC,EAAE;QAC9B,OAAO,CAAC;;MAEV,IAAI,CAAC5G,QAAQ,CAACe,IAAI,CAAC,EAAE;QACnB,IAAI0B,eAAe,EAAE;UACnB,IAAI,OAAOA,eAAe,KAAK,UAAU,EAAE;YACzC,MAAM,IAAIjB,SAAS,CAAC,oCAAoC,CAAC;;UAE3DT,IAAI,GAAG0B,eAAe,CAACmE,CAAC,EAAExC,CAAC,CAAC;UAC5B,IAAI,CAACpE,QAAQ,CAACe,IAAI,CAAC,EAAE;YACnB,MAAM,IAAIS,SAAS,CACjB,0DAA0D,CAC3D;;SAEJ,MAAM;UACL,MAAM,IAAIA,SAAS,CACjB,iDAAiD,GAC/C,wDAAwD,GACxD,sBAAsB,CACzB;;;MAGL,OAAOT,IAAI;IACb,CAAC;IACD,IAAI,CAAC,CAAA8F,WAAY,GAAG,CAClBxC,KAAY,EACZtD,IAAmB,EACnBgF,MAA2B,KACzB;MACFtC,KAAK,CAACY,KAAK,CAAC,GAAGtD,IAAI;MACnB,IAAI,IAAI,CAAC,CAAAY,OAAQ,EAAE;QACjB,MAAMA,OAAO,GAAG,IAAI,CAAC,CAAAA,OAAQ,GAAI8B,KAAK,CAACY,KAAK,CAAY;QACxD,OAAO,IAAI,CAAC,CAAAtB,cAAe,GAAGpB,OAAO,EAAE;UACrC,IAAI,CAAC,CAAAmF,KAAM,CAAC,IAAI,CAAC;;;MAGrB,IAAI,CAAC,CAAA/D,cAAe,IAAIU,KAAK,CAACY,KAAK,CAAW;MAC9C,IAAI0B,MAAM,EAAE;QACVA,MAAM,CAACgB,SAAS,GAAGhG,IAAI;QACvBgF,MAAM,CAACiB,mBAAmB,GAAG,IAAI,CAAC,CAAAjE,cAAe;;IAErD,CAAC;EACH;EAEA,CAAA2D,cAAe,GAA2BO,EAAE,IAAG,CAAE,CAAC;EAClD,CAAAJ,WAAY,GAIAK,CAACD,EAAE,EAAEE,EAAE,EAAEC,GAAG,KAAI,CAAE,CAAC;EAC/B,CAAAT,WAAY,GAKSU,CACnBC,EAAK,EACLC,EAA0B,EAC1BxG,IAAoB,EACpB0B,eAA+C,KAC7C;IACF,IAAI1B,IAAI,IAAI0B,eAAe,EAAE;MAC3B,MAAM,IAAIjB,SAAS,CACjB,kEAAkE,CACnE;;IAEH,OAAO,CAAC;EACV,CAAC;EAED,CAAC,CAAAiD,OAAQ+C,CAAC;IAAEnF,UAAU,GAAG,IAAI,CAACA;EAAU,CAAE,GAAG,EAAE;IAC7C,IAAI,IAAI,CAAC,CAAAtB,IAAK,EAAE;MACd,KAAK,IAAI0G,CAAC,GAAG,IAAI,CAAC,CAAAnE,IAAK,EAAE,IAAI,GAAI;QAC/B,IAAI,CAAC,IAAI,CAAC,CAAAoE,YAAa,CAACD,CAAC,CAAC,EAAE;UAC1B;;QAEF,IAAIpF,UAAU,IAAI,CAAC,IAAI,CAAC,CAAAsC,OAAQ,CAAC8C,CAAC,CAAC,EAAE;UACnC,MAAMA,CAAC;;QAET,IAAIA,CAAC,KAAK,IAAI,CAAC,CAAApE,IAAK,EAAE;UACpB;SACD,MAAM;UACLoE,CAAC,GAAG,IAAI,CAAC,CAAArE,IAAK,CAACqE,CAAC,CAAU;;;;EAIlC;EAEA,CAAC,CAAA/C,QAASiD,CAAC;IAAEtF,UAAU,GAAG,IAAI,CAACA;EAAU,CAAE,GAAG,EAAE;IAC9C,IAAI,IAAI,CAAC,CAAAtB,IAAK,EAAE;MACd,KAAK,IAAI0G,CAAC,GAAG,IAAI,CAAC,CAAApE,IAAK,EAAE,IAAI,GAAI;QAC/B,IAAI,CAAC,IAAI,CAAC,CAAAqE,YAAa,CAACD,CAAC,CAAC,EAAE;UAC1B;;QAEF,IAAIpF,UAAU,IAAI,CAAC,IAAI,CAAC,CAAAsC,OAAQ,CAAC8C,CAAC,CAAC,EAAE;UACnC,MAAMA,CAAC;;QAET,IAAIA,CAAC,KAAK,IAAI,CAAC,CAAAnE,IAAK,EAAE;UACpB;SACD,MAAM;UACLmE,CAAC,GAAG,IAAI,CAAC,CAAAtE,IAAK,CAACsE,CAAC,CAAU;;;;EAIlC;EAEA,CAAAC,YAAaE,CAACvD,KAAY;IACxB,OACEA,KAAK,KAAKS,SAAS,IACnB,IAAI,CAAC,CAAA9B,MAAO,CAACoD,GAAG,CAAC,IAAI,CAAC,CAAAnD,OAAQ,CAACoB,KAAK,CAAM,CAAC,KAAKA,KAAK;EAEzD;EAEA;;;;EAIA,CAACwD,OAAOA,CAAA;IACN,KAAK,MAAMJ,CAAC,IAAI,IAAI,CAAC,CAAAhD,OAAQ,EAAE,EAAE;MAC/B,IACE,IAAI,CAAC,CAAAvB,OAAQ,CAACuE,CAAC,CAAC,KAAK3C,SAAS,IAC9B,IAAI,CAAC,CAAA7B,OAAQ,CAACwE,CAAC,CAAC,KAAK3C,SAAS,IAC9B,CAAC,IAAI,CAAC,CAAAb,iBAAkB,CAAC,IAAI,CAAC,CAAAf,OAAQ,CAACuE,CAAC,CAAC,CAAC,EAC1C;QACA,MAAM,CAAC,IAAI,CAAC,CAAAxE,OAAQ,CAACwE,CAAC,CAAC,EAAE,IAAI,CAAC,CAAAvE,OAAQ,CAACuE,CAAC,CAAC,CAAW;;;EAG1D;EAEA;;;;;;EAMA,CAACK,QAAQA,CAAA;IACP,KAAK,MAAML,CAAC,IAAI,IAAI,CAAC,CAAA/C,QAAS,EAAE,EAAE;MAChC,IACE,IAAI,CAAC,CAAAxB,OAAQ,CAACuE,CAAC,CAAC,KAAK3C,SAAS,IAC9B,IAAI,CAAC,CAAA7B,OAAQ,CAACwE,CAAC,CAAC,KAAK3C,SAAS,IAC9B,CAAC,IAAI,CAAC,CAAAb,iBAAkB,CAAC,IAAI,CAAC,CAAAf,OAAQ,CAACuE,CAAC,CAAC,CAAC,EAC1C;QACA,MAAM,CAAC,IAAI,CAAC,CAAAxE,OAAQ,CAACwE,CAAC,CAAC,EAAE,IAAI,CAAC,CAAAvE,OAAQ,CAACuE,CAAC,CAAC,CAAC;;;EAGhD;EAEA;;;;EAIA,CAACM,IAAIA,CAAA;IACH,KAAK,MAAMN,CAAC,IAAI,IAAI,CAAC,CAAAhD,OAAQ,EAAE,EAAE;MAC/B,MAAML,CAAC,GAAG,IAAI,CAAC,CAAAnB,OAAQ,CAACwE,CAAC,CAAC;MAC1B,IACErD,CAAC,KAAKU,SAAS,IACf,CAAC,IAAI,CAAC,CAAAb,iBAAkB,CAAC,IAAI,CAAC,CAAAf,OAAQ,CAACuE,CAAC,CAAC,CAAC,EAC1C;QACA,MAAMrD,CAAC;;;EAGb;EAEA;;;;;;EAMA,CAAC4D,KAAKA,CAAA;IACJ,KAAK,MAAMP,CAAC,IAAI,IAAI,CAAC,CAAA/C,QAAS,EAAE,EAAE;MAChC,MAAMN,CAAC,GAAG,IAAI,CAAC,CAAAnB,OAAQ,CAACwE,CAAC,CAAC;MAC1B,IACErD,CAAC,KAAKU,SAAS,IACf,CAAC,IAAI,CAAC,CAAAb,iBAAkB,CAAC,IAAI,CAAC,CAAAf,OAAQ,CAACuE,CAAC,CAAC,CAAC,EAC1C;QACA,MAAMrD,CAAC;;;EAGb;EAEA;;;;EAIA,CAAC6D,MAAMA,CAAA;IACL,KAAK,MAAMR,CAAC,IAAI,IAAI,CAAC,CAAAhD,OAAQ,EAAE,EAAE;MAC/B,MAAMmC,CAAC,GAAG,IAAI,CAAC,CAAA1D,OAAQ,CAACuE,CAAC,CAAC;MAC1B,IACEb,CAAC,KAAK9B,SAAS,IACf,CAAC,IAAI,CAAC,CAAAb,iBAAkB,CAAC,IAAI,CAAC,CAAAf,OAAQ,CAACuE,CAAC,CAAC,CAAC,EAC1C;QACA,MAAM,IAAI,CAAC,CAAAvE,OAAQ,CAACuE,CAAC,CAAM;;;EAGjC;EAEA;;;;;;EAMA,CAACS,OAAOA,CAAA;IACN,KAAK,MAAMT,CAAC,IAAI,IAAI,CAAC,CAAA/C,QAAS,EAAE,EAAE;MAChC,MAAMkC,CAAC,GAAG,IAAI,CAAC,CAAA1D,OAAQ,CAACuE,CAAC,CAAC;MAC1B,IACEb,CAAC,KAAK9B,SAAS,IACf,CAAC,IAAI,CAAC,CAAAb,iBAAkB,CAAC,IAAI,CAAC,CAAAf,OAAQ,CAACuE,CAAC,CAAC,CAAC,EAC1C;QACA,MAAM,IAAI,CAAC,CAAAvE,OAAQ,CAACuE,CAAC,CAAC;;;EAG5B;EAEA;;;;EAIA,CAAC1H,MAAM,CAACoI,QAAQ,IAAC;IACf,OAAO,IAAI,CAACN,OAAO,EAAE;EACvB;EAEA;;;;;EAKA,CAAC9H,MAAM,CAACqI,WAAW,IAAI,UAAU;EAEjC;;;;EAIAC,IAAIA,CACF/J,EAAqD,EACrDgK,UAAA,GAA4C,EAAE;IAE9C,KAAK,MAAMb,CAAC,IAAI,IAAI,CAAC,CAAAhD,OAAQ,EAAE,EAAE;MAC/B,MAAMmC,CAAC,GAAG,IAAI,CAAC,CAAA1D,OAAQ,CAACuE,CAAC,CAAC;MAC1B,MAAMc,KAAK,GAAG,IAAI,CAAC,CAAAtE,iBAAkB,CAAC2C,CAAC,CAAC,GACpCA,CAAC,CAAC4B,oBAAoB,GACtB5B,CAAC;MACL,IAAI2B,KAAK,KAAKzD,SAAS,EAAE;MACzB,IAAIxG,EAAE,CAACiK,KAAK,EAAE,IAAI,CAAC,CAAAtF,OAAQ,CAACwE,CAAC,CAAM,EAAE,IAAI,CAAC,EAAE;QAC1C,OAAO,IAAI,CAACrB,GAAG,CAAC,IAAI,CAAC,CAAAnD,OAAQ,CAACwE,CAAC,CAAM,EAAEa,UAAU,CAAC;;;EAGxD;EAEA;;;;;;;;;;;EAWAG,OAAOA,CACLnK,EAAiD,EACjDoK,KAAA,GAAa,IAAI;IAEjB,KAAK,MAAMjB,CAAC,IAAI,IAAI,CAAC,CAAAhD,OAAQ,EAAE,EAAE;MAC/B,MAAMmC,CAAC,GAAG,IAAI,CAAC,CAAA1D,OAAQ,CAACuE,CAAC,CAAC;MAC1B,MAAMc,KAAK,GAAG,IAAI,CAAC,CAAAtE,iBAAkB,CAAC2C,CAAC,CAAC,GACpCA,CAAC,CAAC4B,oBAAoB,GACtB5B,CAAC;MACL,IAAI2B,KAAK,KAAKzD,SAAS,EAAE;MACzBxG,EAAE,CAACqK,IAAI,CAACD,KAAK,EAAEH,KAAK,EAAE,IAAI,CAAC,CAAAtF,OAAQ,CAACwE,CAAC,CAAM,EAAE,IAAI,CAAC;;EAEtD;EAEA;;;;EAIAmB,QAAQA,CACNtK,EAAiD,EACjDoK,KAAA,GAAa,IAAI;IAEjB,KAAK,MAAMjB,CAAC,IAAI,IAAI,CAAC,CAAA/C,QAAS,EAAE,EAAE;MAChC,MAAMkC,CAAC,GAAG,IAAI,CAAC,CAAA1D,OAAQ,CAACuE,CAAC,CAAC;MAC1B,MAAMc,KAAK,GAAG,IAAI,CAAC,CAAAtE,iBAAkB,CAAC2C,CAAC,CAAC,GACpCA,CAAC,CAAC4B,oBAAoB,GACtB5B,CAAC;MACL,IAAI2B,KAAK,KAAKzD,SAAS,EAAE;MACzBxG,EAAE,CAACqK,IAAI,CAACD,KAAK,EAAEH,KAAK,EAAE,IAAI,CAAC,CAAAtF,OAAQ,CAACwE,CAAC,CAAM,EAAE,IAAI,CAAC;;EAEtD;EAEA;;;;EAIAoB,UAAUA,CAAA;IACR,IAAIC,OAAO,GAAG,KAAK;IACnB,KAAK,MAAMrB,CAAC,IAAI,IAAI,CAAC,CAAA/C,QAAS,CAAC;MAAErC,UAAU,EAAE;IAAI,CAAE,CAAC,EAAE;MACpD,IAAI,IAAI,CAAC,CAAAsC,OAAQ,CAAC8C,CAAC,CAAC,EAAE;QACpB,IAAI,CAAC,CAAA9B,MAAO,CAAC,IAAI,CAAC,CAAA1C,OAAQ,CAACwE,CAAC,CAAM,EAAE,QAAQ,CAAC;QAC7CqB,OAAO,GAAG,IAAI;;;IAGlB,OAAOA,OAAO;EAChB;EAEA;;;;;;;;;;;;EAYAC,IAAIA,CAAC3D,GAAM;IACT,MAAMqC,CAAC,GAAG,IAAI,CAAC,CAAAzE,MAAO,CAACoD,GAAG,CAAChB,GAAG,CAAC;IAC/B,IAAIqC,CAAC,KAAK3C,SAAS,EAAE,OAAOA,SAAS;IACrC,MAAM8B,CAAC,GAAG,IAAI,CAAC,CAAA1D,OAAQ,CAACuE,CAAC,CAAC;IAC1B,MAAMc,KAAK,GAAkB,IAAI,CAAC,CAAAtE,iBAAkB,CAAC2C,CAAC,CAAC,GACnDA,CAAC,CAAC4B,oBAAoB,GACtB5B,CAAC;IACL,IAAI2B,KAAK,KAAKzD,SAAS,EAAE,OAAOA,SAAS;IACzC,MAAMkE,KAAK,GAAsB;MAAET;IAAK,CAAE;IAC1C,IAAI,IAAI,CAAC,CAAA5E,IAAK,IAAI,IAAI,CAAC,CAAAD,MAAO,EAAE;MAC9B,MAAM1B,GAAG,GAAG,IAAI,CAAC,CAAA2B,IAAK,CAAC8D,CAAC,CAAC;MACzB,MAAMjC,KAAK,GAAG,IAAI,CAAC,CAAA9B,MAAO,CAAC+D,CAAC,CAAC;MAC7B,IAAIzF,GAAG,IAAIwD,KAAK,EAAE;QAChB,MAAMyD,MAAM,GAAGjH,GAAG,IAAItE,IAAI,CAACE,GAAG,EAAE,GAAG4H,KAAK,CAAC;QACzCwD,KAAK,CAAChH,GAAG,GAAGiH,MAAM;QAClBD,KAAK,CAACxD,KAAK,GAAG3H,IAAI,CAACD,GAAG,EAAE;;;IAG5B,IAAI,IAAI,CAAC,CAAA6F,KAAM,EAAE;MACfuF,KAAK,CAACjI,IAAI,GAAG,IAAI,CAAC,CAAA0C,KAAM,CAACgE,CAAC,CAAC;;IAE7B,OAAOuB,KAAK;EACd;EAEA;;;;;;;;;;;;;EAaAE,IAAIA,CAAA;IACF,MAAMC,GAAG,GAA6B,EAAE;IACxC,KAAK,MAAM1B,CAAC,IAAI,IAAI,CAAC,CAAAhD,OAAQ,CAAC;MAAEpC,UAAU,EAAE;IAAI,CAAE,CAAC,EAAE;MACnD,MAAM+C,GAAG,GAAG,IAAI,CAAC,CAAAnC,OAAQ,CAACwE,CAAC,CAAC;MAC5B,MAAMb,CAAC,GAAG,IAAI,CAAC,CAAA1D,OAAQ,CAACuE,CAAC,CAAC;MAC1B,MAAMc,KAAK,GAAkB,IAAI,CAAC,CAAAtE,iBAAkB,CAAC2C,CAAC,CAAC,GACnDA,CAAC,CAAC4B,oBAAoB,GACtB5B,CAAC;MACL,IAAI2B,KAAK,KAAKzD,SAAS,IAAIM,GAAG,KAAKN,SAAS,EAAE;MAC9C,MAAMkE,KAAK,GAAsB;QAAET;MAAK,CAAE;MAC1C,IAAI,IAAI,CAAC,CAAA5E,IAAK,IAAI,IAAI,CAAC,CAAAD,MAAO,EAAE;QAC9BsF,KAAK,CAAChH,GAAG,GAAG,IAAI,CAAC,CAAA2B,IAAK,CAAC8D,CAAC,CAAC;QACzB;QACA;QACA,MAAMvB,GAAG,GAAGxI,IAAI,CAACE,GAAG,EAAE,GAAI,IAAI,CAAC,CAAA8F,MAAO,CAAC+D,CAAC,CAAY;QACpDuB,KAAK,CAACxD,KAAK,GAAGtF,IAAI,CAACC,KAAK,CAACtC,IAAI,CAACD,GAAG,EAAE,GAAGsI,GAAG,CAAC;;MAE5C,IAAI,IAAI,CAAC,CAAAzC,KAAM,EAAE;QACfuF,KAAK,CAACjI,IAAI,GAAG,IAAI,CAAC,CAAA0C,KAAM,CAACgE,CAAC,CAAC;;MAE7B0B,GAAG,CAACC,OAAO,CAAC,CAAChE,GAAG,EAAE4D,KAAK,CAAC,CAAC;;IAE3B,OAAOG,GAAG;EACZ;EAEA;;;;;;;;;EASAE,IAAIA,CAACF,GAA6B;IAChC,IAAI,CAACG,KAAK,EAAE;IACZ,KAAK,MAAM,CAAClE,GAAG,EAAE4D,KAAK,CAAC,IAAIG,GAAG,EAAE;MAC9B,IAAIH,KAAK,CAACxD,KAAK,EAAE;QACf;QACA;QACA;QACA;QACA;QACA;QACA,MAAMU,GAAG,GAAGrI,IAAI,CAACD,GAAG,EAAE,GAAGoL,KAAK,CAACxD,KAAK;QACpCwD,KAAK,CAACxD,KAAK,GAAG9H,IAAI,CAACE,GAAG,EAAE,GAAGsI,GAAG;;MAEhC,IAAI,CAACqD,GAAG,CAACnE,GAAG,EAAE4D,KAAK,CAACT,KAAK,EAAES,KAAK,CAAC;;EAErC;EAEA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;EA8BAO,GAAGA,CACDnF,CAAI,EACJwC,CAAqC,EACrC4C,UAAA,GAA4C,EAAE;IAE9C,IAAI5C,CAAC,KAAK9B,SAAS,EAAE;MACnB,IAAI,CAACa,MAAM,CAACvB,CAAC,CAAC;MACd,OAAO,IAAI;;IAEb,MAAM;MACJpC,GAAG,GAAG,IAAI,CAACA,GAAG;MACdwD,KAAK;MACLlD,cAAc,GAAG,IAAI,CAACA,cAAc;MACpCG,eAAe,GAAG,IAAI,CAACA,eAAe;MACtCsD;IAAM,CACP,GAAGyD,UAAU;IACd,IAAI;MAAEjH,WAAW,GAAG,IAAI,CAACA;IAAW,CAAE,GAAGiH,UAAU;IAEnD,MAAMzI,IAAI,GAAG,IAAI,CAAC,CAAA4F,WAAY,CAC5BvC,CAAC,EACDwC,CAAC,EACD4C,UAAU,CAACzI,IAAI,IAAI,CAAC,EACpB0B,eAAe,CAChB;IACD;IACA;IACA,IAAI,IAAI,CAACD,YAAY,IAAIzB,IAAI,GAAG,IAAI,CAACyB,YAAY,EAAE;MACjD,IAAIuD,MAAM,EAAE;QACVA,MAAM,CAACwD,GAAG,GAAG,MAAM;QACnBxD,MAAM,CAAC0D,oBAAoB,GAAG,IAAI;;MAEpC;MACA,IAAI,CAAC,CAAA9D,MAAO,CAACvB,CAAC,EAAE,KAAK,CAAC;MACtB,OAAO,IAAI;;IAEb,IAAIC,KAAK,GAAG,IAAI,CAAC,CAAAtD,IAAK,KAAK,CAAC,GAAG+D,SAAS,GAAG,IAAI,CAAC,CAAA9B,MAAO,CAACoD,GAAG,CAAChC,CAAC,CAAC;IAC9D,IAAIC,KAAK,KAAKS,SAAS,EAAE;MACvB;MACAT,KAAK,GACH,IAAI,CAAC,CAAAtD,IAAK,KAAK,CAAC,GACZ,IAAI,CAAC,CAAAuC,IAAK,GACV,IAAI,CAAC,CAAAC,IAAK,CAACpC,MAAM,KAAK,CAAC,GACvB,IAAI,CAAC,CAAAoC,IAAK,CAAC9B,GAAG,EAAE,GAChB,IAAI,CAAC,CAAAV,IAAK,KAAK,IAAI,CAAC,CAAAT,GAAI,GACxB,IAAI,CAAC,CAAAwG,KAAM,CAAC,KAAK,CAAC,GAClB,IAAI,CAAC,CAAA/F,IACD;MACV,IAAI,CAAC,CAAAkC,OAAQ,CAACoB,KAAK,CAAC,GAAGD,CAAC;MACxB,IAAI,CAAC,CAAAlB,OAAQ,CAACmB,KAAK,CAAC,GAAGuC,CAAC;MACxB,IAAI,CAAC,CAAA5D,MAAO,CAACuG,GAAG,CAACnF,CAAC,EAAEC,KAAK,CAAC;MAC1B,IAAI,CAAC,CAAAlB,IAAK,CAAC,IAAI,CAAC,CAAAG,IAAK,CAAC,GAAGe,KAAK;MAC9B,IAAI,CAAC,CAAAjB,IAAK,CAACiB,KAAK,CAAC,GAAG,IAAI,CAAC,CAAAf,IAAK;MAC9B,IAAI,CAAC,CAAAA,IAAK,GAAGe,KAAK;MAClB,IAAI,CAAC,CAAAtD,IAAK,EAAE;MACZ,IAAI,CAAC,CAAA8F,WAAY,CAACxC,KAAK,EAAEtD,IAAI,EAAEgF,MAAM,CAAC;MACtC,IAAIA,MAAM,EAAEA,MAAM,CAACwD,GAAG,GAAG,KAAK;MAC9BhH,WAAW,GAAG,KAAK;KACpB,MAAM;MACL;MACA,IAAI,CAAC,CAAAiC,UAAW,CAACH,KAAK,CAAC;MACvB,MAAMqF,MAAM,GAAG,IAAI,CAAC,CAAAxG,OAAQ,CAACmB,KAAK,CAA2B;MAC7D,IAAIuC,CAAC,KAAK8C,MAAM,EAAE;QAChB,IAAI,IAAI,CAAC,CAAA7F,cAAe,IAAI,IAAI,CAAC,CAAAI,iBAAkB,CAACyF,MAAM,CAAC,EAAE;UAC3DA,MAAM,CAACC,iBAAiB,CAACnK,KAAK,CAAC,IAAIqF,KAAK,CAAC,UAAU,CAAC,CAAC;UACrD,MAAM;YAAE2D,oBAAoB,EAAEjH;UAAC,CAAE,GAAGmI,MAAM;UAC1C,IAAInI,CAAC,KAAKuD,SAAS,IAAI,CAACxC,cAAc,EAAE;YACtC,IAAI,IAAI,CAAC,CAAAsB,UAAW,EAAE;cACpB,IAAI,CAAC,CAAAhC,OAAQ,GAAGL,CAAM,EAAE6C,CAAC,EAAE,KAAK,CAAC;;YAEnC,IAAI,IAAI,CAAC,CAAAN,eAAgB,EAAE;cACzB,IAAI,CAAC,CAAAN,QAAS,EAAEpE,IAAI,CAAC,CAACmC,CAAM,EAAE6C,CAAC,EAAE,KAAK,CAAC,CAAC;;;SAG7C,MAAM,IAAI,CAAC9B,cAAc,EAAE;UAC1B,IAAI,IAAI,CAAC,CAAAsB,UAAW,EAAE;YACpB,IAAI,CAAC,CAAAhC,OAAQ,GAAG8H,MAAW,EAAEtF,CAAC,EAAE,KAAK,CAAC;;UAExC,IAAI,IAAI,CAAC,CAAAN,eAAgB,EAAE;YACzB,IAAI,CAAC,CAAAN,QAAS,EAAEpE,IAAI,CAAC,CAACsK,MAAW,EAAEtF,CAAC,EAAE,KAAK,CAAC,CAAC;;;QAGjD,IAAI,CAAC,CAAAsC,cAAe,CAACrC,KAAK,CAAC;QAC3B,IAAI,CAAC,CAAAwC,WAAY,CAACxC,KAAK,EAAEtD,IAAI,EAAEgF,MAAM,CAAC;QACtC,IAAI,CAAC,CAAA7C,OAAQ,CAACmB,KAAK,CAAC,GAAGuC,CAAC;QACxB,IAAIb,MAAM,EAAE;UACVA,MAAM,CAACwD,GAAG,GAAG,SAAS;UACtB,MAAMK,QAAQ,GACZF,MAAM,IAAI,IAAI,CAAC,CAAAzF,iBAAkB,CAACyF,MAAM,CAAC,GACrCA,MAAM,CAAClB,oBAAoB,GAC3BkB,MAAM;UACZ,IAAIE,QAAQ,KAAK9E,SAAS,EAAEiB,MAAM,CAAC6D,QAAQ,GAAGA,QAAQ;;OAEzD,MAAM,IAAI7D,MAAM,EAAE;QACjBA,MAAM,CAACwD,GAAG,GAAG,QAAQ;;;IAGzB,IAAIvH,GAAG,KAAK,CAAC,IAAI,CAAC,IAAI,CAAC,CAAA2B,IAAK,EAAE;MAC5B,IAAI,CAAC,CAAAsB,qBAAsB,EAAE;;IAE/B,IAAI,IAAI,CAAC,CAAAtB,IAAK,EAAE;MACd,IAAI,CAACpB,WAAW,EAAE;QAChB,IAAI,CAAC,CAAAgD,UAAW,CAAClB,KAAK,EAAErC,GAAG,EAAEwD,KAAK,CAAC;;MAErC,IAAIO,MAAM,EAAE,IAAI,CAAC,CAAAD,SAAU,CAACC,MAAM,EAAE1B,KAAK,CAAC;;IAE5C,IAAI,CAAC/B,cAAc,IAAI,IAAI,CAAC,CAAAwB,eAAgB,IAAI,IAAI,CAAC,CAAAN,QAAS,EAAE;MAC9D,MAAMqG,EAAE,GAAG,IAAI,CAAC,CAAArG,QAAS;MACzB,IAAIsG,IAAmC;MACvC,OAAQA,IAAI,GAAGD,EAAE,EAAEE,KAAK,EAAE,EAAG;QAC3B,IAAI,CAAC,CAAAlI,YAAa,GAAG,GAAGiI,IAAI,CAAC;;;IAGjC,OAAO,IAAI;EACb;EAEA;;;;EAIArI,GAAGA,CAAA;IACD,IAAI;MACF,OAAO,IAAI,CAAC,CAAAV,IAAK,EAAE;QACjB,MAAMiJ,GAAG,GAAG,IAAI,CAAC,CAAA9G,OAAQ,CAAC,IAAI,CAAC,CAAAG,IAAK,CAAC;QACrC,IAAI,CAAC,CAAAyD,KAAM,CAAC,IAAI,CAAC;QACjB,IAAI,IAAI,CAAC,CAAA7C,iBAAkB,CAAC+F,GAAG,CAAC,EAAE;UAChC,IAAIA,GAAG,CAACxB,oBAAoB,EAAE;YAC5B,OAAOwB,GAAG,CAACxB,oBAAoB;;SAElC,MAAM,IAAIwB,GAAG,KAAKlF,SAAS,EAAE;UAC5B,OAAOkF,GAAG;;;KAGf,SAAS;MACR,IAAI,IAAI,CAAC,CAAAlG,eAAgB,IAAI,IAAI,CAAC,CAAAN,QAAS,EAAE;QAC3C,MAAMqG,EAAE,GAAG,IAAI,CAAC,CAAArG,QAAS;QACzB,IAAIsG,IAAmC;QACvC,OAAQA,IAAI,GAAGD,EAAE,EAAEE,KAAK,EAAE,EAAG;UAC3B,IAAI,CAAC,CAAAlI,YAAa,GAAG,GAAGiI,IAAI,CAAC;;;;EAIrC;EAEA,CAAAhD,KAAMmD,CAAC1G,IAAa;IAClB,MAAMF,IAAI,GAAG,IAAI,CAAC,CAAAA,IAAK;IACvB,MAAMe,CAAC,GAAG,IAAI,CAAC,CAAAnB,OAAQ,CAACI,IAAI,CAAM;IAClC,MAAMuD,CAAC,GAAG,IAAI,CAAC,CAAA1D,OAAQ,CAACG,IAAI,CAAM;IAClC,IAAI,IAAI,CAAC,CAAAQ,cAAe,IAAI,IAAI,CAAC,CAAAI,iBAAkB,CAAC2C,CAAC,CAAC,EAAE;MACtDA,CAAC,CAAC+C,iBAAiB,CAACnK,KAAK,CAAC,IAAIqF,KAAK,CAAC,SAAS,CAAC,CAAC;KAChD,MAAM,IAAI,IAAI,CAAC,CAAAjB,UAAW,IAAI,IAAI,CAAC,CAAAE,eAAgB,EAAE;MACpD,IAAI,IAAI,CAAC,CAAAF,UAAW,EAAE;QACpB,IAAI,CAAC,CAAAhC,OAAQ,GAAGgF,CAAC,EAAExC,CAAC,EAAE,OAAO,CAAC;;MAEhC,IAAI,IAAI,CAAC,CAAAN,eAAgB,EAAE;QACzB,IAAI,CAAC,CAAAN,QAAS,EAAEpE,IAAI,CAAC,CAACwH,CAAC,EAAExC,CAAC,EAAE,OAAO,CAAC,CAAC;;;IAGzC,IAAI,CAAC,CAAAsC,cAAe,CAACrD,IAAI,CAAC;IAC1B;IACA,IAAIE,IAAI,EAAE;MACR,IAAI,CAAC,CAAAN,OAAQ,CAACI,IAAI,CAAC,GAAGyB,SAAS;MAC/B,IAAI,CAAC,CAAA5B,OAAQ,CAACG,IAAI,CAAC,GAAGyB,SAAS;MAC/B,IAAI,CAAC,CAAAvB,IAAK,CAACnE,IAAI,CAACiE,IAAI,CAAC;;IAEvB,IAAI,IAAI,CAAC,CAAAtC,IAAK,KAAK,CAAC,EAAE;MACpB,IAAI,CAAC,CAAAsC,IAAK,GAAG,IAAI,CAAC,CAAAC,IAAK,GAAG,CAAU;MACpC,IAAI,CAAC,CAAAC,IAAK,CAACpC,MAAM,GAAG,CAAC;KACtB,MAAM;MACL,IAAI,CAAC,CAAAkC,IAAK,GAAG,IAAI,CAAC,CAAAF,IAAK,CAACE,IAAI,CAAU;;IAExC,IAAI,CAAC,CAAAL,MAAO,CAAC2C,MAAM,CAACvB,CAAC,CAAC;IACtB,IAAI,CAAC,CAAArD,IAAK,EAAE;IACZ,OAAOsC,IAAI;EACb;EAEA;;;;;;;;;;;;;;;;EAgBAxD,GAAGA,CAACuE,CAAI,EAAE8F,UAAA,GAA4C,EAAE;IACtD,MAAM;MAAE9H,cAAc,GAAG,IAAI,CAACA,cAAc;MAAE2D;IAAM,CAAE,GACpDmE,UAAU;IACZ,MAAM7F,KAAK,GAAG,IAAI,CAAC,CAAArB,MAAO,CAACoD,GAAG,CAAChC,CAAC,CAAC;IACjC,IAAIC,KAAK,KAAKS,SAAS,EAAE;MACvB,MAAM8B,CAAC,GAAG,IAAI,CAAC,CAAA1D,OAAQ,CAACmB,KAAK,CAAC;MAC9B,IACE,IAAI,CAAC,CAAAJ,iBAAkB,CAAC2C,CAAC,CAAC,IAC1BA,CAAC,CAAC4B,oBAAoB,KAAK1D,SAAS,EACpC;QACA,OAAO,KAAK;;MAEd,IAAI,CAAC,IAAI,CAAC,CAAAH,OAAQ,CAACN,KAAK,CAAC,EAAE;QACzB,IAAIjC,cAAc,EAAE;UAClB,IAAI,CAAC,CAAAyD,aAAc,CAACxB,KAAK,CAAC;;QAE5B,IAAI0B,MAAM,EAAE;UACVA,MAAM,CAAClG,GAAG,GAAG,KAAK;UAClB,IAAI,CAAC,CAAAiG,SAAU,CAACC,MAAM,EAAE1B,KAAK,CAAC;;QAEhC,OAAO,IAAI;OACZ,MAAM,IAAI0B,MAAM,EAAE;QACjBA,MAAM,CAAClG,GAAG,GAAG,OAAO;QACpB,IAAI,CAAC,CAAAiG,SAAU,CAACC,MAAM,EAAE1B,KAAK,CAAC;;KAEjC,MAAM,IAAI0B,MAAM,EAAE;MACjBA,MAAM,CAAClG,GAAG,GAAG,MAAM;;IAErB,OAAO,KAAK;EACd;EAEA;;;;;;;EAOAsK,IAAIA,CAAC/F,CAAI,EAAEgG,WAAA,GAA8C,EAAE;IACzD,MAAM;MAAE/H,UAAU,GAAG,IAAI,CAACA;IAAU,CAAE,GAAG+H,WAAW;IACpD,MAAM/F,KAAK,GAAG,IAAI,CAAC,CAAArB,MAAO,CAACoD,GAAG,CAAChC,CAAC,CAAC;IACjC,IACEC,KAAK,KAAKS,SAAS,IAClB,CAACzC,UAAU,IAAI,IAAI,CAAC,CAAAsC,OAAQ,CAACN,KAAK,CAAE,EACrC;MACA;;IAEF,MAAMuC,CAAC,GAAG,IAAI,CAAC,CAAA1D,OAAQ,CAACmB,KAAK,CAAC;IAC9B;IACA,OAAO,IAAI,CAAC,CAAAJ,iBAAkB,CAAC2C,CAAC,CAAC,GAAGA,CAAC,CAAC4B,oBAAoB,GAAG5B,CAAC;EAChE;EAEA,CAAAzC,eAAgBkG,CACdjG,CAAI,EACJC,KAAwB,EACxBC,OAAwC,EACxCC,OAAY;IAEZ,MAAMqC,CAAC,GAAGvC,KAAK,KAAKS,SAAS,GAAGA,SAAS,GAAG,IAAI,CAAC,CAAA5B,OAAQ,CAACmB,KAAK,CAAC;IAChE,IAAI,IAAI,CAAC,CAAAJ,iBAAkB,CAAC2C,CAAC,CAAC,EAAE;MAC9B,OAAOA,CAAC;;IAGV,MAAM0D,EAAE,GAAG,IAAI7L,EAAE,EAAE;IACnB,MAAM;MAAEc;IAAM,CAAE,GAAG+E,OAAO;IAC1B;IACA/E,MAAM,EAAEL,gBAAgB,CAAC,OAAO,EAAE,MAAMoL,EAAE,CAAC9K,KAAK,CAACD,MAAM,CAACP,MAAM,CAAC,EAAE;MAC/DO,MAAM,EAAE+K,EAAE,CAAC/K;KACZ,CAAC;IAEF,MAAMgL,SAAS,GAAG;MAChBhL,MAAM,EAAE+K,EAAE,CAAC/K,MAAM;MACjB+E,OAAO;MACPC;KACD;IAED,MAAMiG,EAAE,GAAGA,CACT5D,CAAgB,EAChB6D,WAAW,GAAG,KAAK,KACF;MACjB,MAAM;QAAExL;MAAO,CAAE,GAAGqL,EAAE,CAAC/K,MAAM;MAC7B,MAAMmL,WAAW,GAAGpG,OAAO,CAACxB,gBAAgB,IAAI8D,CAAC,KAAK9B,SAAS;MAC/D,IAAIR,OAAO,CAACyB,MAAM,EAAE;QAClB,IAAI9G,OAAO,IAAI,CAACwL,WAAW,EAAE;UAC3BnG,OAAO,CAACyB,MAAM,CAAC4E,YAAY,GAAG,IAAI;UAClCrG,OAAO,CAACyB,MAAM,CAAC6E,UAAU,GAAGN,EAAE,CAAC/K,MAAM,CAACP,MAAM;UAC5C,IAAI0L,WAAW,EAAEpG,OAAO,CAACyB,MAAM,CAAC8E,iBAAiB,GAAG,IAAI;SACzD,MAAM;UACLvG,OAAO,CAACyB,MAAM,CAAC+E,aAAa,GAAG,IAAI;;;MAGvC,IAAI7L,OAAO,IAAI,CAACyL,WAAW,IAAI,CAACD,WAAW,EAAE;QAC3C,OAAOM,SAAS,CAACT,EAAE,CAAC/K,MAAM,CAACP,MAAM,CAAC;;MAEpC;MACA,MAAMgM,EAAE,GAAG9G,CAAuB;MAClC,IAAI,IAAI,CAAC,CAAAhB,OAAQ,CAACmB,KAAc,CAAC,KAAKH,CAAC,EAAE;QACvC,IAAI0C,CAAC,KAAK9B,SAAS,EAAE;UACnB,IAAIkG,EAAE,CAACxC,oBAAoB,EAAE;YAC3B,IAAI,CAAC,CAAAtF,OAAQ,CAACmB,KAAc,CAAC,GAAG2G,EAAE,CAACxC,oBAAoB;WACxD,MAAM;YACL,IAAI,CAAC,CAAA7C,MAAO,CAACvB,CAAC,EAAE,OAAO,CAAC;;SAE3B,MAAM;UACL,IAAIE,OAAO,CAACyB,MAAM,EAAEzB,OAAO,CAACyB,MAAM,CAACkF,YAAY,GAAG,IAAI;UACtD,IAAI,CAAC1B,GAAG,CAACnF,CAAC,EAAEwC,CAAC,EAAE2D,SAAS,CAACjG,OAAO,CAAC;;;MAGrC,OAAOsC,CAAC;IACV,CAAC;IAED,MAAMsE,EAAE,GAAIC,EAAO,IAAI;MACrB,IAAI7G,OAAO,CAACyB,MAAM,EAAE;QAClBzB,OAAO,CAACyB,MAAM,CAACqF,aAAa,GAAG,IAAI;QACnC9G,OAAO,CAACyB,MAAM,CAAC6E,UAAU,GAAGO,EAAE;;MAEhC,OAAOJ,SAAS,CAACI,EAAE,CAAC;IACtB,CAAC;IAED,MAAMJ,SAAS,GAAII,EAAO,IAAmB;MAC3C,MAAM;QAAElM;MAAO,CAAE,GAAGqL,EAAE,CAAC/K,MAAM;MAC7B,MAAM8L,iBAAiB,GACrBpM,OAAO,IAAIqF,OAAO,CAAC1B,sBAAsB;MAC3C,MAAMP,UAAU,GACdgJ,iBAAiB,IAAI/G,OAAO,CAACzB,0BAA0B;MACzD,MAAMyI,QAAQ,GAAGjJ,UAAU,IAAIiC,OAAO,CAAC5B,wBAAwB;MAC/D,MAAMsI,EAAE,GAAG9G,CAAuB;MAClC,IAAI,IAAI,CAAC,CAAAhB,OAAQ,CAACmB,KAAc,CAAC,KAAKH,CAAC,EAAE;QACvC;QACA;QACA,MAAMqH,GAAG,GAAG,CAACD,QAAQ,IAAIN,EAAE,CAACxC,oBAAoB,KAAK1D,SAAS;QAC9D,IAAIyG,GAAG,EAAE;UACP,IAAI,CAAC,CAAA5F,MAAO,CAACvB,CAAC,EAAE,OAAO,CAAC;SACzB,MAAM,IAAI,CAACiH,iBAAiB,EAAE;UAC7B;UACA;UACA;UACA;UACA,IAAI,CAAC,CAAAnI,OAAQ,CAACmB,KAAc,CAAC,GAAG2G,EAAE,CAACxC,oBAAoB;;;MAG3D,IAAInG,UAAU,EAAE;QACd,IAAIiC,OAAO,CAACyB,MAAM,IAAIiF,EAAE,CAACxC,oBAAoB,KAAK1D,SAAS,EAAE;UAC3DR,OAAO,CAACyB,MAAM,CAACyF,aAAa,GAAG,IAAI;;QAErC,OAAOR,EAAE,CAACxC,oBAAoB;OAC/B,MAAM,IAAIwC,EAAE,CAACS,UAAU,KAAKT,EAAE,EAAE;QAC/B,MAAMG,EAAE;;IAEZ,CAAC;IAED,MAAMO,KAAK,GAAGA,CACZC,GAA+B,EAC/BC,GAAqB,KACnB;MACF,MAAMC,GAAG,GAAG,IAAI,CAAC,CAAA/J,WAAY,GAAGsC,CAAC,EAAEwC,CAAC,EAAE2D,SAAS,CAAC;MAChD,IAAIsB,GAAG,IAAIA,GAAG,YAAYC,OAAO,EAAE;QACjCD,GAAG,CAACE,IAAI,CAACnF,CAAC,IAAI+E,GAAG,CAAC/E,CAAC,KAAK9B,SAAS,GAAGA,SAAS,GAAG8B,CAAC,CAAC,EAAEgF,GAAG,CAAC;;MAE1D;MACA;MACA;MACAtB,EAAE,CAAC/K,MAAM,CAACL,gBAAgB,CAAC,OAAO,EAAE,MAAK;QACvC,IACE,CAACoF,OAAO,CAACxB,gBAAgB,IACzBwB,OAAO,CAAC1B,sBAAsB,EAC9B;UACA+I,GAAG,CAAC7G,SAAS,CAAC;UACd;UACA,IAAIR,OAAO,CAAC1B,sBAAsB,EAAE;YAClC+I,GAAG,GAAG/E,CAAC,IAAI4D,EAAE,CAAC5D,CAAC,EAAE,IAAI,CAAC;;;MAG5B,CAAC,CAAC;IACJ,CAAC;IAED,IAAItC,OAAO,CAACyB,MAAM,EAAEzB,OAAO,CAACyB,MAAM,CAACiG,eAAe,GAAG,IAAI;IACzD,MAAM9H,CAAC,GAAG,IAAI4H,OAAO,CAACJ,KAAK,CAAC,CAACK,IAAI,CAACvB,EAAE,EAAEU,EAAE,CAAC;IACzC,MAAMF,EAAE,GAAuBiB,MAAM,CAACC,MAAM,CAAChI,CAAC,EAAE;MAC9CyF,iBAAiB,EAAEW,EAAE;MACrB9B,oBAAoB,EAAE5B,CAAC;MACvB6E,UAAU,EAAE3G;KACb,CAAC;IAEF,IAAIT,KAAK,KAAKS,SAAS,EAAE;MACvB;MACA,IAAI,CAACyE,GAAG,CAACnF,CAAC,EAAE4G,EAAE,EAAE;QAAE,GAAGT,SAAS,CAACjG,OAAO;QAAEyB,MAAM,EAAEjB;MAAS,CAAE,CAAC;MAC5DT,KAAK,GAAG,IAAI,CAAC,CAAArB,MAAO,CAACoD,GAAG,CAAChC,CAAC,CAAC;KAC5B,MAAM;MACL,IAAI,CAAC,CAAAlB,OAAQ,CAACmB,KAAK,CAAC,GAAG2G,EAAE;;IAE3B,OAAOA,EAAE;EACX;EAEA,CAAA/G,iBAAkBkI,CAACjI,CAAM;IACvB,IAAI,CAAC,IAAI,CAAC,CAAAL,cAAe,EAAE,OAAO,KAAK;IACvC,MAAMuI,CAAC,GAAGlI,CAAuB;IACjC,OACE,CAAC,CAACkI,CAAC,IACHA,CAAC,YAAYN,OAAO,IACpBM,CAAC,CAACC,cAAc,CAAC,sBAAsB,CAAC,IACxCD,CAAC,CAACzC,iBAAiB,YAAYlL,EAAE;EAErC;EA+GA,MAAM6N,KAAKA,CACTlI,CAAI,EACJmI,YAAA,GAAgD,EAAE;IAElD,MAAM;MACJ;MACAlK,UAAU,GAAG,IAAI,CAACA,UAAU;MAC5BF,cAAc,GAAG,IAAI,CAACA,cAAc;MACpCQ,kBAAkB,GAAG,IAAI,CAACA,kBAAkB;MAC5C;MACAX,GAAG,GAAG,IAAI,CAACA,GAAG;MACdM,cAAc,GAAG,IAAI,CAACA,cAAc;MACpCvB,IAAI,GAAG,CAAC;MACR0B,eAAe,GAAG,IAAI,CAACA,eAAe;MACtCF,WAAW,GAAG,IAAI,CAACA,WAAW;MAC9B;MACAG,wBAAwB,GAAG,IAAI,CAACA,wBAAwB;MACxDG,0BAA0B,GAAG,IAAI,CAACA,0BAA0B;MAC5DC,gBAAgB,GAAG,IAAI,CAACA,gBAAgB;MACxCF,sBAAsB,GAAG,IAAI,CAACA,sBAAsB;MACpD2B,OAAO;MACPiI,YAAY,GAAG,KAAK;MACpBzG,MAAM;MACNxG;IAAM,CACP,GAAGgN,YAAY;IAEhB,IAAI,CAAC,IAAI,CAAC,CAAA1I,cAAe,EAAE;MACzB,IAAIkC,MAAM,EAAEA,MAAM,CAACuG,KAAK,GAAG,KAAK;MAChC,OAAO,IAAI,CAAClG,GAAG,CAAChC,CAAC,EAAE;QACjB/B,UAAU;QACVF,cAAc;QACdQ,kBAAkB;QAClBoD;OACD,CAAC;;IAGJ,MAAMzB,OAAO,GAAG;MACdjC,UAAU;MACVF,cAAc;MACdQ,kBAAkB;MAClBX,GAAG;MACHM,cAAc;MACdvB,IAAI;MACJ0B,eAAe;MACfF,WAAW;MACXG,wBAAwB;MACxBG,0BAA0B;MAC1BD,sBAAsB;MACtBE,gBAAgB;MAChBiD,MAAM;MACNxG;KACD;IAED,IAAI8E,KAAK,GAAG,IAAI,CAAC,CAAArB,MAAO,CAACoD,GAAG,CAAChC,CAAC,CAAC;IAC/B,IAAIC,KAAK,KAAKS,SAAS,EAAE;MACvB,IAAIiB,MAAM,EAAEA,MAAM,CAACuG,KAAK,GAAG,MAAM;MACjC,MAAMpI,CAAC,GAAG,IAAI,CAAC,CAAAC,eAAgB,CAACC,CAAC,EAAEC,KAAK,EAAEC,OAAO,EAAEC,OAAO,CAAC;MAC3D,OAAQL,CAAC,CAACuH,UAAU,GAAGvH,CAAC;KACzB,MAAM;MACL;MACA,MAAM0C,CAAC,GAAG,IAAI,CAAC,CAAA1D,OAAQ,CAACmB,KAAK,CAAC;MAC9B,IAAI,IAAI,CAAC,CAAAJ,iBAAkB,CAAC2C,CAAC,CAAC,EAAE;QAC9B,MAAM6F,KAAK,GACTpK,UAAU,IAAIuE,CAAC,CAAC4B,oBAAoB,KAAK1D,SAAS;QACpD,IAAIiB,MAAM,EAAE;UACVA,MAAM,CAACuG,KAAK,GAAG,UAAU;UACzB,IAAIG,KAAK,EAAE1G,MAAM,CAACyF,aAAa,GAAG,IAAI;;QAExC,OAAOiB,KAAK,GAAG7F,CAAC,CAAC4B,oBAAoB,GAAI5B,CAAC,CAAC6E,UAAU,GAAG7E,CAAE;;MAG5D;MACA;MACA,MAAMjC,OAAO,GAAG,IAAI,CAAC,CAAAA,OAAQ,CAACN,KAAK,CAAC;MACpC,IAAI,CAACmI,YAAY,IAAI,CAAC7H,OAAO,EAAE;QAC7B,IAAIoB,MAAM,EAAEA,MAAM,CAACuG,KAAK,GAAG,KAAK;QAChC,IAAI,CAAC,CAAA9H,UAAW,CAACH,KAAK,CAAC;QACvB,IAAIlC,cAAc,EAAE;UAClB,IAAI,CAAC,CAAA0D,aAAc,CAACxB,KAAK,CAAC;;QAE5B,IAAI0B,MAAM,EAAE,IAAI,CAAC,CAAAD,SAAU,CAACC,MAAM,EAAE1B,KAAK,CAAC;QAC1C,OAAOuC,CAAC;;MAGV;MACA;MACA,MAAM1C,CAAC,GAAG,IAAI,CAAC,CAAAC,eAAgB,CAACC,CAAC,EAAEC,KAAK,EAAEC,OAAO,EAAEC,OAAO,CAAC;MAC3D,MAAMmI,QAAQ,GAAGxI,CAAC,CAACsE,oBAAoB,KAAK1D,SAAS;MACrD,MAAM6H,QAAQ,GAAGD,QAAQ,IAAIrK,UAAU;MACvC,IAAI0D,MAAM,EAAE;QACVA,MAAM,CAACuG,KAAK,GAAG3H,OAAO,GAAG,OAAO,GAAG,SAAS;QAC5C,IAAIgI,QAAQ,IAAIhI,OAAO,EAAEoB,MAAM,CAACyF,aAAa,GAAG,IAAI;;MAEtD,OAAOmB,QAAQ,GAAGzI,CAAC,CAACsE,oBAAoB,GAAItE,CAAC,CAACuH,UAAU,GAAGvH,CAAE;;EAEjE;EAoCA,MAAM0I,UAAUA,CACdxI,CAAI,EACJmI,YAAA,GAAgD,EAAE;IAElD,MAAM3F,CAAC,GAAG,MAAM,IAAI,CAAC0F,KAAK,CACxBlI,CAAC,EACDmI,YAI8C,CAC/C;IACD,IAAI3F,CAAC,KAAK9B,SAAS,EAAE,MAAM,IAAID,KAAK,CAAC,4BAA4B,CAAC;IAClE,OAAO+B,CAAC;EACV;EAqCAiG,IAAIA,CAACzI,CAAI,EAAE0I,WAAA,GAA8C,EAAE;IACzD,MAAM/K,UAAU,GAAG,IAAI,CAAC,CAAAA,UAAW;IACnC,IAAI,CAACA,UAAU,EAAE;MACf,MAAM,IAAI8C,KAAK,CAAC,uCAAuC,CAAC;;IAE1D,MAAM;MAAEN,OAAO;MAAEiI,YAAY;MAAE,GAAGlI;IAAO,CAAE,GAAGwI,WAAW;IACzD,MAAMlG,CAAC,GAAG,IAAI,CAACR,GAAG,CAAChC,CAAC,EAAEE,OAAO,CAAC;IAC9B,IAAI,CAACkI,YAAY,IAAI5F,CAAC,KAAK9B,SAAS,EAAE,OAAO8B,CAAC;IAC9C,MAAMmG,EAAE,GAAGhL,UAAU,CAACqC,CAAC,EAAEwC,CAAC,EAAE;MAC1BtC,OAAO;MACPC;KACqC,CAAC;IACxC,IAAI,CAACgF,GAAG,CAACnF,CAAC,EAAE2I,EAAE,EAAEzI,OAAO,CAAC;IACxB,OAAOyI,EAAE;EACX;EAEA;;;;;;EAMA3G,GAAGA,CAAChC,CAAI,EAAEkE,UAAA,GAA4C,EAAE;IACtD,MAAM;MACJjG,UAAU,GAAG,IAAI,CAACA,UAAU;MAC5BF,cAAc,GAAG,IAAI,CAACA,cAAc;MACpCQ,kBAAkB,GAAG,IAAI,CAACA,kBAAkB;MAC5CoD;IAAM,CACP,GAAGuC,UAAU;IACd,MAAMjE,KAAK,GAAG,IAAI,CAAC,CAAArB,MAAO,CAACoD,GAAG,CAAChC,CAAC,CAAC;IACjC,IAAIC,KAAK,KAAKS,SAAS,EAAE;MACvB,MAAMyD,KAAK,GAAG,IAAI,CAAC,CAAArF,OAAQ,CAACmB,KAAK,CAAC;MAClC,MAAM2I,QAAQ,GAAG,IAAI,CAAC,CAAA/I,iBAAkB,CAACsE,KAAK,CAAC;MAC/C,IAAIxC,MAAM,EAAE,IAAI,CAAC,CAAAD,SAAU,CAACC,MAAM,EAAE1B,KAAK,CAAC;MAC1C,IAAI,IAAI,CAAC,CAAAM,OAAQ,CAACN,KAAK,CAAC,EAAE;QACxB,IAAI0B,MAAM,EAAEA,MAAM,CAACK,GAAG,GAAG,OAAO;QAChC;QACA,IAAI,CAAC4G,QAAQ,EAAE;UACb,IAAI,CAACrK,kBAAkB,EAAE;YACvB,IAAI,CAAC,CAAAgD,MAAO,CAACvB,CAAC,EAAE,QAAQ,CAAC;;UAE3B,IAAI2B,MAAM,IAAI1D,UAAU,EAAE0D,MAAM,CAACyF,aAAa,GAAG,IAAI;UACrD,OAAOnJ,UAAU,GAAGkG,KAAK,GAAGzD,SAAS;SACtC,MAAM;UACL,IACEiB,MAAM,IACN1D,UAAU,IACVkG,KAAK,CAACC,oBAAoB,KAAK1D,SAAS,EACxC;YACAiB,MAAM,CAACyF,aAAa,GAAG,IAAI;;UAE7B,OAAOnJ,UAAU,GAAGkG,KAAK,CAACC,oBAAoB,GAAG1D,SAAS;;OAE7D,MAAM;QACL,IAAIiB,MAAM,EAAEA,MAAM,CAACK,GAAG,GAAG,KAAK;QAC9B;QACA;QACA;QACA;QACA;QACA,IAAI4G,QAAQ,EAAE;UACZ,OAAOzE,KAAK,CAACC,oBAAoB;;QAEnC,IAAI,CAAC,CAAAhE,UAAW,CAACH,KAAK,CAAC;QACvB,IAAIlC,cAAc,EAAE;UAClB,IAAI,CAAC,CAAA0D,aAAc,CAACxB,KAAK,CAAC;;QAE5B,OAAOkE,KAAK;;KAEf,MAAM,IAAIxC,MAAM,EAAE;MACjBA,MAAM,CAACK,GAAG,GAAG,MAAM;;EAEvB;EAEA,CAAA6G,OAAQC,CAAChJ,CAAQ,EAAEjE,CAAQ;IACzB,IAAI,CAAC,CAAAmD,IAAK,CAACnD,CAAC,CAAC,GAAGiE,CAAC;IACjB,IAAI,CAAC,CAAAf,IAAK,CAACe,CAAC,CAAC,GAAGjE,CAAC;EACnB;EAEA,CAAAuE,UAAW2I,CAAC9I,KAAY;IACtB;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA,IAAIA,KAAK,KAAK,IAAI,CAAC,CAAAf,IAAK,EAAE;MACxB,IAAIe,KAAK,KAAK,IAAI,CAAC,CAAAhB,IAAK,EAAE;QACxB,IAAI,CAAC,CAAAA,IAAK,GAAG,IAAI,CAAC,CAAAF,IAAK,CAACkB,KAAK,CAAU;OACxC,MAAM;QACL,IAAI,CAAC,CAAA4I,OAAQ,CACX,IAAI,CAAC,CAAA7J,IAAK,CAACiB,KAAK,CAAU,EAC1B,IAAI,CAAC,CAAAlB,IAAK,CAACkB,KAAK,CAAU,CAC3B;;MAEH,IAAI,CAAC,CAAA4I,OAAQ,CAAC,IAAI,CAAC,CAAA3J,IAAK,EAAEe,KAAK,CAAC;MAChC,IAAI,CAAC,CAAAf,IAAK,GAAGe,KAAK;;EAEtB;EAEA;;;;;EAKAsB,MAAMA,CAACvB,CAAI;IACT,OAAO,IAAI,CAAC,CAAAuB,MAAO,CAACvB,CAAC,EAAE,QAAQ,CAAC;EAClC;EAEA,CAAAuB,MAAOyH,CAAChJ,CAAI,EAAEpF,MAA8B;IAC1C,IAAI8J,OAAO,GAAG,KAAK;IACnB,IAAI,IAAI,CAAC,CAAA/H,IAAK,KAAK,CAAC,EAAE;MACpB,MAAMsD,KAAK,GAAG,IAAI,CAAC,CAAArB,MAAO,CAACoD,GAAG,CAAChC,CAAC,CAAC;MACjC,IAAIC,KAAK,KAAKS,SAAS,EAAE;QACvBgE,OAAO,GAAG,IAAI;QACd,IAAI,IAAI,CAAC,CAAA/H,IAAK,KAAK,CAAC,EAAE;UACpB,IAAI,CAAC,CAAAuI,KAAM,CAACtK,MAAM,CAAC;SACpB,MAAM;UACL,IAAI,CAAC,CAAA0H,cAAe,CAACrC,KAAK,CAAC;UAC3B,MAAMuC,CAAC,GAAG,IAAI,CAAC,CAAA1D,OAAQ,CAACmB,KAAK,CAAC;UAC9B,IAAI,IAAI,CAAC,CAAAJ,iBAAkB,CAAC2C,CAAC,CAAC,EAAE;YAC9BA,CAAC,CAAC+C,iBAAiB,CAACnK,KAAK,CAAC,IAAIqF,KAAK,CAAC,SAAS,CAAC,CAAC;WAChD,MAAM,IAAI,IAAI,CAAC,CAAAjB,UAAW,IAAI,IAAI,CAAC,CAAAE,eAAgB,EAAE;YACpD,IAAI,IAAI,CAAC,CAAAF,UAAW,EAAE;cACpB,IAAI,CAAC,CAAAhC,OAAQ,GAAGgF,CAAM,EAAExC,CAAC,EAAEpF,MAAM,CAAC;;YAEpC,IAAI,IAAI,CAAC,CAAA8E,eAAgB,EAAE;cACzB,IAAI,CAAC,CAAAN,QAAS,EAAEpE,IAAI,CAAC,CAACwH,CAAM,EAAExC,CAAC,EAAEpF,MAAM,CAAC,CAAC;;;UAG7C,IAAI,CAAC,CAAAgE,MAAO,CAAC2C,MAAM,CAACvB,CAAC,CAAC;UACtB,IAAI,CAAC,CAAAnB,OAAQ,CAACoB,KAAK,CAAC,GAAGS,SAAS;UAChC,IAAI,CAAC,CAAA5B,OAAQ,CAACmB,KAAK,CAAC,GAAGS,SAAS;UAChC,IAAIT,KAAK,KAAK,IAAI,CAAC,CAAAf,IAAK,EAAE;YACxB,IAAI,CAAC,CAAAA,IAAK,GAAG,IAAI,CAAC,CAAAF,IAAK,CAACiB,KAAK,CAAU;WACxC,MAAM,IAAIA,KAAK,KAAK,IAAI,CAAC,CAAAhB,IAAK,EAAE;YAC/B,IAAI,CAAC,CAAAA,IAAK,GAAG,IAAI,CAAC,CAAAF,IAAK,CAACkB,KAAK,CAAU;WACxC,MAAM;YACL,MAAMgJ,EAAE,GAAG,IAAI,CAAC,CAAAjK,IAAK,CAACiB,KAAK,CAAW;YACtC,IAAI,CAAC,CAAAlB,IAAK,CAACkK,EAAE,CAAC,GAAG,IAAI,CAAC,CAAAlK,IAAK,CAACkB,KAAK,CAAW;YAC5C,MAAMiJ,EAAE,GAAG,IAAI,CAAC,CAAAnK,IAAK,CAACkB,KAAK,CAAW;YACtC,IAAI,CAAC,CAAAjB,IAAK,CAACkK,EAAE,CAAC,GAAG,IAAI,CAAC,CAAAlK,IAAK,CAACiB,KAAK,CAAW;;UAE9C,IAAI,CAAC,CAAAtD,IAAK,EAAE;UACZ,IAAI,CAAC,CAAAwC,IAAK,CAACnE,IAAI,CAACiF,KAAK,CAAC;;;;IAI5B,IAAI,IAAI,CAAC,CAAAP,eAAgB,IAAI,IAAI,CAAC,CAAAN,QAAS,EAAErC,MAAM,EAAE;MACnD,MAAM0I,EAAE,GAAG,IAAI,CAAC,CAAArG,QAAS;MACzB,IAAIsG,IAAmC;MACvC,OAAQA,IAAI,GAAGD,EAAE,EAAEE,KAAK,EAAE,EAAG;QAC3B,IAAI,CAAC,CAAAlI,YAAa,GAAG,GAAGiI,IAAI,CAAC;;;IAGjC,OAAOhB,OAAO;EAChB;EAEA;;;EAGAQ,KAAKA,CAAA;IACH,OAAO,IAAI,CAAC,CAAAA,KAAM,CAAC,QAAQ,CAAC;EAC9B;EACA,CAAAA,KAAMiE,CAACvO,MAA8B;IACnC,KAAK,MAAMqF,KAAK,IAAI,IAAI,CAAC,CAAAK,QAAS,CAAC;MAAErC,UAAU,EAAE;IAAI,CAAE,CAAC,EAAE;MACxD,MAAMuE,CAAC,GAAG,IAAI,CAAC,CAAA1D,OAAQ,CAACmB,KAAK,CAAC;MAC9B,IAAI,IAAI,CAAC,CAAAJ,iBAAkB,CAAC2C,CAAC,CAAC,EAAE;QAC9BA,CAAC,CAAC+C,iBAAiB,CAACnK,KAAK,CAAC,IAAIqF,KAAK,CAAC,SAAS,CAAC,CAAC;OAChD,MAAM;QACL,MAAMT,CAAC,GAAG,IAAI,CAAC,CAAAnB,OAAQ,CAACoB,KAAK,CAAC;QAC9B,IAAI,IAAI,CAAC,CAAAT,UAAW,EAAE;UACpB,IAAI,CAAC,CAAAhC,OAAQ,GAAGgF,CAAM,EAAExC,CAAM,EAAEpF,MAAM,CAAC;;QAEzC,IAAI,IAAI,CAAC,CAAA8E,eAAgB,EAAE;UACzB,IAAI,CAAC,CAAAN,QAAS,EAAEpE,IAAI,CAAC,CAACwH,CAAM,EAAExC,CAAM,EAAEpF,MAAM,CAAC,CAAC;;;;IAKpD,IAAI,CAAC,CAAAgE,MAAO,CAACsG,KAAK,EAAE;IACpB,IAAI,CAAC,CAAApG,OAAQ,CAAClC,IAAI,CAAC8D,SAAS,CAAC;IAC7B,IAAI,CAAC,CAAA7B,OAAQ,CAACjC,IAAI,CAAC8D,SAAS,CAAC;IAC7B,IAAI,IAAI,CAAC,CAAAnB,IAAK,IAAI,IAAI,CAAC,CAAAD,MAAO,EAAE;MAC9B,IAAI,CAAC,CAAAC,IAAK,CAAC3C,IAAI,CAAC,CAAC,CAAC;MAClB,IAAI,CAAC,CAAA0C,MAAO,CAAC1C,IAAI,CAAC,CAAC,CAAC;;IAEtB,IAAI,IAAI,CAAC,CAAAyC,KAAM,EAAE;MACf,IAAI,CAAC,CAAAA,KAAM,CAACzC,IAAI,CAAC,CAAC,CAAC;;IAErB,IAAI,CAAC,CAAAqC,IAAK,GAAG,CAAU;IACvB,IAAI,CAAC,CAAAC,IAAK,GAAG,CAAU;IACvB,IAAI,CAAC,CAAAC,IAAK,CAACpC,MAAM,GAAG,CAAC;IACrB,IAAI,CAAC,CAAA4B,cAAe,GAAG,CAAC;IACxB,IAAI,CAAC,CAAAhC,IAAK,GAAG,CAAC;IACd,IAAI,IAAI,CAAC,CAAA+C,eAAgB,IAAI,IAAI,CAAC,CAAAN,QAAS,EAAE;MAC3C,MAAMqG,EAAE,GAAG,IAAI,CAAC,CAAArG,QAAS;MACzB,IAAIsG,IAAmC;MACvC,OAAQA,IAAI,GAAGD,EAAE,EAAEE,KAAK,EAAE,EAAG;QAC3B,IAAI,CAAC,CAAAlI,YAAa,GAAG,GAAGiI,IAAI,CAAC;;;EAGnC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}